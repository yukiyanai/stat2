[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KUT 統計学2",
    "section": "",
    "text": "これは、高知工科大学 経済・マネジメント学群で開講されている「統計学2」（担当：矢内勇生）の講義用資料である。\n\n\n\n\n\n\n注意\n\n\n\nこれは授業の補助教材である。\n\n大切なことは授業で説明する。この資料にすべて書かれているわけではない。\nこの資料に書かれていない内容も授業で説明する。よって、この資料に書かれていない事項でも授業で説明した内容はすべて試験範囲である。\n受講生全員が 教科書 の指定範囲を読んでいるという前提で授業を進め、試験を実施する。教科書の内容をこの資料で詳しく説明することはないので、必ず教科書を読むように。\n\n\n\n\n\n\nシラバス（講義要項）：PDF\n講義スライド\n\n各授業の後に最新版をアップロードする\n\n\n\n\n\n\n\n\n注意\n\n\n\n一般公開用のスライドでは一部の情報がカットされているので、正規受講生（単位を取得したい者）は KUTLMS で完全版を入手すること\n\n\n\nKUTLMS\n\n登録キーはポータルで通知する\n\n授業用のSlackグループ\n\n登録 には大学ドメインのメールアドレスが必要\n\n\n\n\n\n\n\n\n浅野正彦, 矢内勇生. 2018.『Rによる計量政治学』オーム社（サポートページ）\n\n\n\n\n\n\n宋財泫, 矢内勇生 （執筆中）『私たちのR：ベストプラクティスの探求』(web book、無料)\n\n\n\n\n\n授業の内容は、10のトピックに分かれている。シラバス (PDF) にはトピックごとの予習課題と参考文献が記載されている。 各トピックとこのウェブ資料の対応は以下の通りである。\n\n\n\nトピック\nウェブ資料\n\n\n\n\n1. イントロダクション\n\n\n\n2. Rの基本操作\nRの基本操作\n\n\n3. 記述統計とデータの可視化\nRStudio入門\n\n\n\n記述統計\n\n\n4. R Markdown によるレポート作成\nRマークダウンの使い方\n\n\n5. ggplot2 入門\nggplot2入門\n\n\n6. シミュレーション\n乱数生成\n\n\n\n中心極限定理\n\n\n7. 統計的推定と仮説検定の基礎\n統計的推定と仮説検定の基礎\n\n\n\n母集団と標本をシミュレーションで理解する\n\n\n8. 標本平均と母平均\nシミュレーションを利用して大数の法則を理解する\n\n\n\n標本分布を理解する\n\n\n\n母平均の推定\n\n\n9. \\(t\\) 分布と母平均の推定\n\\(t\\) 分布を利用した母平均の推定\n\n\n10. 2つの平均値を比較する\n統計的検定と平均値の比較\n\n\n\n\n\n\n\n\n\n注意\n\n\n\n一部の例外を除いて、各ページ（各章）の内容を実行するために必要なパッケージはページの冒頭で読み込むことにする。ページの途中から実行しても動かないことがあると思われるので、その際はページの最初から実行してほしい。\n各ページは（パッケージのインストールとデータファイルの入手を除き）独立なので、ページ単位で実行することができる。"
  },
  {
    "objectID": "intro-to-R.html",
    "href": "intro-to-R.html",
    "title": "\n2  Rの基本操作\n",
    "section": "",
    "text": "ここでは、Rの基本的な使い方を解説する。RとRStudioのインストールについては、以下の資料を参照されたい。"
  },
  {
    "objectID": "intro-to-R.html#sec-rbasic",
    "href": "intro-to-R.html#sec-rbasic",
    "title": "\n2  Rの基本操作\n",
    "section": "\n2.1 Rの基礎",
    "text": "2.1 Rの基礎\nRのコードはRのConsoleに直接入力してもいいし、スクリプトに保存してRから呼び出してもよい。スクリプトを使うときは、スクリプトファイルをfile_name.R のように .R ファイルとして保存する。そして、RのConsole で source(\"file_name.R\") とすれば、スクリプト全体が実行される。\n\n\n\n\n\n\n重要\n\n\n\nこの資料にあるコードは簡単にコピーすることができる。それをR (RStduio) にペーストすれば（貼り付ければ）コマンドを実行することができる。 しかし、そのような方法ではなかなかコマンドを覚えることができないだろう。\nRのコマンドは、自らの手でタイプすることを強く勧める。プログラミングを身につけるためには、自分でプログラムを「書く」ことが必要である。\n\n\nRコマンドの区切りは改行である。改行すれば、1つのコマンドが終了したと認識される。\n\n35 + 87\n\n[1] 122\n\n\nただし、括弧が閉じていなかったり、行末に二項演算子 (+ や * など) があるときは、コマンドが次の行まで続いていると認識される。\n\n35 +\n    87\n\n[1] 122\n\n\n1行に複数のコマンドを書きたいときは ; で区切る。\n\n35 + 87; 25 * 4\n\n[1] 122\n\n\n[1] 100\n\n\n\n\n\n\n\n\nヒント\n\n\n\nこの資料のRコマンドを読むときは、どこにスペースがあるかに注意し、自分で書く際も（少なくともはじめのうちは）それを真似するようにしよう。たとえば、上のコマンドの最初の足し算は、35+87 ではなく、35 + 87 と書かれている。\n\n\n通常は、1行には1つのコマンドのみ書くようにしよう。\nRは大文字と小文字を区別する。したがって、Var1 と var1 は異なるモノ（変数、オブジェクト）として認識される。 変数名は英数字と_ [アンダースコア] のみで構成するべきである（日本語も使えるが、トラブルの元なので避けるべき）。ただし、頭文字に数字は使えない。\nスペースは1つ以上ならいくつあっても1つのスペースがある場合と同じである。また、演算子の前後のスペースはあってもなくてもよい（コードの読み易さを考えてスペースの有無を決めること）。\n\n\n\n\n\n\n重要\n\n\n\nコード中のスペースは半角スペースでなければならない。日本語入力で使うスペースは全角スペースだが、全角スペースがあるとコードが正しく動作しないので要注意。プログラミングの際には日本語入力が「オフ」になっていることを確認しよう。\n\n\n# はコメントの開始として扱われる。 行頭に# を書くと、その行すべてがコメントとして扱われる。\n\n# 2 * 4  # 行頭からすべてコメント \n\n行の途中に# を書くと、# 以降がコメントとして扱われる。\n\n2 * 4  # これはコメント\n\n[1] 8\n\n\nコメントを書く作業は、コマンドを書く作業と同様に大切である。詳しくは授業で説明する。\nRに用意されている関数の使い方についてヘルプを参照したいときは?関数名 （またはhelp(関数名))　とする。たとえば、平均値を求める関数 mean() のヘルプは、\n\n?mean\n\nで確認できる。ウェブブラウザでヘルプを参照したいときは、help.start() とする。\nインストール済みのパッケージを利用するときは、library(パッケージ名) とする。たとえば、ggplot2 パッケージを使いたいなら、\n\nlibrary(ggplot2)\n\nとする。パッケージをインストールする際は、install.packages(\"パッケージ名\") とする。その際、どのレポジトリからダウンロードするか尋ねられるので、自分に一番近いところ選ぶ。（パッケージをインストールする度にレポジトリを指定するのが面倒なら、.Rprofile であらかじめレポジトリを指定しておく。）\n\n2.1.1 Rを電卓代わりに使う\nRは電卓の代わりとして使うことができる。 たとえば、\n\n1 + 1       # 足し算\n\n[1] 2\n\n100 - 20    # 引き算\n\n[1] 80\n\n5 * 8       # 掛け算\n\n[1] 40\n\n2 / 3       # 割り算\n\n[1] 0.6666667\n\n2 ^ 3       # 累乗\n\n[1] 8\n\nsqrt(2)     # 平方根\n\n[1] 1.414214\n\n2 ^ (1 / 2) # sqrt(2) と同じ\n\n[1] 1.414214\n\n\nなどの計算ができる。 計算の順番を指定するときは、() で囲めばよい。\n\n(5 * (2 + 1)) ^ 3  # (2 + 1) を最初に計算し、それに5を掛けてから最後に三乗する\n\n[1] 3375\n\n\n\n2.1.2 変数の利用\nRでは、変数（正確にはオブジェクト）を（ある程度）自由に作ることができる。 変数の名前は自由に決めてよい（ただし、数字から始まるものはだめ。また、- [ハイフン] はマイナスと区別できないので使えない）。 たとえば、\n\na <- 1\nb <- 2\n\nとすると、a, b という2つの変数ができる。ここで <- は変数に値を割り当てることを意味する。 （<- の代わりに= を使うこともできるが混乱の元になるので、変数を定義するときは常に<- を使うことにする。）\n<- はショートカットキーを使って入力する。\n\nmacOS: option + -（option キーと -[マイナス] キーを同時に押す）\nWindows: Alt + -（Alt キーと - [マイナス] キーを同時に押す）\n\nこうすることで、 <- だけでなく、その前後に半角スペースが1つずつ挿入されるので便利である。つまり、順番に\n\na\n\noption + - または Alt + -\n\n1\n\nと打つと\n\na <- 1\n\nと入力される。ショートカットキーを使わないと、\n\na\nSPACE\n<\n-\nSPACE\n1\n\nと6段階の入力が必要になる。ショートカットキーを使うことで、これを3回に短縮できる。\n定義された変数名のみを入力して実行すると、変数の中身が表示される。\n\na\n\n[1] 1\n\nb\n\n[1] 2\n\n\nこの変数は、計算に使える。\n\na + b\n\n[1] 3\n\na - b\n\n[1] -1\n\na * b\n\n[1] 2\n\na / b\n\n[1] 0.5\n\nb ^ a\n\n[1] 2\n\n\nまた、\n\nd <- a\na <- 3\n\nとすると、\\(d = 1\\), \\(a = 3\\) となる（各自確かめること）。\nまた、変数名には日本語も使える。 たとえば、\n\n変数1 <- 5\n変数2 <- 7\n変数1 * 変数2\n\n[1] 35\n\n\nとすることも可能である。しかし、変数名に日本語を使うと、（1）英語/日本語の切り替えが面倒であり、（2）文字化け等の予期せぬ問題が生じることがあるので、なるべく日本語の変数名は使わないほうが無難である。\n変数の割当と画面への出力を同時に行いたいときは、全体を () で囲む。\n\n(d <- 3 * 5)\n\n[1] 15\n\n\n変数を消去したいときはrm() 関数を使う。\n\nrm(d)\n\n\n2.1.3 ベクトルと行列\n\n2.1.3.1 ベクトル (vectors)\nRで特定のベクトル (vector) を作りたいときは、c() を（combine; 結合する）使う （上での変数を作るときにc という名前をスキップしたのは、この cという名前の関数があるためだった）。 たとえば、1, 2, 3, 4, 5 という5つの数字からなるベクトル a を作るには、\n\na <- c(1, 2, 3, 4, 5)\n\nとする。このベクトルを画面に表示すると、\n\na\n\n[1] 1 2 3 4 5\n\n\nとなる。\nベクトルの中身は文字列でもかまわない。 たとえば、\n\nuniv_kochi <- c(\"KUT\", \"University of Kochi\", \"Kochi University\")\n\nとすれば、文字列 (characters) のベクトルができる。 このように、文字列は引用符（'' でも\"\" でもよい）で囲む。\nひとつひとつの要素を指定する代わりに、様々な方法でベクトルを作ることが可能である。 たとえば、seq() 関数（sequence; 数列）を使うと、一連の数字からなるベクトルを作ることができる。\n\nseq(1, 20, by = 1)   # 1から20までの整数。1:20 でも同じ\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\nseq(1, 20, by = 2)   # 1から19までの奇数\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\nseq(2, 20, by = 2)   # 2から20までの偶数\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\nseq(20, 1, by = -5)  # 降順、間隔は5\n\n[1] 20 15 10  5\n\nseq(1, 100, length.out = 10) # 最小値が1、最大値が100で、要素の数 (length) が10のベクトル\n\n [1]   1  12  23  34  45  56  67  78  89 100\n\n\nseq(x, y, by = 1) の場合はより単純に x : yとすればよい。\n\n1 : 20\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n\nまた、rep()関数（replicate; 複製する）も便利である。\n\nrep(3, 10)   # 3が10個のベクトル\n\n [1] 3 3 3 3 3 3 3 3 3 3\n\nrep(c('a', 'b', 'c'), c(3, 1, 2))  # aが3つ, bが1つ, cが2つのベクトル\n\n[1] \"a\" \"a\" \"a\" \"b\" \"c\" \"c\"\n\n\nベクトルの\\(i\\)番目の要素にアクセスするにはベクトル名[i]とする。 同時に複数の要素を取り出すこともできる。 たとえば、\n\na <- seq(10, 100, length.out = 10)\nb <- 10:1\na[2]\n\n[1] 20\n\nb[2]\n\n[1] 9\n\na[3:5]\n\n[1] 30 40 50\n\na[c(1,3,5)]\n\n[1] 10 30 50\n\na[c(8, 2, 4)]\n\n[1] 80 20 40\n\n\n\n2.1.3.2 ベクトルの演算\nRでは、ベクトルを使った演算が可能である。 たとえば、次のような計算ができる。\n\nx <- 1 : 10\nx + 10    # ベクトルxの各要素に10を加える\n\n [1] 11 12 13 14 15 16 17 18 19 20\n\nx - 5     # ベクトルxの各要素から5を引く\n\n [1] -4 -3 -2 -1  0  1  2  3  4  5\n\nx * 2     # ベクトルxの各要素に2をかける\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\nx / 3     # ベクトルxの各要素を3で割る\n\n [1] 0.3333333 0.6666667 1.0000000 1.3333333 1.6666667 2.0000000 2.3333333\n [8] 2.6666667 3.0000000 3.3333333\n\nx ^ 2     # ベクトルxの各要素を2乗する\n\n [1]   1   4   9  16  25  36  49  64  81 100\n\nsqrt(x)   # ベクトルxの各要素の平方根（square root）を計算する\n\n [1] 1.000000 1.414214 1.732051 2.000000 2.236068 2.449490 2.645751 2.828427\n [9] 3.000000 3.162278\n\n\nまた、複数のベクトルを使って、次のような計算ができる。\n\nx <- 1:10\ny <- -10:-1\n\n# xのi番目の要素とyのi番目の要素を足す（i = 1, 2, ..., 10）\nx + y\n\n [1] -9 -7 -5 -3 -1  1  3  5  7  9\n\n# xのi番目の要素からyのi番目の要素を引く（i = 1, 2, ..., 10）\nx - y\n\n [1] 11 11 11 11 11 11 11 11 11 11\n\n# xのi番目の要素とyのi番目の要素をかける（i = 1, 2, ..., 10）\nx * y\n\n [1] -10 -18 -24 -28 -30 -30 -28 -24 -18 -10\n\n# xのi番目の要素をyのi番目の要素で割る（i = 1, 2, ..., 10）\nx / y\n\n [1]  -0.1000000  -0.2222222  -0.3750000  -0.5714286  -0.8333333  -1.2000000\n [7]  -1.7500000  -2.6666667  -4.5000000 -10.0000000\n\n# xのi番目の要素を「yのi番目の要素」乗にする（i = 1, 2, ..., 10）\nx ^ y\n\n [1] 1.000000e+00 1.953125e-03 1.524158e-04 6.103516e-05 6.400000e-05\n [6] 1.286008e-04 4.164931e-04 1.953125e-03 1.234568e-02 1.000000e-01\n\n\nベクトル同士の足し算（引き算）をしても、ベクトルの長さは変わらない。\n\nlength(x)\n\n[1] 10\n\nlength(y)\n\n[1] 10\n\nlength(x + y)\n\n[1] 10\n\n\n長さの異なるベクトルを使って演算を行うと、短いのほうのベクトルは要素をリサイクルして対応する。\n\nx <- 1 : 10\ny <- c(100, 200)\nx + y\n\n [1] 101 202 103 204 105 206 107 208 109 210\n\n\nただし、長いほうのベクトルの長さが短いほうのベクトルの長さの整数倍になっていないときは、警告 (warning) が出る。\n\nx <- 1 : 10\ny <- c(100, 200, 300)\nx + y\n\nWarning in x + y: longer object length is not a multiple of shorter object\nlength\n\n\n [1] 101 202 303 104 205 306 107 208 309 110\n\n\n2つのベクトルの内積 (dot product) は%*% で、直積 (outer product) は%o% またはouter() で求められる。\nx <- c(1, 3, 5)\ny <- c(10, 20, 30)\nx %*% y      # xとyの内積\nx %o% y      # xとyの直積\nouter(x, y)  # xとyの直積\n\n\n2.1.3.3 行列 (matrices)\nRで行列を作るには、matrix()関数を使う。 たとえば、\n\n(A <- matrix(1:9, nrow = 3, byrow = TRUE))\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n(B <- matrix(1:9, nrow = 3, byrow = FALSE))\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nのようにする。 ここで、行列Aと行列Bの違いに注目する。 要素全体をひとつの集合としてみると、AとBの行列は全く同じである。 これは、上のコードでは1:9という部分が同じだからである。 しかし、要素の並び方が異なる。 Aを作ったコードはbyrow = TRUEとなっている。 これは、行 (row) 単位でセルを埋めて行くということである。 それに対し、Bではbyrow = FALSE となっている。 これは行単位でセルを埋めない（したがって、列 [col] 単位で埋める）ということを意味する。 この違いが、AとBの違いを生み出している。 行列を作るときは行数 nrow と列数 ncol を指定するが、要素の合計数が決まっているときは、どちらか一方を指定すれば、もう一方は自動的に決められる。 上の例では、要素の数が9で、行の数に3を指定したので、列の数は自動的に 9 / 3 = 3 になっている。\n行列の各行と各列にはそれぞれ名前を付けることができる。\n\nrow.names(A) <- c('row1', 'row2', 'row3')  # 各行に名前をつける\ncolnames(A) <- c('col1', 'col2', 'col3')   # 各列に名前をつける\nA\n\n     col1 col2 col3\nrow1    1    2    3\nrow2    4    5    6\nrow3    7    8    9\n\n\nrow.names()には . があり、colnames()にはそれがないことに注意。\n行列の\\(i\\)行\\(j\\)列を取り出すには、行列名[i, j]とする。 例えば\n\nA[1, 3]          # 第1行、第3列の要素を取り出す\n\n[1] 3\n\nA[2, c(1, 3)]    # 第2行で、第1列と第3列の要素を取り出す\n\ncol1 col3 \n   4    6 \n\nA[3, ]           # 第3行の要素をすべて取り出す\n\ncol1 col2 col3 \n   7    8    9 \n\nA[, 2]           # 第2列の要素をすべて取り出す\n\nrow1 row2 row3 \n   2    5    8 \n\n\n\n2.1.3.4 行列の演算\nRでは行列を使った計算ができる。\n基本的な演算の結果は次のとおりである。\n\nA <- matrix(1:9, ncol = 3)   　# 行列Aを定義する\nB <- matrix(-4:4, ncol = 3)    # 行列Bを定義する\nA + 3   # 行列の各要素に3を加える\n\n     [,1] [,2] [,3]\n[1,]    4    7   10\n[2,]    5    8   11\n[3,]    6    9   12\n\n2 * A   # 行列の各要素を2倍する\n\n     [,1] [,2] [,3]\n[1,]    2    8   14\n[2,]    4   10   16\n[3,]    6   12   18\n\nA + B   # Aのi行j列要素とBのi行j列要素を足す (i, j = 1, 2, 3)\n\n     [,1] [,2] [,3]\n[1,]   -3    3    9\n[2,]   -1    5   11\n[3,]    1    7   13\n\nA * B   # 行列の要素同士の積\n\n     [,1] [,2] [,3]\n[1,]   -4   -4   14\n[2,]   -6    0   24\n[3,]   -6    6   36\n\nA %*% B  # 行列の積\n\n     [,1] [,2] [,3]\n[1,]  -30    6   42\n[2,]  -39    6   51\n[3,]  -48    6   60\n\nB %*% A  # 行列の積\n\n     [,1] [,2] [,3]\n[1,]    0   -9  -18\n[2,]    6    6    6\n[3,]   12   21   30\n\n## AB と BA は異なる\nA %*% B == B %*% A  # 要素ごとに等しいかどうか比較する\n\n      [,1]  [,2]  [,3]\n[1,] FALSE FALSE FALSE\n[2,] FALSE  TRUE FALSE\n[3,] FALSE FALSE FALSE\n\na <- 1:3  # ベクトルを定義する\nA %*% a   # (3行3列) x (3行1列) なので結果は3行1列\n\n     [,1]\n[1,]   30\n[2,]   36\n[3,]   42\n\n\n行列の転置 (transpose) にはt()を使う。\n\nt(A)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\n逆行列はsolve()で求める。\n\nC <- matrix(c(2, 3, 5, \n              7, 11, 13,\n              17, 19, 23),\n            nrow = 3)\nsolve(C)\n\n            [,1]       [,2]        [,3]\n[1,] -0.07692308 -0.7692308  0.69230769\n[2,] -0.33333333  0.5000000 -0.16666667\n[3,]  0.20512821 -0.1153846 -0.01282051\n\n\n特異行列 (a singular matrix) にsolve() を使うとエラーになる。\n\nS <- matrix(1:9, nrow = 3)\nsolve(S)\n\nError in solve.default(S): Lapack routine dgesv: system is exactly singular: U[3,3] = 0\n\n\nエラーメッセージを読めば何がまずいのかわかるので、エラーが出たらエラーメッセージの中身をよく読むこと。 この場合は、行列が特異行列 (singular) であることを教えてくれている。\n\n\n\n\n\n\nヒント\n\n\n\nRを使っている最中にエラーが出ても何も問題ない。プログラミングを身につけるためには試行錯誤が必要なので、エラーをおそれず、どんどんエラーを出していこう。\nエラーが出たら、「自分の意図したとおりに動かず、エラーが出たのはなぜか」を考えよう。エラーの原因を特定することで、プログラミング（R言語）に対する理解が深まるだろう。"
  },
  {
    "objectID": "intro-to-RStudio.html",
    "href": "intro-to-RStudio.html",
    "title": "\n3  RStudio入門\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "intro-to-RStudio.html#sec-projects",
    "href": "intro-to-RStudio.html#sec-projects",
    "title": "\n3  RStudio入門\n",
    "section": "\n3.1 プロジェクトの作成",
    "text": "3.1 プロジェクトの作成\nRStudio にはプロジェクト機能がある。この機能を使うと、プロジェクトの管理が容易になる。ここでは、「統計学2」をプロジェクトの1つと考え、新規プロジェクトを作成してみよう。\n以下のステップを踏めば、プロジェクトが作れる。\n\nコンピュータの自分のファイルが保存できる場所（たとえば、「ドキュメント」）に、この授業（統計学2）用のフォルダ（ディレクトリ； directory）を作る。\n\n\nフォルダ名はアルファベットと数字のみで付ける\nフォルダ名の最初の文字はアルファベットにする\nファルダ名にスペース（空白）を使わない!\nフォルダ名の例: stat2\n\n\n\n\n\n\n\n重要\n\n\n\n大学の情報演習室にあるパソコンを使っている場合は、Zドライブ にフォルダを作る。 授業で説明するので、説明をよく聞くように。説明がよくわからない場合は、担当教員またはSAにその場ですぐに質問しよう。\n\n\n\n上部のメニューで、File -> New Project を選ぶ\nExisting Directory（既存のディレクトリ）を選ぶ\nbrowse（閲覧）を押して、自分が作ったフォルダ（ディレクトリ）を選び、右下の Create Project をクリックする\n\nこれで新しいプロジェクトができる。プロジェクト名（自分で作ったフォルダの名前がそのまま使われる）は RStudioの右上に表示される。\n次回以降、このプロジェクトを開くには、File -> Open Project でこのプロジェクトを選べばよい。\n\n\n\n\n\n\n重要\n\n\n\n大学の情報演習室にあるパソコンを使っている場合は、Zドライブ 経由でプロジェクトを開く必要がある。授業で説明するので、説明をよく聞くように。わからなくなったら、担当教員またはSAにその場ですぐに質問しよう。"
  },
  {
    "objectID": "intro-to-RStudio.html#sec-scripts",
    "href": "intro-to-RStudio.html#sec-scripts",
    "title": "\n3  RStudio入門\n",
    "section": "\n3.2 Rスクリプトの作成と利用",
    "text": "3.2 Rスクリプトの作成と利用\nRのコマンド（命令文）は、RStudio 右側（あるいは左下）の Console に直接打ち込むこともできる。しかし、通常はそのような使い方はしない。代わりに、Rの命令が書かれたファイルを別に作り、その中に命令を記入する。\nRStudio で新しいRスクリプトを作るには、RStudioで 「Cmd/Ctrl + Shift + N」を入力する （あるいはRStudio 上部のメニューで、File -> New File -> R Script の順番で選ぶ）。そうすると、RStudio の左側のウィンドウが上下に2分割されるはずである。このとき、左上に新たに開くのがRスクリプトである。（左下が Hisotory の場合は、不要なので最小化する。左下 Console の場合はそのままにする）\nRスクリプトができたら、「Cmd/Ctrl + S」 を押し、名前をつけて保存しよう（名前の付け方はフォルダ名の付け方と同じルールで）。このファイルにRの命令を書き込む。基本的には、1つの行には1つの命令しか書かない。\nこのファイルに書いた命令を実行したいときは、実行したい行にカーソルをおいた状態で、「Cmd/Ctrl + Return/Enter」を押す。すると、命令がConsole に送られ、実行される。"
  },
  {
    "objectID": "intro-to-RStudio.html#sec-comments",
    "href": "intro-to-RStudio.html#sec-comments",
    "title": "\n3  RStudio入門\n",
    "section": "\n3.3 コメントの利用",
    "text": "3.3 コメントの利用\nRスクリプトには、Rに送る命令以外に、自分（あるいは他の人間）用のコメントを書き込むことができる。Rでコメントを書くときは、# （ハッシュ）という記号を使う。Rは、その行で # より後にあるものを無視する。\n\n\n\n\n\n\n注意\n\n\n\n# は半角！\n\n\nたとえば、以下の4行をRで実行すると、2行目と3行目は無視される。\n\na <- c(4, 5, 3, 4, 6, 7, 1, 2, 9)\n# a の標準偏差を求めたい\n# 標準偏差は英語では standard deviation; sd() という関数を使う\nsd(a)\n\n[1] 2.505549\n\n\n\n\n\n\n\n\nヒント\n\n\n\n<- という記号は、「Option/Alt + - [マイナス] 」で入力する。\n\n\nスクリプトに命令だけ書いても、命令の意味を忘れてしまったり、自分がなぜその命令を書いたのか後でわからなくなったりするので、どんどんコメントを書き込もう。\n\n\n\n\n\n\n重要\n\n\n\nコメントは人の為ならず：コメントしておくことで、未来の自分に感謝される！"
  },
  {
    "objectID": "descriptive-stat.html",
    "href": "descriptive-stat.html",
    "title": "\n4  記述統計\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "descriptive-stat.html#sec-1var",
    "href": "descriptive-stat.html#sec-1var",
    "title": "\n4  記述統計\n",
    "section": "\n4.1 1変数の記述統計とデータの可視化",
    "text": "4.1 1変数の記述統計とデータの可視化\n\n4.1.1 パッケージの読み込み\nまず、この授業で頻繁に（ほぼ毎回）使う、tidyverseパッケージをインストールしよう。既にインストール済みなら再度インストールする必要はない。割と時間がかかるので注意。\n\n\n\n\n\n\n重要\n\n\n\n大学の情報演習室のパソコンを使っている場合は、パッケージをインストールしてはいけない。基本的なパッケージはインストール済みなので、さらにインストールすると同じパッケージが二箇所に存在することになり、トラブルのもとになる。大学PCにインストールしなければならないパッケージ（CRANに登録されていないパッケージ）もある が、そのときは別途アナウンスする。\n\n\nパッケージのインストールには、install.packages() という関数を使う。パッケージをインストールするにはネット接続が必須。 パッケージは1度インストールすれば、Rのバージョンアップを行うまでそのまま使える。同じパッケージを何度もインストールしないように注意！（時間のムダ） 大学PCを使っている場合、以下のコードは実行しない（理由は上に書いたとおり）。\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"systemfonts\")\ninstall.packages(\"shiny\")\ninstall.packages(\"miniUI\")\ninstall.packages(\"DT\")\ninstall.packages(\"patchwork\")\ninstall.packages(\"remotes\")\n\n\n\n\n\n\n\nヒント\n\n\n\n手間を少し減らしたい場合は、\n\npkgs <- c(\"tidyverse\", \n          \"sytemfonts\",\n          \"shiny\",\n          \"miniUI\",\n          \"DT\",\n          \"patchwork\",\n          \"remotes\")\ninstall.packages(pkgs)\n\nのようにすればよい。\n\n\nただし、一部のパッケージは install.packages() 以外の方法でインストールする必要がある。この授業では必要になるたびに説明する。 今日はとりあえず次のコードを実行する（大学PCでは実行しない！)。\n\nremotes::install_github(\"Gedevan-Aleksizde/fontregisterer\", \n                        repos = NULL, \n                        type = \"source\")\n\n\n\n\n\n\n\nヒント\n\n\n\nRで利用可能なパッケージのうち、CRAN (Comprehensive R Archive Network) に登録されているものは、install.packages() でインストールする。\n上でインストールした fontregisterer のように、CRANには登録されていないが GitHub で公開されているものは、remotes::install_github() または devtools::install_github() でインストールすることができる。\n\n\nインストールが完了したら、library() でパッケージを読み込もう。パッケージの読み込みは、R (RStudio) を起動するたびに行う必要がある。つまり、library() はそのパッケージを使う場合には毎回実行する必要がある。また、複数の Rmd で同じパッケージを使う場合には、それぞれの Rmdファイルにlibrary() でパッケージを読み込む命令を書いておく必要がある（Rmd ファイルについては 5章 で説明する）。\n\nlibrary(tidyverse)\n\n図中の日本語が文字化けすることがあるので、OSに合わせてフォントを指定する以下のコードを実行する（RStudio Cloud の場合は回避策が面倒なので省略。Cloudユーザは 英語 [アルファベット] を使うように）。これは、library(tidyverse) の後に、毎回実行することが必要。（Linux ユーザは、自分の環境で使用可能なフォントを指定すること。）\nLinux ユーザ（IPAexフォント が利用可能である場合）は、\n\ntheme_set(theme_gray(base_size = 9,\n                     base_family = \"IPAexGothic\"))\n\nを実行する。\nmacOS ユーザは、\n\nlibrary(fontregisterer)\ntheme_set(theme_gray(base_size = 9,\n                     base_family = \"Hiragino Sans\"))\n\nを実行する。\nWindows ユーザ（大学PCを含む）は、\n\nlibrary(fontregisterer)\ntheme_set(theme_gray(base_size = 9,\n                     base_family = \"Yu Gothic\"))\n\nを実行する。\n\n\n\n\n\n\n備考\n\n\n\n利用可能なフォントは、library(fontregisterer) を実行した後に、自分のOSにあわせて以下のいずれかを実行することで確認できる。\n\n# Linux\nsystemfonts::system_fonts()$family\n\n\n# macOS\nnames(quartzFonts())\n\n\n# Windows\nnames(windowsFonts())\n\n\n\n\n4.1.2 データセットの読み込み\nまず、今回の実習で利用するデータをダウンロードしよう。 準備として、現在利用しているプロジェクト（上で作ったフォルダ）の中に、data という名前のフォルダを作ろう。\n\ndir.create(\"data\")\n\n次にデータセット fake_data_01.csv をダウンロードし、今作った data フォルダの中に保存する。\n\ndownload.file(\n  url = \"http://yukiyanai.github.io/jp/classes/stat2/contents/data/fake_data_01.csv\",\n  destfile = \"data/fake_data_01.csv\")\n\nダウンロードがうまくいかない（あるいは、次の読み込み段階で失敗する）場合は、ファイル (fake_data_01.csv) をここ から手動でダウンロードして、プロジェクト内の data ディレクトリに移動する。\n\n\n\n\n\n\n注意\n\n\n\n毎年、Windows ユーザの中に download.file() がうまくいく者とそうでない者がいる。原因がよくわからない（担当者はWindows を使わない）ので、今回うまくいかない場合は、次回以降も毎回手動でデータをダウンロードしてほしい。\n\n\nこのデータは CSVと呼ばれる形式で保存されているので、readr::read_csv()という関数を使ってこのデータセットを読み込むことができる（他の形式で保存されたデータの使い方は必要に応じて後の授業で解説する）。\nこのデータセットを myd という名前で利用することにしよう（これはデータセットのファイル名を変えるのではなく、R上での呼び名を決めているだけである）。\n\nmyd <- read_csv(\"data/fake_data_01.csv\")\n\n読み込んだデータの中身を確認してみよう。 次のコマンドを打ち込むと、スプレッドシート（Excelの表のようなもの）上にデータが表示される。\n\nView(myd)\n\n確認できたら、スプレッドシートが表示されているタブを閉じる。\n次に、コンソール上に、データセットの最上部または最下部にある数行分だけを表示してみよう。\n\nhead(myd)          # 行数を指定しないと6行分\n\n# A tibble: 6 × 6\n     id gender   age height weight  income\n  <dbl> <chr>  <dbl>  <dbl>  <dbl>   <dbl>\n1     1 male      52   174    63.1 3475810\n2     2 male      33   175.   70.2  457018\n3     3 male      22   175    82.6 1627793\n4     4 male      33   170.   81.8 6070642\n5     5 male      26   167.   51.2 1083052\n6     6 male      37   159.   57.8 2984929\n\ntail(myd, n = 8)   # 最後の8行分\n\n# A tibble: 8 × 6\n     id gender   age height weight   income\n  <dbl> <chr>  <dbl>  <dbl>  <dbl>    <dbl>\n1    93 female    61   159.   46.5  4025250\n2    94 female    60   166.   62.2  6300194\n3    95 female    21   165.   56.3  1339138\n4    96 female    65   161.   46.8  6127136\n5    97 female    45   161.   48.7  1062663\n6    98 female    53   166.   64.2 10154200\n7    99 female    43   158.   48.5  8287163\n8   100 female    48   154.   42    1125390\n\n\nデータセットに含まれる変数名を確認したいときは、\n\nnames(myd)\n\n[1] \"id\"     \"gender\" \"age\"    \"height\" \"weight\" \"income\"\n\n\nとする。\nデータセットに含まれる観測数 (\\(n\\)) と変数の数を知りたいときは、\n\ndim(myd)\n\n[1] 100   6\n\n\nとする。最初の数字が\\(n\\)の数（データセットの行数）、2番目の数字が変数の数（列数）である（RStudio を使うと、右上のウィンドウの”Environment” というタブにこの情報が既に表示されているので、そこで確認してもよい）。\nまた、データセットの確認には、glimpse() も便利である。\n\nglimpse(myd)\n\nRows: 100\nColumns: 6\n$ id     <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n$ gender <chr> \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\",…\n$ age    <dbl> 52, 33, 22, 33, 26, 37, 50, 30, 62, 51, 55, 36, 66, 42, 36, 47,…\n$ height <dbl> 174.0, 175.3, 175.0, 170.1, 167.4, 159.3, 173.3, 162.5, 160.2, …\n$ weight <dbl> 63.1, 70.2, 82.6, 81.8, 51.2, 57.8, 68.6, 47.2, 68.2, 59.4, 66.…\n$ income <dbl> 3475810, 457018, 1627793, 6070642, 1083052, 2984929, 1481061, 1…\n\n\nデータセットに含まれるすべての変数の基本的な統計量を確認したいときは、\n\nsummary(myd)\n\n       id            gender               age            height     \n Min.   :  1.00   Length:100         Min.   :20.00   Min.   :148.0  \n 1st Qu.: 25.75   Class :character   1st Qu.:36.00   1st Qu.:158.1  \n Median : 50.50   Mode  :character   Median :45.00   Median :162.9  \n Mean   : 50.50                      Mean   :45.96   Mean   :163.7  \n 3rd Qu.: 75.25                      3rd Qu.:57.25   3rd Qu.:170.2  \n Max.   :100.00                      Max.   :70.00   Max.   :180.5  \n     weight          income        \n Min.   :28.30   Min.   :  240184  \n 1st Qu.:48.95   1st Qu.: 1343679  \n Median :59.95   Median : 2987818  \n Mean   :59.18   Mean   : 4343425  \n 3rd Qu.:67.33   3rd Qu.: 6072696  \n Max.   :85.60   Max.   :23505035  \n\n\nとする。\n\n4.1.3 基本的な統計量の計算\n基本的な統計量の計算方法を学習しよう。Rにはよく使われる統計量を計算するための関数があらかじめ用意されているので、関数を利用する。Rの関数の基本的な形は、関数名() である。この () の中に何を書くべきかは、関数によって異なる。Rの関数の使い方を身につけるためには、() の中身を適切に指定できるようになることが必要である。() の中身は関数の引数（ひきすう; arguments）と呼ばれる。\n\n\n\n\n\n\n備考\n\n\n\n引数には仮引数 (paramter) と実引数 (argument) という区別があるが、現時点では深入りしないことにする。気になる場合は、この説明 を参照されたい。\n\n\n私たちが利用しているデータセット myd に含まれる height（身長）という変数 (variable) の平均値（算術平均; mean）を求めよう。Rでは、mean(変数名)とすると、平均値が求められる。\nただし、height という変数は myd というデータの一部（1つの変数, 1つの列）なので、それをRに伝える必要がある。データセットの中身の変数を使うときは、$ マークを使って、データセット名$変数名とすればよい。よって、height の平均値は\n\nmean(myd$height)\n\n[1] 163.746\n\n\nである。\n次に、身長の中央値 (median) を求めよう。中央値は median() で求められるので、\n\nmedian(myd$height)\n\n[1] 162.9\n\n\nである。\n続いて、身長の分散 (variance) を求めよう。分散（より正確には、不偏分散）は、var()で求める。したがって、\n\nvar(myd$height)\n\n[1] 59.16574\n\n\nである。\n今度は、標準偏差 (standard deviation) を求めよう。標準偏差は、sd() で計算できるので、\n\nsd(myd$height)\n\n[1] 7.691927\n\n\nである。また、標準偏差は分散の平方根 (square root) なので、sqrt() を使って、\n\nsqrt(var(myd$height))\n\n[1] 7.691927\n\n\nとしても、sd() を使った場合と同じ結果が得られる。\n次に、範囲 (range)を求めよう。最大値は max()、最小値は min() で求められるので、範囲は\n\nmax(myd$height) - min(myd$height)\n\n[1] 32.5\n\n\nである。range() という関数もあるが、この関数の結果は\n\nrange(myd$height)\n\n[1] 148.0 180.5\n\n\nとなり、区間が表示されるので注意が必要である。\n続いて、四分位範囲 (interquartile range; IQR) を求めよう。IQR() を使う。\n\nIQR(myd$height)\n\n[1] 12.075\n\n\nちなみに、第1四分位数すなわち25パーセンタイルは quantile() 関数を使って求めることができる。\n\n(q1 <- quantile(myd$height, prob = 0.25))\n\n  25% \n158.1 \n\n\n同様に第3四分位数すなわち75パーセンタイルは、\n\n(q3 <- quantile(myd$height, prob = 0.75))\n\n    75% \n170.175 \n\n\nである。第3四分位数から第1四分位数を引くと、\n\nq3 - q1\n\n   75% \n12.075 \n\n\nとなり、先ほどIQR()求めた四分位範囲と一致することが確認できる。\nquantile() を使うと、自分の好きなパーセンタイルを求めることができる。 例として、22パーセンタイルと77パーセンタイル、87パーセンタイルを同時に求めてみよう。\n\nquantile(myd$height, prob = c(0.22, 0.77, 0.87))\n\n    22%     77%     87% \n157.678 170.869 172.726 \n\n\nこれを使えば、身長 height の五数要約 (five-number summary) を表示することができる。次のようにすればよい。\n\nquantile(myd$height, prob = c(0, 0.25, 0.5, 0.75, 1))\n\n     0%     25%     50%     75%    100% \n148.000 158.100 162.900 170.175 180.500 \n\n\n五数要約のための関数 fivenum() を使うこともできる。\n\nfivenum(myd$height)\n\n[1] 148.00 158.10 162.90 170.25 180.50\n\n\n（一部の結果が四捨五入されていることを除けば）同じ結果が得られた。\n課題\n\n体重 (weight) について、平均値、中央値、分散、標準偏差、四分位範囲を求めよう。\n所得 (income) について、平均値、中央値、分散、標準偏差、四分位範囲を求めよう。\n\n4.1.4 変数の可視化\n変数の特徴は統計量によってある程度把握することができるが、統計量だけではわかりにくい特徴もある。そこで、データ分析を行う際には、図を作って自分が持っているデータを可視化するという作業が必要かつ重要である。\n今日は、ggplot2パッケージを使って、簡単な図をいくつか作ってみよう。ggplot2は先ほど読み込んだ tidyverse の一部なので、新たに読み込む必要はない。また、ggplot2の詳しい使い方は Topic 5（Web資料の「6. ggplot2入門」）で解説するので、今日はコードの中身まで理解しなくてもよい。\nまず、最も基本的かつよく使う図であるヒストグラム　(histogram) を作ってみよう。 ggplot2では geom_histogram() でヒストグラムを作ることができる。\n例として、身長のヒストグラムを描いてみよう。\n\nhist_h <- ggplot(myd, aes(x = height)) +\n  geom_histogram(color = \"black\")\nplot(hist_h)\n\n\n\n\nこれでとりあえずヒストグラムが描ける。\nこのヒストグラムを元にして、様々なカスタマイズが可能である。例えば、横軸と縦軸のラベル (label) を変えたいときは、次のように labs()を加える。\n\nhist_h2 <- hist_h + \n    labs(x = \"身長 (cm)\", \n         y = \"度数\")\nplot(hist_h2)\n\n\n\n\nバーの色を変えたいときは、geom_histogram() で fill を指定する。 指定可能な色については このページ を参照。\n\nhist_h3 <- ggplot(myd, aes(x = height)) +\n  geom_histogram(color = \"black\", \n                 fill = \"dodgerblue\") +\n  labs(x = \"身長 (cm)\", \n       y = \"度数\")\nplot(hist_h3)\n\n\n\n\nヒストグラムのビン（棒）の幅は、binwidth で指定できる。\n\nhist_h4 <- ggplot(myd, aes(x = height)) +\n  geom_histogram(color = \"black\", \n                 fill = \"royalblue\", \n                 binwidth = 5) +\n  labs(x = \"身長 (cm)\", \n       y = \"度数\")\nplot(hist_h4)\n\n\n\n\nヒストグラムの縦軸を度数 (frequency, count) ではなく確率密度 (probability density) に変えたいときは、y軸に after_stat(density) を指定する。\n\nhist_h5 <- ggplot(myd, aes(x = height, y = after_stat(density))) +\n  geom_histogram(color = \"black\", \n                 fill = \"dodgerblue\", \n                 binwidth = 5) +\n  labs(x = \"身長 (cm)\", \n       y = \"確率密度\")\nprint(hist_h5)\n\n\n\n\n課題\n\n体重 (weight) のヒストグラム（色付き）を作り、日本語でラベルを付けよう。\n所得 (income) のヒストグラム（色付き）を作り、日本語でラベルを付けよう。"
  },
  {
    "objectID": "descriptive-stat.html#sec-2var",
    "href": "descriptive-stat.html#sec-2var",
    "title": "\n4  記述統計\n",
    "section": "\n4.2 2変数の記述統計とデータの可視化",
    "text": "4.2 2変数の記述統計とデータの可視化\n\n4.2.1 2つの量的変数の関係を図示する\n2つの量的変数の関係は、散布図 (scatter plot) で確認する。ここでは、身長 (height) と体重 (weight) の関係を図示してみよう。ggplot2では、geom_point() で散布図ができる。\n\nscat <- ggplot(myd, aes(x = height, y = weight)) +\n  geom_point() +\n  labs(x = \"身長 (cm)\", y = \"体重 (kg)\")\nplot(scat)\n\n\n\n\nこのデータセットに含まれる身長と体重の間には、どのような関係があるだろうか？\n\n4.2.2 2つの量的変数の関係を統計量で示す\n2つの量的変数の関係を表すのにもっともよく使われるのは、相関係数 (correlation coefficient) である。この統計量は、\\(r\\) で表されることが多い。\\(-1 \\leq r \\leq 1\\)となる。\\(a\\)と\\(b\\) という2つの変数があったとき、\\(a\\)が大きくなるほど\\(b\\) も大きくなるという関係があるとき、「\\(a\\)と\\(b\\)には正の相関 (positive correlation) がある」と言い、このとき \\(r > 0\\) である。また、\\(a\\)が大きくなるほど\\(b\\) が小さくなるという関係があるとき、「\\(a\\)と\\(b\\)には負の相関 (negative correlation) がある」と言い、このとき \\(r < 0\\) である。\\(r = 0\\) のとき、「\\(a\\)と\\(b\\)は相関関係がない」と言う。\n正の相関があるとき、\\(r\\)が\\(1\\)に近いほど、その関係は強い。また、負の相関があるとき、\\(r\\)が\\(-1\\)に近いほど、その関係は強い。つまり、相関関係は、相関係数の絶対値が1に近いほど強い。\nRで相関係数を求めるときは、cor()を使う。身長と体重の相関係数は、\n\ncor(myd$height, myd$weight)\n\n[1] 0.7294207\n\n\nである。この2変数にはどんな関係があるだろうか？\n\n4.2.3 散布図と相関係数\n2つの量的な変数の関係を調べるときは、散布図と相関係数の両者を使ったほうがよい。\n散布図だけを使うと、本当は存在しない関係を、誤って見つけてしまうことがある。例えば、本当は相関がない2つの変数の散布図を描いたとき、描かれた点がなんとなく右肩上がりの直線の周りに集まっているように見えてしまうことがある。これは、人間がパタンを見つける能力に優れている（優れ過ぎている？）からだと考えられる。偶然できた壁のシミが人間の顔に見えてしまうことがあるというのも似たような現象である。\n散布図だけに頼ると、存在しないパタンが見えてしまうことがあるので、散布図で発見したパタンが本当にあるかどうか、相関係数を求めて確かめるべきである。\n反対に、相関係数だけに頼るのも危険である。相関係数は、2変数のあらゆる関係を捉えられるわけではない。相関係数が示すのは、2つの変数の直線的な関係だけである。\n例として、\\(x\\) と\\(y\\) という2つの変数を以下のとおり作り、相関係数を計算してみよう。\n\nx <- -10:10\ny <- x ^ 2\ncor(x, y)\n\n[1] -5.470844e-17\n\n\n2変数と\\(x\\)と\\(y\\)の相関係数は（ほぼ）0である。相関係数だけに頼ると、2つの変数の間には関係がないと言う結論が出せそうである。しかし、相関係数が低くても、必ず散布図を描いたほうがよい。散布図を作ってみよう。\n\nnewd <- tibble(x = x, y = y)\nscat2 <- ggplot(newd, aes(x = x, y = y)) +\n  geom_point()\nplot(scat2)\n\n\n\n\nこの図を見て、\\(x\\)と\\(y\\)は無関係と言えるだろうか？\n散布図から明らか（\\(y\\)をどのように作ったかを思い出せばもっと明らかだが）なように、\\(x\\)と\\(y\\)には強い関係がある（\\(y\\)は\\(x\\)の関数である）。しかし、その関係は曲線的 なので、直線的な関係しか捉えられない相関係数は、強い関係を見落としてしまうのである。\n\n\n\n\n\n\n重要\n\n\n\n2つの量的変数の関係を調べるときは、散布図と相関係数の両方を確認する習慣を身につけよう。"
  },
  {
    "objectID": "r-markdown.html",
    "href": "r-markdown.html",
    "title": "\n5  Rマークダウンの使い方\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "r-markdown.html#sec-rmd1",
    "href": "r-markdown.html#sec-rmd1",
    "title": "\n5  Rマークダウンの使い方\n",
    "section": "\n5.1 Rマークダウンファイルを knit してレポートを作る",
    "text": "5.1 Rマークダウンファイルを knit してレポートを作る\nRマークダウンファイルの作り方と書き方は後で説明する。その前に、Rマークダウンファイルを書いた後、それをどうやって他の形式のファイルに出力する（言い換えると、レポートとして提出可能な状態に変換する）方法を説明する。\nRマークダウンファイルをPDF（またはHTML） に出力するために、rmarkdown::render() やknitr::knit() を利用する。これらがインストール済みでない場合はまずインストールする。 既にインストール済みのパッケージをあらためてインストールする必要はない。\n\n# tidyverse, systemfonts, remotes, fontregisterer は前回インストールしたはず\n#install.packages(\"tidyverse\")\n#install.packages(\"systemfonts\")\n#install.packages(\"remotes\")\n#remotes::install_github(\"Gedevan-Aleksizde/fontregisterer\", \n#                        repos = NULL, \n#                        type = \"source\")\ninstall.packages(\"rmarkdown\", dependencies = TRUE) \ninstall.packages(\"knitr\", dependencies = TRUE) \n\n\n5.1.1 RマークダウンファイルをPDFファイルに出力する\nRマークダウンファイルからPDFファイルを作るためにはTeXが必要である。まず、 tinytex をインストールする。\n\n\n\n\n\n\n注意\n\n\n\n大学PCにはインストールしない！\n\n\n\ninstall.packages(\"tinytex\")\n\nTeXを使った経験がなく、パソコンにTeXがインストールされていない場合は、以下のコマンドを実行してTeX環境を整える。それなりに時間がかかるので気長に待とう。\n\n\n\n\n\n\n重要\n\n\n\n既にLaTeX環境が設定済みなら、以下のコードを実行する必要はない。情報演習室のパソコンには TeX Live がインストールされているので、install_tinytex() は実行しない！\n\n\n\n\n\n\n\n\nヒント\n\n\n\n数式や図表を含む論文を書く際には、LaTeX を使うことが多い。LaTeX を利用するためには、TeX Live（macOS の場合は MacTeX でも可）をインストールする（無料）。インストール方法は ココ で説明されている。TeX Live (MacTeX) をインストールするなら、install_tinytex() を実行してはいけない。 実行してしまったが TeX Live に切り替えたいという場合は、tinytex::uninstall_tinytex() を実行して tinytex をアンインストールしてから、TeX Live をインストールしよう。\n\n\n\ntinytex::install_tinytex()\n\n準備ができたら、stat2_sample2022.Rmd を “stat2_sample2022.pdf” に変換してみよう。\nまず、リンク から Rマークダウンファイルをダウンロードする。次に、ダウンロードしたファイルを授業用のプロジェクトのフォルダに移動する。移動できたら、RStudio の右下の “Files” タブでからそのファイルを開こう。開いたら、コード編集画面の上にある “Knit” ボタン（毛糸と棒針のマーク）の右にある三角ボタンを押して、表示されたメニューから “Knit to PDF” を選べばPDFができる。初めて実行するときは、足りないパッケージを自動でインストールするので、時間がかかるかもしれない。\n\n\n\n\n\n\nヒント\n\n\n\nダウンロードしたファイルは通常「ダウンロード (Downloads)」という名前のフォルダに保存されている。 これをプロジェクトのフォルダに移動するためには、macOS ならファインダ（Finder）、Windows なら Explorer（エクスプローラー）と呼ばれるファイル表示アプリを利用してファイルを移動すればよい。ファインダやエクスプローラーを開くのが面倒なら、RStudio 右下の “Files” タブを利用してファイルを移動してもよい。\nLinux や macOS でコマンドラインが使えるなら（RStudio にも “Terminal” タブが用意されている！）、mv で移動することもできる。\n\n\n出力されたPDFファイルは（他のディレクトリを指定しない限り）元のRmdファイルと同じディレクトリ（プロジェクトのフォルダ。ダウンロードしたファイルを移動せずにそのまま開いた場合は「ダウンロード」フォルダ）に保存される。出来上がったPDFファイルをAdobe Readerやskim 等のPDFリーダで開いて確認してみよう。\nうまくいけば stat2_sample2022_success.pdf と同じ（ような）ファイルができるはずである。\n\n5.1.2 R MarkdownファイルをHTMLファイルに出力する\n試しに、stat2_sample2022.Rmd （上と同じファイル）を “stat2_sample2022.html” に変換してみよう。コード編集画面の上にある “Knit” ボタン（毛糸と棒針のマーク）の右にある三角ボタンを押して、表示されたメニューから “Knit to HTML” を選べばHTMLファイルができる。\n出力されたHTMLファイルは（他のディレクトリを指定しない限り）元のRmdファイルと同じディレクトリ（プロジェクトのフォルダ。ダウンロードしたファイルを移動せずにそのまま開いた場合は「ダウンロード」フォルダ）に保存される。出来上がったHTMLファイルをウェブブラウザ（Google Chrome, Firefox, Safari, etc.）で開いて確認してみよう。\nうまくいけば stat2_sample2022_success.html と同じ（ような）ファイルができるはずである。"
  },
  {
    "objectID": "r-markdown.html#sec-rmd2",
    "href": "r-markdown.html#sec-rmd2",
    "title": "\n5  Rマークダウンの使い方\n",
    "section": "\n5.2 Rマークダウンによるレポート作成",
    "text": "5.2 Rマークダウンによるレポート作成\nRマークダウンファイルをPDF（やHTML）に変換する方法がわかったところで、Rマークダウンファイルの書き方を覚えよう。\nRStudio では、上部のメニューから [File] -> [New File] -> [R Markdown…] を選ぶと、新しい R マークダウンファイルを作ることができる。 ファイルを開くことができたら、名前をつけて保存しよう。 このファイルの拡張子は .Rmd にする。\nこのウェブ資料は、.Rmd ファイルではなく .qmd (Quarto マークダウン) ファイルで作られている。Rマークダウンファイルの書き方を .qmd ファイル内で説明すると混乱するので、以降の説明は r-markdown.html に記載する。\nRマークダウンの書き方を説明する上のページ（.html ファイル）の元となったRマークダウンファイルは r-markdown.Rmd である。また、同じファイルをPDFに変換すると、r-markdown.pdf ができる。元の.Rmd ファイルと、それを元に作られた .pdf ファイル、.html ファイルの3つをよく比べてみよう。\nこの授業の課題の作成には、Rマークダウンの利用が必須である。 そこで、今後の授業で使えるテンプレートを配布する。 stat2_template2022.Rmd をダウンロードし、YAML ヘッダやグローバルチャンクオプションをそのまま利用してほしい。"
  },
  {
    "objectID": "intro-to-ggplot2.html",
    "href": "intro-to-ggplot2.html",
    "title": "\n6  ggplot2 入門\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "intro-to-ggplot2.html#sec-prep6",
    "href": "intro-to-ggplot2.html#sec-prep6",
    "title": "\n6  ggplot2 入門\n",
    "section": "\n6.1 準備",
    "text": "6.1 準備\n今回利用するパッケージを読み込もう。ggplot2 は tidyverse に含まれているので、library() で tidyverse を読み込めばよい。パッケージをインストール済みでない場合は、読み込みの前にまずinstall.packages() でインストールする。\n\n#install.packages(\"tidyverse\", dependencies = TRUE)\nlibrary(tidyverse)"
  },
  {
    "objectID": "intro-to-ggplot2.html#sec-dataframe",
    "href": "intro-to-ggplot2.html#sec-dataframe",
    "title": "\n6  ggplot2 入門\n",
    "section": "\n6.2 データフレーム",
    "text": "6.2 データフレーム\nggplot2 で図を作るためには、データフレーム (data frame) と呼ばれる形式のデータが必要である。 そこで、まずデータフレームについて説明する。\n\n6.2.1 CSVデータの読み込み\nCSV形式で保存されたデータセットをもっているなら、readr::read_csv() や read.csv() などでそのデータを読み込めば、データフレームができる。\n\n\n\n\n\n\n備考\n\n\n\nreadr パッケージも tidyverse に含まれているので、tidyverse を読み込み済みならあらためて librar(readr) を実行する必要はない。 このように、tidyverse はデータ分析でよく使うツールをまとめて提供しており、便利である。 詳しくは、『私たちのR』「データハンドリング」 を参照されたい。\n\n\n例として、これまでの授業でも使った fake_data_01.csv を読み込んでみよう。プロジェクト内の data ディレクトリ（フォルダ）に fake_data_01.csv があることを想定している。\n\nmyd <- read_csv(\"data/fake_data_01.csv\")\n\nこれがデータフレームかどうか確かめるために、is.data.frame() を使う。\n\nis.data.frame(myd)\n\n[1] TRUE\n\n\nTRUE （真）という答えが返され、myd がデータフレームであることがわかる。\nデータフレームの中身は、tibble::glimpse() で確認できる。\n\nglimpse(myd)\n\nRows: 100\nColumns: 6\n$ id     <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, …\n$ gender <chr> \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\", \"male\",…\n$ age    <dbl> 52, 33, 22, 33, 26, 37, 50, 30, 62, 51, 55, 36, 66, 42, 36, 47,…\n$ height <dbl> 174.0, 175.3, 175.0, 170.1, 167.4, 159.3, 173.3, 162.5, 160.2, …\n$ weight <dbl> 63.1, 70.2, 82.6, 81.8, 51.2, 57.8, 68.6, 47.2, 68.2, 59.4, 66.…\n$ income <dbl> 3475810, 457018, 1627793, 6070642, 1083052, 2984929, 1481061, 1…\n\n\nid, gender, age, height, weight, income という6つの変数があり、gender が <chr> すなわち文字列 (character) 型で、他の変数はすべて <dbl> すなわち実数 (double [double-precision floating-point]) 型であることがわかる。\nデータフレームの中身を確認する方法は他にもいくつかある。 View() を使うと、表計算ソフトのスプレッドシートと同じように、データを表形式で表示してくれる。 Souce ペインに表示されるので確認が終わったらタブを閉じるようにしよう。 この関数は R Markdown ファイルではなく、Console に直接入力したほうが良い。\n\n\n\n\n\n\nヒント\n\n\n\nView() や help() のように、RStudio でインタラクティブに（マウスを使って）操作することを想定するコマンドは、Console に直接書き込むようにする。また、繰り返し使わないコマンド（例：install.packages() ）も R マークダウンに記録するのではなく、Consoleに書き込もう。\n\n\n\nView(myd)\n\nひとつひとつの変数が列（縦方向の並び）を構成し、観測個体が行（横方向の並び）を構成していることがわかる。 View() の代わりに、RStudio の右下のペインにある Environment タフで、Data という項目に表示されているデータの右端にあるボタンを押して、データを表示することもできる。\nデータフレームの各列の名前（つまり、変数名）を知りたいときは、names() を使う。\n\nnames(myd)\n\n[1] \"id\"     \"gender\" \"age\"    \"height\" \"weight\" \"income\"\n\n\nこれで、どのような名前で変数が記録されているかがわかる。\nこの例では変数が6つしかないので自分で変数の数を数えるのも容易である。しかし、変数の数が多い場合には、自分で数えるのは面倒だ。そのようなときは、ncol() を使う（ncol は the number of columns [列の数] の略である）。\n\nncol(myd)\n\n[1] 6\n\n\nこれで、myd には変数が6つあることがわかる。\nまた、データに含まれる観測個体の数は、nrow() で確かめることができる (the number of rows [行の数] の略である）。\n\nnrow(myd)\n\n[1] 100\n\n\nmyd は100行あることがわかる。\ndim() を使えば、行数と列数を1度に調べることができる。\n\ndim(myd)\n\n[1] 100   6\n\n\n実は、行数と列数は、上でglimpse(myd) を実行したときにも表示されていた。\nデータの先頭の数行を表示して変数の中身を確認したいときは、head() を使う。\n\nhead(myd)\n\n# A tibble: 6 × 6\n     id gender   age height weight  income\n  <dbl> <chr>  <dbl>  <dbl>  <dbl>   <dbl>\n1     1 male      52   174    63.1 3475810\n2     2 male      33   175.   70.2  457018\n3     3 male      22   175    82.6 1627793\n4     4 male      33   170.   81.8 6070642\n5     5 male      26   167.   51.2 1083052\n6     6 male      37   159.   57.8 2984929\n\n\nこのように、デフォルトでは最初の6行が表示される。表示する行数は、自分で指定できる。引数 nを使う。\n\nhead(myd, n = 4)\n\n# A tibble: 4 × 6\n     id gender   age height weight  income\n  <dbl> <chr>  <dbl>  <dbl>  <dbl>   <dbl>\n1     1 male      52   174    63.1 3475810\n2     2 male      33   175.   70.2  457018\n3     3 male      22   175    82.6 1627793\n4     4 male      33   170.   81.8 6070642\n\n\n同様に、データの末尾は tail() で表示できる。\n\ntail(myd, n = 5)\n\n# A tibble: 5 × 6\n     id gender   age height weight   income\n  <dbl> <chr>  <dbl>  <dbl>  <dbl>    <dbl>\n1    96 female    65   161.   46.8  6127136\n2    97 female    45   161.   48.7  1062663\n3    98 female    53   166.   64.2 10154200\n4    99 female    43   158.   48.5  8287163\n5   100 female    48   154.   42    1125390\n\n\nデータの中身をさらに詳しく知りたい場合には、str() (structure) を使う。\n\nstr(myd)\n\nspec_tbl_df [100 × 6] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ id    : num [1:100] 1 2 3 4 5 6 7 8 9 10 ...\n $ gender: chr [1:100] \"male\" \"male\" \"male\" \"male\" ...\n $ age   : num [1:100] 52 33 22 33 26 37 50 30 62 51 ...\n $ height: num [1:100] 174 175 175 170 167 ...\n $ weight: num [1:100] 63.1 70.2 82.6 81.8 51.2 57.8 68.6 47.2 68.2 59.4 ...\n $ income: num [1:100] 3475810 457018 1627793 6070642 1083052 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   id = col_double(),\n  ..   gender = col_character(),\n  ..   age = col_double(),\n  ..   height = col_double(),\n  ..   weight = col_double(),\n  ..   income = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n\n\nこの情報はR初心者にはわかりにくいと思われるので、最初は glimpse() を使った方がいいだろう。\nデータセットをRに読み込んだら、glimpse() をはじめとするさまざまな関数を使って、データの中身を確認する習慣を身につけよう。\n\n6.2.2 データフレームの作成\nデータフレームは、data.frame() を使ってRで作ることもできる。データフレームの代わりにtibble と呼ばれる形式のデータを使うこともできる。tibble は、tibble::tibble() で作れる。\n練習のために、df1という名前のデータフレーム (data.frame) と、df2という名前のtibble を作ってみよう。まず、x とy という2つの変数をもつ df1 を作る。\n\ndf1 <- data.frame(x = 1:100, \n                  y = 100:1)\nis.data.frame(df1)\n\n[1] TRUE\n\n\nこのデータの中身を確認してみよう。\n\nglimpse(df1)\n\nRows: 100\nColumns: 2\n$ x <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 2…\n$ y <int> 100, 99, 98, 97, 96, 95, 94, 93, 92, 91, 90, 89, 88, 87, 86, 85, 84,…\n\n\nx と y という変数があり、それぞれが  すなわち整数 (integer) 型であることがわかる。また、データは100行2列である。\n次に、v1, v2, v3 という3つの変数をもつ df2 を tibble() で作る。rnorm(n, mean, sd) で、平均がmean、標準偏差がsd の正規分布から n 個の乱数を生成することができる（詳しくは、「シミュレーション」の回に説明する）。\n\ndf2 <- tibble(v1 = rnorm(100, mean =  0, sd = 5),\n              v2 = rnorm(100, mean = -4, sd = 5),\n              v3 = rnorm(100, mean =  0, sd = 1))\nis.data.frame(df2)\n\n[1] TRUE\n\n\ndf2 の中身を確認しておこう。\n\nglimpse(df2)\n\nRows: 100\nColumns: 3\n$ v1 <dbl> -0.5257696, -2.6236272, 3.5198054, 1.4040933, 1.2791673, -10.645842…\n$ v2 <dbl> -6.3653747, -1.4941088, -1.7410102, -4.0138387, 0.4014079, -3.46978…\n$ v3 <dbl> 0.15974774, 1.81375308, -0.33244806, 1.08965091, -0.09555577, -0.84…\n\n\nv1, v2, v3 という3つの変数があり、それぞれが  すなわち実数型であることがわかる。このデータフレームは100行3列である。\n\n\n\n\n\n\n備考\n\n\n\n というのは、double precision floating point number type（倍精度浮動小数点数型）のことである。この授業で必要な範囲では、実数 (real number) であると考えて差し支えない。この他に授業で出てくる変数の型は、\n\n: integer（整数型）\n: logical（論理型）\n: character（文字列型）\n: factor（因子型）\n\nそれぞれ登場したときに必要な範囲で説明するが、詳しくは「プログラミング」の授業で勉強してほしい。\n\n\nこのように、data.frame() と tibble() を使って、df1とdf2のという “data.frame” （データフレーム）を作ることができた。基本的にはどちらの方法でデータフレームを作っても良いが、特にdata.frame() のほうを好む理由がなければ、今後は tibble() でデータフレーム (tibble) を作ろう。（tibble を優先する理由の説明は割愛するが、Consoleに直接 df1 [これは data.frame である] と入力して実行した結果と、 同じく df2[これは tibble である] と入力して実行した結果を比べると、tibble のほうが良い理由の1つがわかるだろう。）\n\n6.2.3 組み込みデータ\nRにはあらかじめいくつかの（多くの！）データフレームが用意されている。たとえば、自動車に関するデータセットであるmtcarsというものがある。このデータは、data() で呼び出すことができる。\n\ndata(mtcars)\n\nこれを実行すると、RStudio 右下ペインの Environement タブの中で、Values という項目のところに、mtcars が表示されるはずだ。この中身を確認してみよう。\n\nglimpse(mtcars)\n\nRows: 32\nColumns: 11\n$ mpg  <dbl> 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8,…\n$ cyl  <dbl> 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8,…\n$ disp <dbl> 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 16…\n$ hp   <dbl> 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 180…\n$ drat <dbl> 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92,…\n$ wt   <dbl> 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3.…\n$ qsec <dbl> 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 18…\n$ vs   <dbl> 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,…\n$ am   <dbl> 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,…\n$ gear <dbl> 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3,…\n$ carb <dbl> 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2,…\n\n\n32行11列のデータであることがわかる。この時点で、 Environement タブの中で Data 項目の中に mtcars が移動し、データフレームとして認識されていることがわかる。念のために確認しておこう。\n\nis.data.frame(mtcars)\n\n[1] TRUE\n\n\nこのデータの詳細を確認したければ、次のコマンドで。\n\n\n\n他にどんなデータが利用可能か確認したければ、以下を実行する。\n\ndata()"
  },
  {
    "objectID": "intro-to-ggplot2.html#sec-ggplotbasic",
    "href": "intro-to-ggplot2.html#sec-ggplotbasic",
    "title": "\n6  ggplot2 入門\n",
    "section": "\n6.3 ggplot2の基礎",
    "text": "6.3 ggplot2の基礎\n\n6.3.1 ggplot2 とは何か\nggplot2 は、Rで綺麗な図を作るためのパッケージである。 RStudio のChief Scientist である Hadley Wickham が大学院生時代に開発・公開し、アップデートを重ねてきたものである（Hadley は tidyverse などの重要パッケージ開発の中心人物であり、世界中のRユーザから最も尊敬されている人物だと考えられる。日本の一部のRユーザは彼を「羽鳥先生」と呼ぶ）。\nggplot2 の gg は　Grammar of Graphics（図のための文法） という意味で、一貫した方法で様々な図が作れるように工夫されている。 最初は文法を覚えるのに少し苦労するかもしれない。しかし、一度文法を身につけてしまえば、様々な図を簡単に作れるようになるので、とても便利である。また、デフォルト（既定）の設定でそれなりに綺麗な図が作れるのも魅力である（某表計算ソフトのように、何も考えずに 3D棒グラフのような醜い図を作ってしまうということが防げる）。\nggplot2 についての詳しい説明は、Hadley自身が書いた ggplot2: Elegant Graphics for Data Analysis, 3rd edition. (Springer) で読むことができる（オンラインで無料で公開 されている）。\nまた、チートシート（日本語版; 英語版）が公開されているので、ダウンロードしていつでも見られるようにしておくと、便利である。\n\n\n\n\n\n\nヒント\n\n\n\nこの他にも、さまざまなチートシートが RStudio のウェブサイト で公開されている。 いくつかのチートシートには日本語翻訳もある。作成者と翻訳者の皆さんに感謝。\n\n\n\n6.3.2 ggplot2 パッケージの読み込み\nこのページの冒頭に書いたとおり、ggplot2は tidyverse に含まれているので、library() で tidyverse を読み込めばよい。上で実行したなら、再度実行する必要はない。パッケージをインストール済みでない場合は、読み込みの前にまずinstall.packages() でインストールする。\n\n#install.packages(\"tidyverse\", dependencies = TRUE)\nlibrary(tidyverse)\n\n次に、日本語が正しく表示されるようにするため、theme_set() で使用する文字フォントを指定する。OSによって命令がやや異なるので注意されたい。 以下のチャンクは、どのOSでも動くように適切に場合分けを行う。その際、fontregisterer というパッケージを利用するので、これをあらかじめインストールしておく必要がある。このパッケージのインストール方法については 記述統計 の説明を、パッケージの詳細については 作者による説明 を参照されたい）。 また、以下はあくまで例であり、他のフォントを使用してもよい（各自のパソコンにインストールされているフォントは私にはわからないので、変えたいなら自分で調べること。もちろん、日本語が表示できるフォントが必要）。また、RStudio Cloud を利用している場合は、日本語を表示することができない（一応表示する方法もあるが、ものすごく面倒なので割愛する）ので、諦めて英語を使おう（この授業では、レポートの本文が日本語で図のラベルが英語でも許容する。しかし、本来は日本語のレポートなら図のラベルもすべて日本語にすべきである。あるいは、英語で図を作るなら、本文も英語にすべきである）。\n\n## 図のなかで日本語を使えるようにする\n## フォントの設定はお好みで\n## （Unix/Linux ではIPAexフォントのインストールが必要かも）\nlibrary(fontregisterer)\nif (.Platform$OS.type == \"windows\") { # Windows\n  my_font <- \"Yu Gothic\"\n} else if (capabilities(\"aqua\")) { # macOS\n  my_font <- \"Hiragino Sans\"\n} else { # Unix/Linux\n  my_font <- \"IPAexGothic\"\n}\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))\n\n\n\n\n\n\n\nヒント\n\n\n\nコードチャンクに書かれたコマンドを1つずつ実行するときに使うショートカットは command + reutrn または Ctrl + Enter であることは以前説明した。複数行にわたるコマンドであっても、1つのコマンドであればこの方法で実行できる。しかし、上のコードチャンクのように複数のコマンドが含まれる場合、その方法では一挙に実行することができない。\nコードチャンク全体を一挙に実行するためには、command + shift + return または Ctrl + Shift + Enter というショートカットを利用する。\n\n\n\n6.3.3 ggplot の基本的な使い方\nggplot2::ggplot() を使って図を作る手順は次のとおりである。\n\n作図対象となるデータを ggplot() に入力する\n\n\ndata: データフレームを指定\n\nmapping: どの変数を図のなかでどのように利用するか指定\n\n\n\ngeom_xxx() で図の層を加える（xxx の部分はグラフの種類によって変わる）\nラベル (label) や凡例 (legend) の指定、作図範囲の絞り込み、軸の交換などを行う\n\nplot() で図を表示する\n\n順番にやってみよう。\n\n6.3.3.1 例1：散布図\n上で読み込んだ mtcars は自動車に関するデータである。例として、燃費 (mile per gallon; mpg) と車の重量 (weight; wt) の関係を散布図にしてみよう。\nまず、 作図対象となるデータを指定する。また、作図の対象となる変数を指定する。ここでは、散布図の横軸 xに wt、縦軸yに mpg を指定する。\n\np1_1 <- ggplot(data = mtcars, \n               mapping = aes(x = wt, y = mpg)) \n\n同じことだが、data とmapping は省略して\n\np1_1 <- ggplot(mtcars, aes(x = wt, y = mpg)) \n\nと書くことが多い。\nこの時点で図を表示してみる。\n\nplot(p1_1)\n\n\n\n\n指定した通り、横軸にwt、縦軸にmpgをとった図を描く準備ができているが、グラフ自体はまだない。\nここに、散布図を作るための層 (layer) を加える。図を作るためには、geom_xxx() のように、geom から始まる関数で新たな層 (layer) を加える必要がある。geom とは geometry（形状）のことである。たとえば、ヒストグラム (histogram) を作るときはgeom_histogram() を、箱ひげ図 (box[-and-whisker] plot) を作るときは geom_boxplot() を使う。\n散布図は、geom_point() でできる。\n\np1_2 <- p1_1 + geom_point()\n\nこのように、前に作ったものに + で何かを加えることで、ggplot に新たな要素を追加することができる。この時点で、作った図を表示してみよう。\n\nplot(p1_2)\n\n\n\n\n散布図ができた。\n次に、ラベルをわかりやすいものに変える。labs() で変更する。（注意： RStudio Cloud を使っている場合は日本語不可。日本語を正しく表示するために事前準備が必要。上の説明を参照。）\n\np1_3 <- p1_2 + \n    labs(x = \"重量 (1000 lbs)\", \n         y = \"燃費 (Miles / US gallon)\")\n\n表示してみる。\n\nplot(p1_3)\n\n\n\n\nこれで散布図ができた。\n慣れてきたら、一度にコマンドを書いてもよい。\n\np1 <- ggplot(mtcars, aes(x = wt, y = mpg)) +\n    geom_point() +\n    labs(x = \"重量 (1000 lbs)\", \n         y = \"燃費 (Miles / US gallon)\")\nplot(p1)\n\n\n\n\n\n6.3.3.2 例2：ヒストグラム\n引き続き mtcars を使う。燃費 (mile per gallon; mpg) のヒストグラムを作ってみよう。\nまず、作図対象となるデータを入力する。また、作図対象となる変数を指定する。ヒストグラムは1つの変数を可視化するグラフなので、aes にはxのみ指定する。\n\np2_1 <- ggplot(mtcars, aes(x = mpg)) \n\nこの時点で図を表示してみる。\n\nplot(p2_1)\n\n\n\n\n指定した通り、横軸にmpgをとった図を描く準備ができているが、グラフ自体はまだない。また、縦軸は指定していないので何もない。\nここに、ヒストグラムを作るための層 (layer) を加える。ヒストグラムは、geom_histogram() でできる。\n\np2_2 <- p2_1 + geom_histogram()\n\nこの時点で表示してみよう。\n\nplot(p2_2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nヒストグラム自体はできている。しかし、ビン（ヒストグラムの一つひとつの棒）の幅が狭すぎるので、binwidth で調整する（binwidth を指定しないと、stat_bin() using … というメッセージが表示され、適切な binwidth を設定するよう促される）。ここでは、2.5 mpgごとに1つのビン（ヒストグラムの棒）を作ってみよう。\n\np2_3 <- p2_1 + \n    geom_histogram(binwidth = 2.5)\nplot(p2_3)\n\n\n\n\nビンの境が見えにくいので、ビンの縁に黒色をつけよう。ビンの縁取りは color で指定する。color で指定するのはビンの中身の色ではないので注意しよう。\n\np2_4 <- p2_1 + \n    geom_histogram(binwidth = 2.5, color = \"black\")\nplot(p2_4)\n\n\n\n\nビンの区切りがちょうどいい位置にないので、boundary でビンの境界をどの位置に置きくか指定する。今回はビンの幅が2.5 なので、境界線が\\(5, 7.5, 10, \\dots\\) になるように 5 を指定する。\n\np2_5 <- p2_1 + \n  geom_histogram(binwidth = 2.5, \n                 color = \"black\",\n                 boundary = 5)\nplot(p2_5)\n\n\n\n\n次に、ラベルをわかりやすいものに変える。（注意： RStudio Cloud を使っている場合は日本語不可。）\n\np2_6 <- p2_5 + \n    labs(x = \"燃費 (Miles / US gallon)\", y = \"度数\")\nplot(p2_6)\n\n\n\n\nこれで縦軸が度数 (count, frequency) のヒストグラムができた。\nヒストグラムの縦軸を確率密度 (probability density) に変えたいときは、aes() で y = after_stat(density) を指定する。ついでに、ビンの色をドジャーブルーに変えてみる（必要ではない。Go, Dodgers!)\n\np2_dens <- ggplot(mtcars,\n                  aes(x = mpg, \n                      y = after_stat(density))) +\n    geom_histogram(binwidth = 2.5, \n                   boundary = 5, \n                   color = \"black\", \n                   fill = \"dodgerblue\") +\n    labs(x = \"燃費 (Miles / US gallon)\", \n         y = \"確率密度\")\nplot(p2_dens)    \n\n\n\n\n指定可能な色は、このページ で確認できる。\n\n6.3.3.3 例3：箱ひげ図\nRに用意されている、ダイヤモンドのデータ diamonds を使ってみよう。\n\ndata(diamonds)\nglimpse(diamonds)\n\nRows: 53,940\nColumns: 10\n$ carat   <dbl> 0.23, 0.21, 0.23, 0.29, 0.31, 0.24, 0.24, 0.26, 0.22, 0.23, 0.…\n$ cut     <ord> Ideal, Premium, Good, Premium, Good, Very Good, Very Good, Ver…\n$ color   <ord> E, E, E, I, J, J, I, H, E, H, J, J, F, J, E, E, I, J, J, J, I,…\n$ clarity <ord> SI2, SI1, VS1, VS2, SI2, VVS2, VVS1, SI1, VS2, VS1, SI1, VS1, …\n$ depth   <dbl> 61.5, 59.8, 56.9, 62.4, 63.3, 62.8, 62.3, 61.9, 65.1, 59.4, 64…\n$ table   <dbl> 55, 61, 65, 58, 58, 57, 57, 55, 61, 61, 55, 56, 61, 54, 62, 58…\n$ price   <int> 326, 326, 327, 334, 335, 336, 336, 337, 337, 338, 339, 340, 34…\n$ x       <dbl> 3.95, 3.89, 4.05, 4.20, 4.34, 3.94, 3.95, 4.07, 3.87, 4.00, 4.…\n$ y       <dbl> 3.98, 3.84, 4.07, 4.23, 4.35, 3.96, 3.98, 4.11, 3.78, 4.05, 4.…\n$ z       <dbl> 2.43, 2.31, 2.31, 2.63, 2.75, 2.48, 2.47, 2.53, 2.49, 2.39, 2.…\n\nclass(diamonds)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n詳細については、?diamonds で確認できる。\nダイヤモンドのカットの質 (cut) ごとの 深さ (depth) のばらつきを可視化するため、箱ひげ図 (box[-and-whisker] plot) を作ってみよう。\nまず、データとマッピングを指定する。\n\np3_1 <- ggplot(diamonds, aes(x = cut, y = depth))\nplot(p3_1)\n\n\n\n\n指定通り、横軸に cut、縦軸に depth を可視化する準備ができている。\n次に、geom_boxplot() で箱ひげ図の層を加える。\n\np3_2 <- p3_1 + geom_boxplot() \nplot(p3_2)\n\n\n\n\n軸ラベルを日本語にする (RStudio Cloud 以外)。\n\np3_3 <- p3_2 + labs(x = \"カット\", y = \"深さ\")\nplot(p3_3)\n\n\n\n\nFair, Good なども日本語にすることもできるが、今回は覚えなくて良い（私にはダイヤモンドの知識がまったくないのでよくわからないが、ネットで検索した限りだと、Fair の訳は フェア、Good の訳は グッド、 … で日本語にする意味がなさそう）。一応できるということを見せるために、コードは載せておく（このコードは今は理解しなくてよい）。\n\np3_3a <- diamonds %>% \n    mutate(cut_jp = factor(\n      cut, \n      levels = c(\"Fair\", \"Good\", \"Very Good\", \"Premium\", \"Ideal\"),\n      labels = c(\"フェア\", \"グッド\", \"ベリーグッド\", \n                 \"プレミアム\", \"アイディアル\"))) %>% \n    ggplot(aes(x = cut_jp, y = depth)) +\n    geom_boxplot() +\n    labs(x = \"カット\", y = \"深さ\")\nplot(p3_3a)\n\n\n\n\n箱ひげ図の向きを横向きにしたいときは、作った図に coord_flip() を使えば良い。\n\np3_4 <- p3_3 + coord_flip()\nplot(p3_4)\n\n\n\n\nこのように、coord_flip() は横軸と縦軸を入れ替えてくれる。箱ひげ図以外でも使える。\nまた、aes() の xとy を入れ替えることで、向きを変えることもできる。\n\np4 <- ggplot(diamonds, aes(x = depth, y = cut)) +\n    geom_boxplot() +\n    labs(x = \"カット\", y = \"深さ\")\nplot(p4)\n\n\n\n\nこれらの例からわかるとおり、作図に用いる変数の指定は、aes() で行う。aes とは aesthetics（美感）のことである。この aes() の指定の仕方は作る図によって異なる。したがって、ggplot2 の使い方をマスターするには、geom ごとに異なるaes の使い方を覚える必要がある。覚えるといっても、必ずしも暗記する必要なない。頻繁に使うものは覚えたほうが楽（自然に覚える）が、その他のものについては上で紹介したチートシートやインターネット上にまとめられた情報（たとえば、ココ やココ）で確認すればよい。"
  },
  {
    "objectID": "intro-to-ggplot2.html#sec-savefig",
    "href": "intro-to-ggplot2.html#sec-savefig",
    "title": "\n6  ggplot2 入門\n",
    "section": "\n6.4 作成した図の保存",
    "text": "6.4 作成した図の保存\n作成した図は、PDFファイルやPNGファイルなどの外部ファイルに保存することができる。プロジェクト内に、図を保存するための figs というディレクトリ（フォルダ）を新たに作り、図をその中に保存しよう。\n\ndir.create(\"figs\")\n\n図はPDFとして保存することが望ましい（理由の説明は省略するが、一言で述べれば「ベクター画像」が望ましいから）ので、PDFファイルでの保存方法のみ説明する。\n\n\n\n\n\n\n重要\n\n\n\n図のファイルを作るときは、あらかじめ図のサイズ（幅 [width] と高さ [height]）を決めておくことが重要である。いいかげんなサイズで図を作り、後で拡大・縮小すると、軸ラベルの文字などが伸びたり縮んだりして汚くなるので、スマートではない。\n\n\n基本的には、以下の3つのステップで図を保存する。\n\n図を保存するためのファイルを開く（作る）\n図をファイルに書き込む\nファイルを閉じる\n\nこれら3つのステップはセットで行う。R Markdown を使っている場合は特に注意が必要で、各ステップを1つずつ実行しても図が保存されない。 そこで、3つのステップを1つのコードチャンクの中にまとめて書き、以下のいずれかの方法でチャンク全体を一挙に実行する必要がある。\n\nショートカットを使う\n\n\ncommand + shift + return (macOS)\n\nCtrl + Shift + Enter （どのOSでも）\n\n\nチャンク右上の実行ボタン (Run Current Chunk) をクリックする\n\nPDF形式の図を保存するには、cairo_pdf() という関数を使うのが便利である。 先ほど作ったヒストグラム p2_6 を、PDFファイルに保存しよう。 ファイル名は、hist_eg1.pdf にしよう。図の大きさは、A4用紙の半ページよりやや小さくなるように、幅 (width) を5インチ (127.0mm)、高さ (height) を4インチ (101.6mm) にする。軸ラベルに日本語を使っているので、日本語を表示できるフォントを指定する必要があるが、上で library(tidyverse) を実行した直後に fontregregisterer パッケージを利用して theme_set() で指定したフォント（Linux は IPAexゴシック、macOS は ヒラギノ角ゴシック、Windows は游ゴシック）が使われる。 第1ステップの内容をまとめると、次のようになる（第1ステップだけで実行しない!!!）。\n\ncairo_pdf(file = \"figs/hist_eg1.pdf\",\n          width = 5, height = 4)\n\nfile の figs/ という部分が、figs ディレクトリ（フォルダ）の中にファイルを作ることを指示している。\n第2ステップは、第1ステップの直後に print(p2_6) とすればよい。\n最後に、ファイルを閉じるために、dev.off() を実行する。\n以上をまとめると、次のようになる。R Markdown では、以下のコードチャンクを一挙に実行する必要がある（Rスクリプトでは1行ずつ実行してよい）。\n\ncairo_pdf(file = \"figs/hist_eg1.pdf\",\n          width = 5, height = 4)\nprint(p2_6)\ndev.off()\n\nこれで図 (p2_6) が保存されるはずだ。figsディレクトリの中に、hist_eg1.pdf というPDFファイルができていることを確かめよう。また、PDFファイルを開いて図が保存されていることも確認しよう。\n\n\n\n\n\n\n備考\n\n\n\nmacOS を使っているなら、cairo_pdf() の代わりに quartz() を使うこともできる。quartz() を使う場合は、\n\nquartz(file = \"figs/hist_eg1.pdf\", \n       type = \"pdf\", family = \"HiraginoSans-W3\",\n       width = 5, height = 4)\nprint(p2_6)\ndev.off()\n\nのようにする。"
  },
  {
    "objectID": "intro-to-ggplot2.html#sec-commonfig",
    "href": "intro-to-ggplot2.html#sec-commonfig",
    "title": "\n6  ggplot2 入門\n",
    "section": "\n6.5 よく使う図の作り方",
    "text": "6.5 よく使う図の作り方\nggplotの使い方を身につけるために、統計学でよく使う基本的な図を作ってみよう。\n例として、fake_score.csv という架空のデータを使おう。このデータに含まれる変数は、以下の通りである。\n\nid: 個人識別番号。\nclass: クラス。1組から8組まで。\ngender: 性別。女 (female) か男 (male) か。\nmath: 数学の試験の得点。\nenglish: 英語の試験の得点。\nchemistry: 化学の試験の得点。\n\nまず、データを保存するためのディレクトリを作る。既にプロジェクト内に data ディレクトリがある場合（これまでの実習をすべて実行していれば、既にあるはずである）、このコマンドは実行しなくてよい。\n\ndir.create(\"data\")\n\n次に、データをダウンロードする。以下のコードはWindows では失敗する可能性が高いので、ココを右クリック して対象をファイルに保存する。保存先はプロジェクトフォルダの中の data フォルダにする（ダウンロードした後にファイルを移動してもよい）。\n\ndownload.file(\n  url = \"https://yukiyanai.github.io/jp/classes/stat2/contents/data/fake_score.csv\",\n  destfile = \"data/fake_score.csv\"\n)\n\nデータを読み込む。\n\nmyd <- read_csv(\"data/fake_score.csv\")\n\nデータの中身を確認する。\n\nglimpse(myd)\n\nRows: 400\nColumns: 6\n$ id        <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ class     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ gender    <chr> \"female\", \"female\", \"female\", \"female\", \"female\", \"female\", …\n$ math      <dbl> 100, 43, 80, 52, 63, 45, 74, 54, 59, 74, 65, 41, 71, 75, 75,…\n$ english   <dbl> 68, 59, 67, 60, 72, 59, 69, 66, 72, 73, 77, 52, 69, 65, 57, …\n$ chemistry <dbl> 97, 60, 75, 60, 57, 67, 62, 63, 69, 67, 70, 48, 59, 76, 84, …\n\n\n正しくデータが読み込めたようだ。このデータを使い、作図の方法を学習しよう。\nこの時点でデータが正しく読み込めていない場合は、ウェブブラウザで fake_score.csv をダウンロードし、ダウンロードしたファイルを手動でプロジェクト内のデータフォルダの中に移動してから、以下を実行し直そう。 もう一度データを読み込む。\n\nmyd <- read_csv(\"data/fake_score.csv\")\nglimpse(myd)\n\n\n6.5.1 棒グラフ\n棒グラフ (bar plot) は geom_bar() で作る。まず、クラスごとの人数を棒グラフにしてみよう。 横軸にクラス、縦軸にはクラスの人数を表示する。そのために、次のコマンドを使う。\n\nbar1 <- ggplot(myd, aes(x = class)) +\n    geom_bar() +\n    labs(x = \"クラス\", y = \"人数\")\n\n表示してみよう。\n\nplot(bar1)\n\n\n\n\n各クラスの人数が、等しく50人ずつであることがわかる。\n横軸のクラスの数字1から8のうち、表示されていない数字がある。scale_x_continuous() を使って、すべて表示させよう。既に作った bar1 を基に、新しい図を作る。\n\nbar2 <- bar1 + \n    scale_x_continuous(breaks = 1:8)\n\n表示してみよう。\n\nplot(bar2)\n\n\n\n\nクラスの数字をすべて表示することができた。\n男女の内訳はどうなっているだろうか。男女を色分けして描き、図で確かめよう。 データセットに含まれる gender という変数を使って色分けするために、aes の中で fill を指定する。\n\nbar3 <- ggplot(myd, aes(x = class, fill = gender)) +\n    geom_bar() +\n    labs(x = \"クラス\", y = \"人数\") +\n    scale_x_continuous(breaks = 1:8)\nplot(bar3)\n\n\n\n\n女子の方が多いクラスと男子の方が多いクラスがあるようだ。 凡例 (legend) が英語になっているので、日本語に直そう。\n\nbar4 <- bar3 + \n    scale_fill_brewer(palette = \"Accent\",\n                      name = \"性別\", \n                      labels = c(\"女\", \"男\"))\nplot(bar4)\n\n\n\n\nこの棒グラフでは男女の数の比較が難しいので、男女の棒を並べて描きたい。そのために、position = \"dodge\" を指定する。\n\nbar5 <-  ggplot(myd, aes(x = class, fill = gender)) +\n    geom_bar(position = \"dodge\") +\n    labs(x = \"クラス\", y = \"人数\") + \n    scale_x_continuous(breaks = 1:8) +\n    scale_fill_brewer(palette = \"Set2\",\n                      name = \"性別\", \n                      labels = c(\"女\", \"男\"))\nplot(bar5)\n\n\n\n\nこれで、クラス1からクラス4までは女子が20人で男子が30人だが、残りのクラスでは男女の数が逆転していることがわかる。\n\n6.5.2 ヒストグラム\nヒストグラム (histogram) は、ある変数の分布の仕方を確かめる際に最も便利な図である。 既に説明した通り、ヒストグラムを作るには geom_histogram() を使う。\n\n6.5.2.1 基本的な使い方\nまず、数学の点数をヒストグラムにしてみよう。\n\nhist1 <- ggplot(myd, aes(x = math)) +\n    geom_histogram() +\n    labs(x = \"数学の点数\", y = \"人数\")\nplot(hist1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nこのままだと、ヒストグラムの一つひとつの棒 (bin) の区切りが分かりにくいので、棒の縁に色をつけよう。 既に説明したとおり、縁取りの色はcolor で指定する。このとき、変数によって色を変えるのではなく、自分で設定した色を使うため、aesの外で color を指定する（上での棒グラフの例では、aesの中で fill を指定した）。\n\nhist2 <- ggplot(myd, aes(x = math)) +\n    geom_histogram(color = \"black\") +\n    labs(x = \"数学の点数\", y = \"人数\")\nplot(hist2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n次に棒の幅 (bin width) を変えてみよう。binwidth を指定することで、棒の幅を設定できる。試しに、10点ごとにしてみよう。\n\nhist3 <- ggplot(myd, aes(x = math)) +\n    geom_histogram(color = \"black\", binwidth = 10) +\n    labs(x = \"数学の点数\", y = \"人数\")\nplot(hist3)\n\n\n\n\n\n6.5.2.2 縦軸を確率密度に変える\n上で説明したとおり、y に after_stat(density) を指定することで、縦軸を確率密度 (probability density) に変えることができる。\n\nhist4 <- ggplot(myd, aes(x = math, y = after_stat(density))) +\n    geom_histogram(color = \"black\", binwidth = 10) +\n    labs(x = \"数学の点数\", y = \"確率密度\")\nplot(hist4)\n\n\n\n\n縦軸が確率密度のヒストグラムができた。\n\n6.5.2.3 複数の geom を重ねる\n数学の点数の平均値は、\n\nmean(myd$math)\n\n[1] 55.6\n\n\nである。これを図に書き加えよう。\nまず、geom_vline() で、平均値の位置に縦線を加える。 vlineのv はvertical（垂直）を示す。 geom_vline()で縦線の位置を決めるために、xintercept（x切片、つまり、線が横軸と交わる位置）を指定する。\n\nhist5 <- hist3 + \n    geom_vline(xintercept = mean(myd$math), \n               color = \"red\")\nplot(hist5)\n\n\n\n\n次に、平均値の値を（小数第一位までに丸めて [round] して）書き込む。 日本語を使うので、family でフォントを指定する必要がある。\n\nhist6 <- hist5 + \n    geom_text(aes(x = 70, y = 90, \n                  label = str_c(\"平均値：\", round(mean(myd$math), 1))),\n              color = \"red\", \n              family = my_font)\n\n表示する。\n\nplot(hist6)\n\n\n\n\n\n6.5.2.4 facet でグループを分ける\n数学の点数のヒストグラムを、クラスごとに分けて描いてみよう。そのために、facet_wrap() を使う。\n\nhist7 <- hist3 + \n    facet_wrap(vars(class))\nplot(hist7)\n\n\n\n\nこのように、クラスごとにヒストグラムができる。\n\n6.5.3 箱ひげ図\nヒストグラムは分布の形状を確かめるのに便利だが、上で作った hist7 のように、複数のグループの分布を比較するのには少し不便である。 そこで異なるグループの分布を比較するときによく使われるのが、箱ひげ図 (box[-and-whisker] plot) である。箱ひげ図は、五数要約（最小値、第1四分位数、中央値、第3四分位数、最大値）と外れ値（「1.5 \\(\\times\\) IQRルール」で判定される）を図で表現するものである。\n箱ひげ図は、geom_boxplot() で作る。このとき、aes には x（比較するグループを表す変数）とy（作図の対象となる変数）を指定する（xの代わりに group を使うこともできる）。ここで、class の中身の数字には数値としての意味はなく、単にクラス分けのための記号にすぎないことを gpplotに伝えるために as.factor() を使う（本当はデータ前処理の時点で　id と class は factor にしておくことが望ましいが、今回はこれで妥協する）。既に説明したとおり、横向きにしたいときは、x とy を入れ替えれば良い。\n\nbox1 <- ggplot(myd, aes(x = as.factor(class), y = math)) +\n    geom_boxplot() +\n    labs(x = \"クラス\", y = \"数学の点数\") \nplot(box1)\n\n\n\n\nこれで、グループ間で数学の点数の五数を比較しやすくなった。\n\n6.5.4 バイオリンプロット\n箱ひげ図でグループ間比較がしやすくなったが、ヒストグラムとは異なり、分布の形状がわからなくなってしまった。この不満を解消してくれるのが、バイオリンプロット (violin plot) である。geom_violin() で作る。\n\nvln1 <- ggplot(myd, aes(x = as.factor(class), y = math)) +\n    geom_violin() +\n    labs(x = \"クラス\", y = \"数学の点数\") \nplot(vln1)\n\n\n\n\nこの図は、ヒストグラムを横倒しにしてその概形を滑らかな線で表したものと、それを鏡に写したものが合わさってできている。バイオリンプロットの幅が広い（狭い）ところが、ヒストグラムの山が高い（低い）ところである。\n\n6.5.5 箱ひげ図とバイオリンプロットの重ね描き\nバイオリンプロットは、分布の形状がわからないという箱ひげ図の弱点を克服しているものの、箱ひげ図では一目でわかった中央値や四分位範囲がわからないという弱点がある。両者の長所を活かすため、二つの図を重ねて描いてみよう。\n\nbv1 <- ggplot(myd, aes(x = as.factor(class), y = math)) +\n    geom_boxplot() +\n    geom_violin() +\n    labs(x = \"クラス\", y = \"数学の点数\") \nplot(bv1)\n\n\n\n\nバイロリンプロットが箱ひげ図の線に重なり、箱ひげ図がよく見えない。箱ひげ図をバイオリンプロットの上に（手前に）描いたほうがよさそうだ。ggplotでは、後に加えた要素（層）が上になるので、geom_violin() の後に geom_boxplot() を書く。\n\nbv2 <- ggplot(myd, aes(x = as.factor(class), y = math)) +\n    geom_violin() +\n    geom_boxplot() +\n    labs(x = \"クラス\", y = \"数学の点数\") \nplot(bv2)\n\n\n\n\n今度は、箱がバイオリンの線に重なってしまっている。geom_boxplot() で width を指定し、箱の幅を狭くしてみよう。\n\nbv3 <- ggplot(myd, aes(x = as.factor(class), y = math)) +\n    geom_violin() +\n    geom_boxplot(width = 0.3) +\n    labs(x = \"クラス\", y = \"数学の点数\") \nplot(bv3)\n\n\n\n\nこれで、箱ひげ図とバイロリンプロットが同時に確認できるようになった。しかし、このままでは箱ひげ図が目立たないので、色を変えよう。\n\nbv4 <- ggplot(myd, aes(x = as.factor(class), y = math)) +\n    geom_violin() +\n    geom_boxplot(width = 0.3, fill = \"gray\") +\n    labs(x = \"クラス\", y = \"数学の点数\") \nplot(bv4)\n\n\n\n\nこの図を見れば、数学の点数の分布をクラス間で比較できる。\n\n6.5.6 ビースウォームプロット（蜂群図）\n箱ひげ図とバイオリンプロットで、グループ間の分布を比較できるようになった。しかし、観測値が実際にどの値をとったかはわからない。この問題を克服するために使われるのが、ビースウォームプロット (bee swarm plot) である。\nggplotを使ってビースウォームプロットを描くには、ggbeeswarm というパッケージを導入するのが簡単だ。 まず、インストールする（既にインストール済みなら、このコマンドは実行しなくてよい）。\n\ninstall.packages(\"ggbeeswarm\")\n\nインストールが済んだら、パッケージを読み込む。\n\nlibrary(ggbeeswarm)\n\nビースウォームプロットは、geom_beeswarm()またはgeom_quasirandom() で描く。 これら二つの違いは、点の散らし方である。実際に作って比べてみよう。\n\nbee1 <- ggplot(myd, aes(x = as.factor(class), y = math)) +\n    geom_beeswarm() +\n    labs(x = \"クラス\", y = \"数学の点数\") \nplot(bee1)\n\n\n\n\n\nbee2 <- ggplot(myd, aes(x = as.factor(class), y = math)) +\n    geom_quasirandom() +\n    labs(x = \"クラス\", y = \"数学の点数\") \nplot(bee2)\n\n\n\n\nビースウォームプロットでは、全く同じか近い値をとった観測値が重ならないよう、点を散らして (jittering) くれる。その散らし方が、二つの geom で異なる。\nこれらの図により、分布の中で実際に観測値がどこにあるかが明らかになった。ビースウォームプロットを、箱ひげ図とバイロリンプロットに重ねてみよう。\n\nbee3 <- bv4 + geom_quasirandom()\nplot(bee3)\n\n\n\n\n点のせいで箱ひげ図がの線が見えにくいなら、(1) 点の色を変えるか、(2) 点の透明度を上げてみよう。透明度は alpha で指定する。alpha = 1/3 とすると、点が3つ重なったときに透明度が0（つまり、普通の色）になるなるようになる。\n両方同時にやってみよう。\n\nbee4 <- bv4 + \n    geom_quasirandom(color = \"skyblue\", alpha = 3/5)\nplot(bee4)\n\n\n\n\n男女の点の色を変えてみよう。\n\nbee5 <- bv4 + \n    geom_quasirandom(aes(color = gender),\n                     alpha = 2/3) +\n    scale_color_brewer(palette = \"Dark2\",\n                       name = \"性別\", \n                       labels = c(\"女\", \"男\"))\nplot(bee5)\n\n\n\n\nこれで、分布の形状と五数だけでなく、実際の観測値がどこにあるかまで明らかにできた。\n\n6.5.7 散布図\nここまでは、1つの変数を可視化するグラフを作ってきた。続いて、2変数の関係を可視化してみよう。\n2変数（2つの量的変数）の関係を可視化するための最も基本的な図は散布図 (scatter plot) である。散布図は、geom_point() で作る。散布図のaesには、横軸の変数 x と縦軸の変数 y を指定する。\n数学の点数（横軸）と英語の点数（縦軸）の関係を散布図にしみてよう。\n\nscat1 <- ggplot(myd, aes(x = math, y = english)) +\n    geom_point() +\n    labs(x = \"数学の得点\", y = \"英語の得点\")\nplot(scat1)\n\n\n\n\n英語も数学も100点満点の試験なのに、図が横長になっていて数学の得点の範囲の方が広く見えてしまう。 この点を改善するために、xlim() と ylim() で横軸と縦軸の範囲を指定し、coord_fixed(ratio = 1) で縦横比を1:1にしよう（ratio = 1 はデフォルトなので、単に coord_fixed() でもいいが、比がはっきりわかるようにここでは明示しておく）。\n\nscat2 <- scat1 + \n    xlim(0, 100) + \n    ylim(0, 100) +\n    coord_fixed(ratio = 1)\nplot(scat2)\n\n\n\n\n男女の点を、色 (color) と形 (shape) で区別してみよう。\nまず、色で区別する。\n\nscat3 <- ggplot(myd, \n                aes(x = math,\n                    y = english, \n                    color = gender)) +\n    geom_point() +\n    labs(x = \"数学の得点\", \n         y = \"英語の得点\") +\n    scale_color_discrete(name = \"性別\", \n                         labels = c(\"女\", \"男\")) +\n    xlim(0, 100) +\n    ylim(0, 100) + \n    coord_fixed(ratio = 1)\nplot(scat3)\n\n\n\n\nこれで一応色分けはできたが、色があまり気に入らない。 特に、赤と緑を区別できない人がいると思われるので、scale_color_brewer() で色使い (color paletter) を Accent に変えてみよう。指定できるパレットについては、このページ を参照されたい。\n\nscat3a <- ggplot(myd, \n                 aes(x = math, \n                     y = english, \n                     color = gender)) +\n    geom_point() +\n    labs(x = \"数学の得点\", \n         y = \"英語の得点\") +\n    scale_color_brewer(palette = \"Accent\",\n                       name = \"性別\", \n                       labels = c(\"女\", \"男\")) +\n    xlim(0, 100) + \n    ylim(0, 100) + \n    coord_fixed(ratio = 1)\nplot(scat3a)\n\n\n\n\n色分けができた。試しにもう1つ異なるパレットを作ってみよう。Set1 を使ってみる。\n\nscat3b <- ggplot(myd, \n                 aes(x = math, \n                     y = english, \n                     color = gender)) +\n    geom_point() +\n    labs(x = \"数学の得点\", \n         y = \"英語の得点\") +\n    scale_color_brewer(palette = \"Set1\", \n                       name = \"性別\", \n                       labels = c(\"女\", \"男\")) +\n    xlim(0, 100) + \n    ylim(0, 100) + \n    coord_fixed(ratio = 1)\nplot(scat3b)\n\n\n\n\n「男は青で女は赤」というステレオタイプ（偶然そうなってしまっただけだが）が気にいらないなら、色を逆にしてみよう。パレットに用意された色を使う順番を、direction = -1 で逆順にできる。\n\nscat3c <- ggplot(myd, \n                 aes(x = math, \n                     y = english, \n                     color = gender)) +\n    geom_point() +\n    labs(x = \"数学の得点\", \n         y = \"英語の得点\") +\n    scale_color_brewer(palette = \"Set1\", \n                       direction = -1,\n                       name = \"性別\",\n                       labels = c(\"女\", \"男\")) +\n    xlim(0, 100) + \n    ylim(0, 100) +\n    coord_fixed(ratio = 1)\nplot(scat3c)\n\n\n\n\n次に、形 (shape) で区別する。\n\nscat4 <- ggplot(myd, \n                aes(x = math, \n                    y = english, \n                    shape = gender)) +\n    geom_point() +\n    labs(x = \"数学の得点\", \n         y = \"英語の得点\") +\n    scale_shape_discrete(name = \"性別\", \n                         labels = c(\"女\", \"男\")) +\n    xlim(0, 100) +\n    ylim(0, 100) + \n    coord_fixed(ratio = 1)\nplot(scat4)\n\n\n\n\n最後に、色と形で区別する。\n\nscat5 <- ggplot(myd, \n                aes(x = math,\n                    y = english,\n                    color = gender,\n                    shape = gender)) +\n    geom_point() +\n    labs(x = \"数学の得点\",\n         y = \"英語の得点\") +\n    scale_color_brewer(palette = \"Accent\", \n                       direction = -1,\n                       name = \"性別\", \n                       labels = c(\"女\", \"男\")) +\n    scale_shape_discrete(name = \"性別\", \n                         labels = c(\"女\", \"男\")) +\n    xlim(0, 100) + \n    ylim(0, 100) + \n    coord_fixed(ratio = 1)\nplot(scat5)\n\n\n\n\nこのように、ggplot2を使えば簡単に綺麗な図を作ることができる。\n慣れるまではggplot2での作図を面倒に感じるかもしれないが、慣れてしまえばggplotが手放せなくなるだろう。"
  },
  {
    "objectID": "rng.html",
    "href": "rng.html",
    "title": "\n7  乱数生成\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "rng.html#sec-prep7",
    "href": "rng.html#sec-prep7",
    "title": "\n7  乱数生成\n",
    "section": "\n7.1 準備",
    "text": "7.1 準備\n必要なパッケージを読み込む。\n\nlibrary(tidyverse)\n\n次に、日本語が正しく表示されるようにする。\n\n## 図のなかで日本語を使えるようにする\n## フォントの設定はお好みで\n## （Unix/Linux ではIPAexフォントのインストールが必要かも）\nlibrary(fontregisterer)\nif (.Platform$OS.type == \"windows\") { # Windows\n  my_font <- \"Yu Gothic\"\n} else if (capabilities(\"aqua\")) { # macOS\n  my_font <- \"Hiragino Sans\"\n} else { # Unix/Linux\n  my_font <- \"IPAexGothic\"\n}\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))"
  },
  {
    "objectID": "rng.html#sec-rng",
    "href": "rng.html#sec-rng",
    "title": "\n7  乱数生成\n",
    "section": "\n7.2 乱数の生成",
    "text": "7.2 乱数の生成\nRを使って乱数 (random numbers) を生成しよう。\n\n7.2.1 コイン投げ\n自分で決めた特定の対象から、ランダムにどれかを選びたいときは、sample() 関数を利用する。たとえば、この関数を使ってコイン投げを実行したいときは、\n\ncoin <- c(\"表\", \"裏\")  # コインを定義する\nsample(coin, size = 1)\n\n[1] \"表\"\n\n\nとする。size で何回選ぶか（何回コインを投げるか）を指定している。\nこれを何度か実行してみよう。\n\nsample(coin, size = 1)\n\n[1] \"裏\"\n\nsample(coin, size = 1)\n\n[1] \"裏\"\n\nsample(coin, size = 1)\n\n[1] \"裏\"\n\nsample(coin, size = 1)\n\n[1] \"裏\"\n\nsample(coin, size = 1)\n\n[1] \"裏\"\n\n\n選ぶ回数を変えてみよう。\n\nsample(coin, size = 2)\n\n[1] \"裏\" \"表\"\n\n\nもう一度やってみよう。\n\nsample(coin)\n\n[1] \"裏\" \"表\"\n\n\nさらに、もう一度やってみよう。\n\nsample(coin, size = 2)\n\n[1] \"表\" \"裏\"\n\n\nこれを何度やっても、1回目が表なら2回目は裏、1回目が裏なら2回目が表になる。つまり、2回目のコイン投げはランダムではない。これは、sample() が決められた対象から1つずつ順番に選ぶという作業をしているためである。私たちが定義した coin の中身は「表」と「裏」の2つしかない。この2つから順番に選ぶ作業をすると、1つ目に表（裏）が出れば、2回目に残されているのは裏（表）だけなので、2回目がランダムではなくなってしまう。\n試しに選ぶ回数を3回にしてみよう。\n\nsample(coin, size = 3)\n\nError in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'\n\n\nエラーが出た。選ぶ対象が2つしかないのに3つは選べないのでエラーになる（エラーをよく読むと、そのように書いてある）。\nしたがって、sample() を使ってコイン投げを2回以上行うには、少し工夫が必要になる。sample() は私たちが特に指示をしないと非復元抽出（sampling without replacement）を行う。非復元抽出というのは、1度選んだものは選択肢から外すという選び方である。何度もコイン投げを繰り返すには、復元抽出 (sampling with replacement) を行えばよい。復元抽出では、1度選んだものも選択肢の中に戻す（選択肢として復元する）という選び方である。 sapmle() で復元抽出を実行するために、replace = TRUE という指示を加える。\n\nsample(coin, size = 5, replace = TRUE)\n\n[1] \"裏\" \"表\" \"裏\" \"裏\" \"表\"\n\n\nこれでコイン投げを複数回実行できる。\n試しにコインを10回投げて、その結果を coin10 という名前で保存してみよう。（%>% print()は結果を表示するためにつけているだけなので、結果を表示する必要がないならなくてもよい。）\n\ncoin10 <- sample(coin, size = 10, replace = TRUE) %>% \n  print()\n\n [1] \"裏\" \"表\" \"裏\" \"表\" \"表\" \"裏\" \"裏\" \"裏\" \"表\" \"裏\"\n\n\n10回のうち、表は何回出ただろうか？Rを使って数えてみよう。数えるために、以下の方法をとる。\n\n特定のコイン投げ（1回目, 2回目, \\(\\dots\\), 10回目）が表だったかどうか調べる\n表の回数を数える\n\nRである特定の値（数または文字列）になっているか調べたいときは、== （二重等号）を使う。\n\n\n\n\n\n\n注意\n\n\n\n= [等号1つ] は <- と同じで右側の内容を左側に保存してしまうので注意。\n\n\n「二重等号の左側は右側と同じかどうか」を調べ、同じときは TRUE（真）、異なるときは FALSE（偽）という答えが返ってくる。簡単な例で確認してみよう。\n\na <- 2    # aに2を代入する\na == 2\n\n[1] TRUE\n\na == 3\n\n[1] FALSE\n\na == \"裏\" # 文字列と比べるときは文字列を引用符で囲む\n\n[1] FALSE\n\n\nこれを使って、上で行った10回のコイン投げが表だったかどうか確かめよう。\n\ncoin10 == \"表\"\n\n [1] FALSE  TRUE FALSE  TRUE  TRUE FALSE FALSE FALSE  TRUE FALSE\n\n\nこのように、各回について、表 (TRUE) か裏 (FALSE) かを教えてくれる。\n私たちは表が何回出たかを知りたいので、TRUE の回数を数えればいい。ここでは、10回しか投げていないので、自力で数えることもできるが、数が増えると数えるのは面倒である。そこで、Rを使って数える。Rでは TRUE と FALSE を数として扱うと、TRUE は 1、FALSE は0 とみなされる。したがって、TRUEの数を数えたいなら、上の結果を合計すればよい。合計は sum() で求められるので、次のようにする。\n\nsum(coin10 == \"表\")\n\n[1] 4\n\n\n表は10回中4回だったことがわかる。\n\n7.2.2 サイコロ投げ\n同じ関数を使って、サイコロ (die) 投げを実行してみよう。 まずは、サイコロを定義する。\n\ndie <- 1:6  # 1から6までの整数\n# 以下のような書き方も可能\n# die <- c(1, 2, 3, 4, 5, 6)\n# die <- seq(from = 1, to = 6, by = 1)\n\nこれを復元抽出すれば、サイコロ投げを何度も行える。100回投げてみよう。\n\ndie100 <- sample(die, size = 100, replace = TRUE)\n\n3は何回出ただろうか？\n\nsum(die100 == 3)\n\n[1] 17\n\n\n17回出たことがわかる。\nここまでは、「正しいコイン (a fair coin)」や「正しいサイコロ (a fair die)」を想定してきたが、特定の目が出やすいサイコロ（やコイン）を使うこともできる。「1が出る確率だけ他の目の4倍」というサイコロを1,000回投げてみよう。そのために、prob で各目が出る比率を指定する（確率を指定してもよい）。\n\nunfair1000 <- sample(die, \n                     size = 1000, \n                     replace = TRUE,\n                     prob = c(4, 1, 1, 1, 1, 1))\n\n1が何回出たか確かめてみよう。\n\nsum(unfair1000 == 1)\n\n[1] 436\n\n\n1,000回のうち、436回1の目が出たことがわかる。\nこのように、それぞれの選択肢が選べる確率を自由に設定して実験することができる。\nまた、選ぶ対象も自由に設定できる。たとえば、\n\nsample(c(\"高知工科大\", \"高知県立大\", \"高知大\"), \n       size = 1, \n       replace = TRUE, \n       prob = c(3, 2, 1))\n\n[1] \"高知県立大\"\n\n\nのようなこともできる。\n実習課題 (1)\n\n1から6までの目がある「正しい」サイコロを2個振るという作業を1,000回繰り返し、出た目の合計が9になる回数を数えてみよう。\n「正しくない」コイン（表が出る確率が0.5ではないコイン）を500回投げ、表が出た回数を数えよう。表が出る確率は自由に設定してよい（ただし、0, 0.5, 1 を除く）。"
  },
  {
    "objectID": "rng.html#sec-probdist",
    "href": "rng.html#sec-probdist",
    "title": "\n7  乱数生成\n",
    "section": "\n7.3 確率分布からの乱数生成",
    "text": "7.3 確率分布からの乱数生成\nRでは、代表的な確率分布から乱数を生成することが可能である。基本的には、 r（randomの頭文字）と、分布名の最初の数文字を組み合わせた関数を使う。\n\n7.3.1 一様分布\n一様分布 (uniform distribution) からの乱数生成には、runif() を使う。この関数では、以下の3つの引数（ひきすう）を指定する。\n\n\nn: 生成する乱数の個数（必ず指定する）\n\nmin: 最小値（指定しないと 0 に設定される）\n\nmax: 最大値（指定しないと 1 に設定される）\n\n\n\n\n\n\n\n備考\n\n\n\nrunif()の min = 0や max = 1 などのように、引数を指定しないときに自動的に設定される値を既定値またはデフォルト (default value) と言う。「runif() 関数の min のデフォルトは0である」のような言い方をするので、覚えておこう。\n\n\n時計のように1から12（12は0とも考えらえる）の数字が書いてあるような円盤の上でランダムにルーレットを回すことを考える。そうすると、0から12の間のどの位置にルーレットが止まる確率も等しいと考えられる。このような状況を、最小値が0で最大値が12の（連続な）一様分布（連続一様分布; continuous uniform distribution）で表すことができる。このルーレットを100回使ってみよう。\n\na1 <- runif(n = 100, min = 0, max = 12)\n\n結果をヒストグラムにしてみよう。\n\ndf1 <- tibble(a1)  # 結果をデータフレーム (tibble) に入れる\nh1 <- ggplot(df1, aes(x = a1)) +\n  geom_histogram(binwidth = 1, \n                 boundary = 0,\n                 fill = \"royalblue\", \n                 color = \"black\") +\n  labs(x = \"時計盤上のルーレットからの乱数\", \n       y = \"度数\") +\n  scale_x_continuous(breaks = 0 : 12)  # x軸の目盛を調整\nplot(h1)\n\n\n\n\n乱数の個数を増やしてみよう。\n\na2 <- runif(n = 10000, min = 0, max = 12)\ndf2 <- tibble(a2)\nh2 <- ggplot(df2, aes(x = a2)) +\n  geom_histogram(binwidth = 1, \n                 boundary = 0,\n                 fill = \"royalblue\", \n                 color = \"black\") +\n  labs(x = \"時計盤上のルーレットからの乱数\", \n       y = \"度数\") +\n  scale_x_continuous(breaks = 0 : 12)  # x軸の目盛を調整\nplot(h2)\n\n\n\n\n連続ではない一様分布（離散一様分布; discrete uniform distribution）からの乱数は、上で使った sample() で生成することができる。「正しいサイコロ」投げは、「1から6までの整数の（非連続な）一様分布」である。\n\na3 <- sample(1 : 6, size = 100000, replace = TRUE)\ndf3 <- tibble(a3)\np3 <- ggplot(df3, aes(x = a3)) +\n  geom_bar(width = 0.5) +\n  labs(x = \"出た目\", y = \"回数\") +\n  scale_x_continuous(breaks = 1 : 6)\nplot(p3)\n\n\n\n\n\n7.3.2 二項分布\nコイン投げの結果は、表か裏の2パタン（通常、「成功」と「失敗」と呼ばれる。コイン投げでは、表と裏のどちらを成功と呼んでもよいが、ここでは表を成功、裏を失敗としておく）しかない。また、同じコインを何度か投げることを繰り返すとき、1回1回のコイン投げで表が出る確率は一定であると考えられる。\nこのように、結果が成功と失敗の2種類のみで、成功確率が \\(\\theta\\) で一定（したがって、失敗確率は “\\(1-\\theta\\)” で一定）であるような試行を \\(N\\) 回繰り返したとき、その成功回数の分布を、「試行回数 \\(N\\) で成功確率 \\(\\theta\\) の二項分布 (binomial distribution)」と呼ぶ。\n理論的には、二項分布の平均値（期待値）は \\(N \\theta\\)、分散は \\(N \\theta (1 - \\theta)\\) になる。したがって、標準偏差は \\(\\sqrt{N \\theta (1 - \\theta)}\\) になる。また、最小値は0（1ではないので注意）、最大値は \\(N\\) である。\nたとえば、「試行回数5で成功確率0.3の二項分布」の平均値は\\(5 \\cdot 0.3 = 1.5\\)、分散は \\(5 \\cdot 0.3 (1 - 0.3) = 1.05\\)、標準偏差は \\(\\sqrt{1.05} \\approx 1.02\\) である（「\\(\\approx\\)」は「ほぼ等しい」という意味）。最小値は0、最大値は5である。 この分布は、次の図のような形をしている。\n\n\n\n\n\nsample() を使わずに、Rでコイン投げを実行してみよう。Rで二項分布に従う乱数を生成する関数は、rbinom() である。この関数で指定しなければならない引数（ひきすう）は以下の3つである。\n\n\nn：実験の回数\n\nsize: 試行回数（0以上の（非負の）整数）\n\nprob: 成功確率（コイン投げで表が出る確率。0以上1以下）\n\nたとえば、rbinom(n = 8, size = 10, prob = 0.4 ) とすると、「表が出る確率が0.4のコインを10回投げる」という実験を8回実行する。\n\nrbinom(n = 8, size = 10, prob = 0.4)\n\n[1] 3 5 3 2 3 2 1 4\n\n\n結果として、8つの数字が表示されるが、それぞれの数字が、1回ごとの実験（コインを10回投げる）で表が何回出たかを表している。\n\n\n\n\n\n\n注意\n\n\n\nこの数は乱数 (random numbers)、つまり、Rによってランダムに生み出された数字なので、人によって異なる数字が得られるはずで、このWebページと同じ数字が出るとは限らない。\n\n\n試しにまったく同じ関数をもう一度実行すると、違う数が得られる。\n\nrbinom(n = 8, size = 10, prob = 0.4)\n\n[1] 5 3 6 3 6 5 6 4\n\n\n表が出る確率が0.5のコインを使って、1回のコイン投げ実験を1回だけ実行するには、\n\nrbinom(n = 1, size = 1, prob = 0.5)\n\n[1] 1\n\n\nとする。0と出れば表が0回出た（つまり、裏が出た）ということであり、1ならば表が出たということである。何度か試してみよう。\n\nrbinom(n = 1, size = 1, prob = 0.5)\n\n[1] 0\n\n\n\nrbinom(n = 1, size = 1, prob = 0.5)\n\n[1] 0\n\n\n\nrbinom(n = 1, size = 1, prob = 0.5)\n\n[1] 1\n\n\n\nrbinom(n = 1, size = 1, prob = 0.5)\n\n[1] 1\n\n\n\nrbinom(n = 1, size = 1, prob = 0.5)\n\n[1] 1\n\n\n表が出る確率が0.5のコインを使って、1回のコイン投げ実験を10回まとめて実行するには、次のようにする。\n\nrbinom(n = 10, size = 1, prob = 0.5)\n\n [1] 0 1 0 1 1 1 1 0 1 1\n\n\n実習課題 (2)\n\n3つの引数の値を変えて、様々な条件で二項分布からの乱数生成を試してみよう！\n\n\n\n7.3.3 正規分布\n正規分布 (normal distribution) からの乱数生成には、rnorm() を使う。この関数では、以下の3つの引数（ひきすう）を指定する。\n\n\nn: 生成する乱数の個数（必ず指定する）\n\nmean: 正規分布の平均値（指定しないと 0 に設定される）\n\nsd: 正規分布の標準偏差（指定しないと 1 に設定される）\n\n平均と標準偏差を指定しないと、平均が0で標準偏差が1の正規分布、すなわち標準正規分布からの乱数生成が行われる。\n標準正規分布から100個の乱数を生成してみよう。\n\nb1 <- rnorm(n = 100)\n\n作った乱数をヒストグラムにしてみよう。\n\ndf_n1 <- tibble(b1)\nh_n1 <- ggplot(df_n1, aes(x = b1)) +\n  geom_histogram(color = \"black\", fill = \"dodgerblue\") +\n  labs(x = \"標準正規分布からの乱数\", y = \"度数\")\nplot(h_n1)\n\n\n\n\n正規分布に見えるだろうか？ 乱数の平均値と標準偏差を計算してみよう。\n\nmean(b1)\n\n[1] -0.01004308\n\nsd(b1)\n\n[1] 1.074921\n\n\n元の分布の平均値と標準偏差と比べると、どんなことが言えるだろうか？\n乱数の数を増やして同じことしてみよう。\n\nb2 <- rnorm(n = 10000)\ndf_n2 <- tibble(b2)\nh_n2 <- ggplot(df_n2, aes(x = b2)) +\n  geom_histogram(color = \"black\", fill = \"dodgerblue\") +\n  labs(x = \"標準正規分布からの乱数\", y = \"度数\")\nplot(h_n2)\n\n\n\n\n今度はどうだろうか？\n乱数の平均値と標準偏差を計算してみよう。\n\nmean(b2)\n\n[1] -0.01025195\n\nsd(b2)\n\n[1] 1.007354\n\n\n元の分布の平均値と標準偏差と比べると、どんなことが言えるだろうか？\n実習課題 (3)\n\n平均が10, 標準偏差が4の正規分布から乱数を1,000個生成し、結果をヒストグラムにしてみよう。また、乱数の平均値と標準偏差を計算し、元になった分布と比べてみよう。"
  },
  {
    "objectID": "clt.html",
    "href": "clt.html",
    "title": "\n8  中心極限定理\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "clt.html#sec-prep8",
    "href": "clt.html#sec-prep8",
    "title": "\n8  中心極限定理\n",
    "section": "\n8.1 準備",
    "text": "8.1 準備\n必要なパッケージを読み込む。\n\nlibrary(tidyverse)\n\n次に、日本語が正しく表示されるようにする。\n\n## 図のなかで日本語を使えるようにする\n## フォントの設定はお好みで\n## （Unix/Linux ではIPAexフォントのインストールが必要かも）\nlibrary(fontregisterer)\nif (.Platform$OS.type == \"windows\") { # Windows\n  my_font <- \"Yu Gothic\"\n} else if (capabilities(\"aqua\")) { # macOS\n  my_font <- \"Hiragino Sans\"\n} else { # Unix/Linux\n  my_font <- \"IPAexGothic\"\n}\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))"
  },
  {
    "objectID": "clt.html#sec-clt",
    "href": "clt.html#sec-clt",
    "title": "\n8  中心極限定理\n",
    "section": "\n8.2 中心極限定理",
    "text": "8.2 中心極限定理\n中心極限定理 (Central Limit Theorem)　は、「標本サイズ（サンプルサイズ）が大きくなれば、標本平均は正規分布で近似できる」という定理である（より正確には、「標本サイズを無限大にすると標本平均を標準化したものが標準正規分布に収束する」という定理である）。厳密に理解する（証明する）のはこの授業の範囲を超える（つまり、難しい）。しかし、私たちが統計的推定や検定を行うときに正規分布（特に標準正規分布）ばかり使ってもいいのは、この定理のおかげである。したがって、実際に正規分布ではない分布から正規分布ができるということを理解する必要がある。\nそこで、Rでシミュレーションを実行することを通じて中心極限定理を理解しよう。\n例として、10個のボールが入った袋を考える。ボールにはそれぞれ0から9までの整数が書いてあるとする。この袋から、ランダムに1つボールを選ぶとすると、選んだボールに書かれた数は、0から9までの整数のどれかで、0から9が選ばれる確率は等しく10分の1（0.1）である。図にすると、以下のようになる。\n\n\n\n\n\nつまり、ランダムにボールを1つ選ぶというのは、（離散）一様分布からの乱数生成である。 1つボールを選ぶとき、ボールに書かれている数の平均値（期待値）は、\\((9 - 0) / 2 = 4.5\\) である。\nここで、私たちはボールにどんな数が書かれているか知らない（0から9ではなく、100から109かもしれないし、すべての数が奇数かもしれない）と仮定しよう。この状態で、この袋からボールを引く作業を繰り返し（復元抽出する）、ボールに書かれている数の平均値を当てたい（正解は4.5）。\nもっとも単純な方法は、ボールを \\(n\\) 回引いて、その平均値を使うという方法である。\nまず、ボールを2回だけ引いて平均値を当てるという実験を行ってみよう。この実験をすると、1回目のボールの選び方は10通り、2回目のボールの選び方も10通りあるので、全部で100通りの選び方がある。しかし、2つのボールに書かれている数は0から9までの整数なので、可能な合計値は0から18までの19通りであり、平均値は「合計/2」 なので、平均値も19通りしかない。\n理論的には、次の図のような確率で、それぞれの平均値が得られる。\n\n\n\n\n\nこの図から、この実験を1回だけ行うとき、正解である4.5が選ばれる確率は0.1 であることがわかる。試しに1回やってみよう。\n\nbag <- 0:9  # 袋の中身を定義する\nexp_2 <- sample(bag, size = 2, replace = TRUE)  # 復元抽出\nmean(exp_2)   # 平均値を求める\n\n[1] 4\n\n\n今回は、たまたま4になった。\nでは、この実験を1,000回繰り返すと「それぞれの回での平均値の分布」はどんな形になるだろうか。実際にやってみよう。\nRで同じ作業を繰り返し行う簡単な方法は、for ループを使うことである。for の直後の丸カッコで繰り返し回数を指定し、ループさせる内容を中括弧 { } で囲む。 たとえば、0からスタートして「1を足す」という作業を5回繰り返すには、次のようにする。\nまず、スタート時の数である0を保存する。\n\na <- 0  # a に0を入れる\n\n次に、結果を保存するために、result という名前の入れ物を用意する。NA は「空」の状態を表す（これを欠測値 [missing value] と呼ぶ）。また、 length.out で保存場所が何個分必要か指定する。\n\nresult <- rep(NA, length.out = 5) \n\nこの時点で result の中身を確認してみよう。\n\nresult  # result の中身を確認する\n\n[1] NA NA NA NA NA\n\n\nすべて NA になっている。\nforループを利用して、数を1だけ加える作業を5回繰り返す。\n\nfor (i in 1 : 5) {    # i が1から5までの繰り返し\n  a <- a + 1        # a に1を足す\n  result[i] <- a    # i番目の足し算の結果を result[i] に入れる    \n}\nresult  # resultの中身を確認\n\n[1] 1 2 3 4 5\n\n\nこのループを利用して、ボールを2回引く作業を1,000回繰り返してみよう。\n\nN <- 2                                # 標本サイズ\ntrials <- 1000                        # 実験の繰り返し回数\nsim1 <- rep(NA, length.out = trials)  # 結果の保存容器\nfor (i in 1 : trials) {\n  experiment <- sample(bag, size = N, replace = TRUE)  # 復元抽出\n  sim1[i] <- mean(experiment)         # i 回目の平均値を保存\n}\n\n結果をヒストグラムにしてみよう。\n\ndf_sim1 <- tibble(avg = sim1)\nh_sim1 <- ggplot(df_sim1, aes(x = avg)) +\n  geom_histogram(binwidth = 1, \n                 boundary = 0.5,\n                 color = \"black\") +\n  labs(x = \"2個のボールの平均値\", \n       y = \"度数\") +\n  scale_x_continuous(breaks = 0 : 9)\nplot(h_sim1)\n\n\n\n\nこの分布は正規分布に見えるだろうか？\n次に、サンプルサイズ \\(N\\) を2から5に増やし、同様の実験をしてみよう。\n\nN <- 5                                # サンプルサイズ\ntrials <- 1000                        # 実験の繰り返し回数\nsim2 <- rep(NA, length.out = trials)  # 結果の保存容器\nfor (i in 1:trials) {\n  experiment <- sample(bag, size = N, replace = TRUE)  # 復元抽出\n  sim2[i] <- mean(experiment)         # i 回目の平均値を保存\n}\n\n結果をヒストグラムにしてみよう。\n\ndf_sim2 <- tibble(avg = sim2)\nh_sim2 <- ggplot(df_sim2, aes(x = avg)) +\n  geom_histogram(binwidth = 0.5, \n                 boundary = 0.5,\n                 color = \"black\") +\n  labs(x = \"5個のボールの平均値\", \n       y = \"度数\") +\n  scale_x_continuous(breaks = 0:9)\nplot(h_sim2)\n\n\n\n\nこの分布は正規分布に見えるだろうか？\nサンプルサイズ \\(N\\) を10に増やしてみよう。\n\nN <- 10                              # サンプルサイズ\ntrials <- 1000                       # 実験の繰り返し回数\nsim3 <- rep(NA, length.out = trials) # 結果の保存容器\nfor (i in 1 : trials) {\n  experiment <- sample(bag, size = N, replace = TRUE)  # 復元抽出\n  sim3[i] <- mean(experiment)        # i 回目の平均値を保存\n}\n\n結果をヒストグラムにしてみよう。\n\ndf_sim3 <- tibble(avg = sim3)\nh_sim3 <- ggplot(df_sim3, aes(x = avg)) +\n  geom_histogram(binwidth = 0.5,\n                 color = \"black\") +\n  labs(x = \"10個のボールの平均値\", y = \"度数\")\nplot(h_sim3)\n\n\n\n\nこの分布は正規分布に見えるだろうか？\nサンプルサイズ \\(N\\) を100に増やしてみよう。\n\nN <- 100                             # サンプルサイズ\ntrials <- 1000                       # 実験の繰り返し回数\nsim4 <- rep(NA, length.out = trials) # 結果の保存容器\nfor (i in 1 : trials) {\n  experiment <- sample(bag, size = N, replace = TRUE)  # 復元抽出\n  sim4[i] <- mean(experiment)        # i 回目の平均値を保存\n}\n\n結果をヒストグラムにしてみよう。\n\ndf_sim4 <- tibble(avg = sim4)\nh_sim4 <- ggplot(df_sim4, aes(x = avg)) +\n  geom_histogram(binwidth = 0.125, \n                 color = \"black\") +\n  labs(x = \"100個のボールの平均値\", y = \"度数\")\nplot(h_sim4)\n\n\n\n\nこのように、元の分布は一様分布でも、サンプルサイズ \\(N\\) を増やすと、「平均値の分布」は正規分布に近づく。よって、サンプルサイズ \\(N\\) が十分大きい（大まかな目安は \\(N > 100\\)）とき、正規分布を使って統計的推定や検定を行うことが許される。\n実習課題\n\n\n\\(N=5\\) と \\(N=500\\) のそれぞれの場合について、同様の実験を行ってみよう。"
  },
  {
    "objectID": "intro-to-inference.html",
    "href": "intro-to-inference.html",
    "title": "\n9  統計的推定と仮説検定の基礎\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "intro-to-inference.html#sec-prep9",
    "href": "intro-to-inference.html#sec-prep9",
    "title": "\n9  統計的推定と仮説検定の基礎\n",
    "section": "\n9.1 パッケージの読み込み",
    "text": "9.1 パッケージの読み込み\n今回利用するパッケージを読み込む。\n\nlibrary(tidyverse)\n\n次に、日本語が正しく表示されるようにする。\n\n## 図のなかで日本語を使えるようにする\n## フォントの設定はお好みで\n## （Unix/Linux ではIPAexフォントのインストールが必要かも）\nlibrary(fontregisterer)\nif (.Platform$OS.type == \"windows\") { # Windows\n  my_font <- \"Yu Gothic\"\n} else if (capabilities(\"aqua\")) { # macOS\n  my_font <- \"Hiragino Sans\"\n} else { # Unix/Linux\n  my_font <- \"IPAexGothic\"\n}\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))"
  },
  {
    "objectID": "intro-to-inference.html#sec-example9",
    "href": "intro-to-inference.html#sec-example9",
    "title": "\n9  統計的推定と仮説検定の基礎\n",
    "section": "\n9.2 例題",
    "text": "9.2 例題\n問題： 表が出る確率が0.5のコインを \\(N\\)回投げたところ、10回表が出た。コインを投げた回数\\(N\\)はいくつ？\n\n私たちが観察したこと（データ）：「表が10回」\n私たちが知りたい数（母数, パラメタ, parameter）：\\(N\\)\n\n\n\n\n\n\n\n\n備考\n\n\n\nこの例題は、小島寛之 (2006)『完全独習 統計学入門』（ダイヤモンド社）の第9講からとった。詳細な解説については小島 (2006: 90-106) を参照されたい。"
  },
  {
    "objectID": "intro-to-inference.html#sec-refbinom",
    "href": "intro-to-inference.html#sec-refbinom",
    "title": "\n9  統計的推定と仮説検定の基礎\n",
    "section": "\n9.3 準備：二項分布（復習）",
    "text": "9.3 準備：二項分布（復習）\n前のトピックで学習したとおり、コイン投げの結果は二項分布を利用して考えることができる。\nたとえば、「表が出る確率が0.45のコインを10回投げる」という実験を7回実行するには次のようにする。\n\nrbinom(n = 7, size = 10, prob = 0.45)\n\n[1] 6 5 4 6 5 4 4"
  },
  {
    "objectID": "intro-to-inference.html#sec-test",
    "href": "intro-to-inference.html#sec-test",
    "title": "\n9  統計的推定と仮説検定の基礎\n",
    "section": "\n9.4 統計的仮説検定の基礎",
    "text": "9.4 統計的仮説検定の基礎\n上で出された例題について、以下の2つの仮説を考えよう。\n\n\n仮説 1： \\(N＝16\\)\n\n\n仮説 2： \\(N＝36\\)\n\n\n\n9.4.1 仮説1 (\\(N=16\\)) が正しいと仮定する\n仮説1が正しいとすると、1回のコイン投げ実験はrbinom(n = 1, size = 16, prob = 0.5) で表されるはずである（問題で設定した\\(N\\)は、rbinom()関数では size である。nではないので注意！）。例題では、たまたま10回表が出たということになる。 試してみよう。\n\nrbinom(n = 1, size = 16, prob = 0.5)\n\n[1] 10\n\n\n表は何回出ただろうか？\nもう1度試してみよう。\n\nrbinom(n = 1, size = 16, prob = 0.5)\n\n[1] 6\n\n\n表は何回出ただろうか？\n1回ずつ結果を出すと面倒なので、まとめて10,000回この実験を実施し、結果をresult1という名前で保存してみよう。\n\nresult1 <- rbinom(n = 10000, size = 16, prob = 0.5)\n\n上の関数をRStudio で実行すると、右下（あるいは右上）の “Environment” タブの “Values” という列に result1が表示されるはずである。そして、その横に int [1:10000] と書かれているはずである。これは、result1の中身を示しており、int というのは整数 (integer) のことで、[1:10000] というのは、1個目から10,000個目まで数がある（つまり、「A : B」は「AからBまでの整数」という意味）ことを示している。「コインを16回投げる」という実験を実際に10,000回繰り返し、その結果を手で書いて記録するのはものすごく大変だが、Rを使えば同様の実験をほんの数秒で実施できてしまう。\nこの結果を詳しく検討して見よう。まず、表が出る回数の平均値 (mean) はいくつだろうか。\n\nmean(result1)\n\n[1] 7.9977\n\n\n平均すると 7.9977回表が出たことがわかった。理論値である \\(16 \\cdot 0.5 = 8\\) に近い値である。\n分散 (variance) と標準偏差 (standard deviation) はいくつだろうか。\n\nvar(result1)\n\n[1] 3.998095\n\nsd(result1)\n\n[1] 1.999524\n\n\n分散の理論値は \\(16\\cdot 0.5 (1 - 0.5) = 4\\)、標準偏差の理論値は\\(\\sqrt{4} = 2\\) だから、どちらもほぼ理論値どおりの値である。\nこの実験結果をヒストグラムにしてみよう。 縦軸を確率密度 (probability density) にするために、y = after_stat(density) を指定する。\n\ndf1 <- tibble(x = result1)\nhist1 <- ggplot(df1, aes(x = x, y = after_stat(density))) +\n  geom_histogram(color = \"black\", \n                 fill = \"skyblue\",\n                 binwidth = 1) +\n  labs(x = \"表が出た回数\", \n       y = \"確率密度\",\n       title = \"表が出る確率0.5のコインを16回投げる\")\nplot(hist1)\n\n\n\n\n例題で得られた「表が10回」という結果は、このヒストグラムのどの辺りにあるだろうか。これをgeom_vline()で加えてみよう。\n\nhist2 <- hist1 + \n    geom_vline(xintercept = 10, \n               color = \"tomato\")\nplot(hist2)\n\n\n\n\nこのヒストグラムの形状に注目してみると、なんとなく正規分布に似ているように見える。そこで、先ほど計算した平均値と標準偏差（分散）を利用して、平均が 7.9977で標準偏差が1.9995236の正規分布を、このヒストグラムに重ねて描いてみよう。\n\n# 次の2行の中身は現時点で理解しなくてもよい\ndf2 <- tibble(x = seq(from = 0, to = 16, length.out = 1000)) %>% \n  mutate(y = dnorm(x, mean = mean(result1), sd = sd(result1)))\nhist3 <- hist2 + geom_line(data = df2, aes(x = x, y = y), color = \"darkblue\")\nplot(hist3)\n\n\n\n\nこの図からわかるとおり、二項分布から得られたヒストグラムの形は、正規分布によく似ている（こういう状況を、「正規分布で近似できる」という）。\n私たちが実験で手に入れたデータ (result1) のヒストグラムが正規分布に似ていることがわかったので、正規分布の特徴を（統計学1の内容から）思い出して使ってみよう。正規分布の特徴から、平均\\(\\pm\\) 2標準偏差の間にデータの約95%があるはずである。 したがって、仮説1 (\\(N=16\\)) が正しいとすれば、表が出る回数の95%は、\n\nmean(result1) - 2 * sd(result1)\n\n[1] 3.998653\n\n\nと\n\nmean(result1) + 2 * sd(result1)\n\n[1] 11.99675\n\n\nの間にあるはずだ。\n念のため、正規分布に頼らずに私たの実験結果からも同じことを確かめてみよう。私たちは実験を10,000回繰り返した。実験の結果として得られた10,000個の数を、小さい順に並べ替えてみよう。小さい順の並べ替えは、sort()で行う。\n\nresult1_sorted <- sort(result1)\n\nこの並べ替えたデータのうち、小さい方から2.5%（つまり１番小さい数から250番目に小さい数まで）と大きい方から2.5%（つまり、9751番目に小さい数から10,000番目に小さい数、言い換えると、１番大きい数から250番目に大きい数）を取り除くと、平均に近い95%のデータを残すことができる。つまり、10,000回の実験結果を小さい順に並べ替えたとき、251番目から9750番目までの数が、平均周りの95%になる。\nRで単純な数の集まり（ベクトル, ヴェクタ [vector] と呼ぶ）から特定の位置にあるものを抜き出すときは[] を使う。Aという変数の3番目の要素を取り出したいときはA[3]と書き、5番目から8番目までを取り出したいときは、A[5:8] と書く。\n私たちが知りたいのは、result1_sorted（実験結果を小さい順に並べ替えたもの）の251番目と9750番目である。\n\nresult1_sorted[251]\n\n[1] 4\n\nresult1_sorted[9750]\n\n[1] 12\n\n\nつまり、データの95%は、4 と12 の間にある。これは正規分布を利用して求めた数と（ほぼ）同じである。\n小さい順に並べ替えた後、特定のパーセンテージの位置にある数は、Rのquantile() を使えば、もっと簡単に求められる。私たちが知りたいのは、下から2.5% (0.025) と97.5% (0.975) の位置なので、次のようにする。\n\nquantile(result1, prob = 0.025)\n\n2.5% \n   4 \n\nquantile(result1, prob = 0.975)\n\n97.5% \n   12 \n\n#quantile(result1, prob = c(0.025, 0.975))  # 2つの値を1度に求めたいとき\n\nこのように、わざわざ小さい順に並べ替えたり2.5%と97.5%は何番目の数かを考えたりしなくても、quantile() を使えば簡単に答えが求められる。\nいずれの方法を使っても、仮にコイン投げの回数が16回（仮説1）だとすれば、例題の観測値として得られた「10回」という回数は、平均周りの95%の範囲に含まれている。つまり、「16回コインを投げて10回表が出る」という現象は、特に珍しいわけではない。よって、\\(N=16\\)という仮説を否定するような証拠はないと考えられる。仮説1はとりあえず保留しておこう。\n\n9.4.2 仮説2 (\\(N=36\\)) が正しいと仮定する\n仮説2が正しいとすると、1回のコイン投げ実験はrbinom(n = 1, size = 36, prob = 0.5) で表されるはずである。例題では、たまたま10回表が出たということになる。 試してみよう。\n\nrbinom(n = 1, size = 36, prob = 0.5)\n\n[1] 19\n\n\n表は何回出ただろうか？\nもう1度試してみよう。\n\nrbinom(n = 1, size = 36, prob = 0.5)\n\n[1] 18\n\n\n表は何回出ただろうか？\n先ほどと同様にこの実験をまとめて10,000回実施し、結果をresult2という名前で保存してみよう。\n\nresult2 <- rbinom(n = 10000, size = 36, prob = 0.5)\n\nこの結果を詳しく検討してみよう。 まず、表が出る回数の平均値はいくつだろうか。\n\nmean(result2)\n\n[1] 17.9692\n\n\n平均すると 17.9692回表が出たことがわかった。\n分散と標準偏差はいくつだろうか。\n\nvar(result2)\n\n[1] 8.98255\n\nsd(result2)\n\n[1] 2.99709\n\n\n結果をヒストグラムにしてみよう。\n\ndf3 <- tibble(x = result2)\nhist4 <- ggplot(df3, aes(x = x, y = after_stat(density))) +\n  geom_histogram(color = \"black\", \n                 fill = \"skyblue\", \n                 binwidth = 1) +\n  labs(x = \"表が出た回数\", \n       y = \"確率密度\",\n       title = \"表が出る確率0.5のコインを36回投げる\") +\n  geom_vline(xintercept = 10, \n             color = \"tomato\")\nplot(hist4)\n\n\n\n\n例題で得られた「表が10回」という結果は、このヒストグラムのどの辺りにあるだろうか。\nこのヒストグラムの形状に注目してみると、なんとなく正規分布に似ているように見える。そこで、先ほど計算して平均値と標準偏差（分散）を利用して、平均が 17.9692で標準偏差が2.9970902の正規分布を、このヒストグラムに重ねて描いてみよう。\n\n# 次の2行の中身は現時点で理解しなくてもよい\ndf4 <- tibble(x = seq(from = 0, to = 32, length.out = 1000)) %>% \n  mutate(y = dnorm(x, mean = mean(result2), sd = sd(result2)))\nhist5 <- hist4 + geom_line(data = df4, aes(x = x, y = y), color = \"darkblue\")\nplot(hist5)\n\n\n\n\n先ほどと同様、二項分布から得られたヒストグラムは正規分布によく似ている。\n私たちが実験で手に入れたデータ (result2) のヒストグラムが正規分布に似ていることがわかったので、正規分布の特徴から平均\\(\\pm\\) 2標準偏差の間にデータの約95%があるはずである。 したがって、仮説2 (\\(N=36\\)) が正しいとすれば、表が出る回数の95%は、\n\nmean(result2) - 2 * sd(result2)\n\n[1] 11.97502\n\n\nと\n\nmean(result2) + 2 * sd(result2)\n\n[1] 23.96338\n\n\nの間にあるはずだ。\n念のため、正規分布に頼らずに私たの実験結果からも同じことを確かめてみると\n\nquantile(result2, prob = 0.025)\n\n2.5% \n  12 \n\nquantile(result2, prob = 0.975)\n\n97.5% \n   24 \n\n#quantile(result2, prob = c(0.025, 0.975))  # 1行で求めたいとき\n\nとなり、（ほぼ）同じ結果が得られる。\nいずれの方法を使っても、仮にコイン投げの回数が36回（仮説2）だとすれば、例題の観測値として得られた「10回」という回数は、平均周りの95%の範囲に含まれていない。つまり、「36回コインを投げて10回表が出る」という現象は、とても珍しい現象であり、あまり起こることは期待されない。これは、\\(N=36\\)という仮説を否定するような証拠と考えられるので、\\(N=36\\)という仮説は棄却 (reject) する。"
  },
  {
    "objectID": "intro-to-inference.html#sec-estimation",
    "href": "intro-to-inference.html#sec-estimation",
    "title": "\n9  統計的推定と仮説検定の基礎\n",
    "section": "\n9.5 統計的推定の基礎",
    "text": "9.5 統計的推定の基礎\n仮説検定の方法を使えば、1つひとつの仮説について、その説がおかしいと言える証拠があるかどうか確かめることができる。しかし、理論的に可能な仮説はたくさん存在しており、1つひとつ確かめるのは少し面倒だ。私たちが考えている例題の場合、10以上の整数であれば、どんな数でも可能である（\\(N=36\\) が仮説として妥当でないとわかった時点で、37以上の数は無視できるが）。\nそこで、そもそも \\(N\\) はいくつなのかということ自体を直接考えるのが、統計的推定 (statistical estimation) である。\n\n9.5.1 点推定 (point estimation)\nある特定の分布で、もっとも起こりそうな結果は何だろうか？\n例として、「試行回数5で、成功確率0.4の二項分布」を考えよう。 この分布は以下のような形をしている。\n\n\n\n\n\nこの図をみて、どんな結果がもっとも起こりやすそうだと考えられるだろうか。図からは、成功回数2回がもっとも起こりやすそうだということがわかる。 また、この分布の平均値は、\\(5 \\cdot 0.4 = 2\\) である。\nこれらの知識を利用すると、二項分布では平均値がもっとも起こりやすそうである（自習課題：他の値をパラメタ（母数）にもつ二項分布でもそう言えるか自分で確かめよ）。\nこの知識を利用して私たちの例題について考えてみよう。 私たちは試行回数 \\(N\\) を知りたいが、どんな試行回数であっても、もっとも起こりやすいのは平均値だとする。そうすると、10回表が出たということから、平均値が10になるような二項分布を探せばよいことになる。成功確率は0.5だとわかっているので、この関係を式にすると、 \\[\nN \\cdot 0.5 = 10\n\\] となる。この式を解くと、 \\(N = 20\\) となる。つまり、「試行回数20で成功確率の0.5の二項分布の平均値が10である」ということがわかる。この平均値が私たちのデータに合致するので、私たちは、「\\(N=20\\)」 という推定を行う。このようにして得られた、1つの数をピンポイントで示す推定法を点推定 (point estimation) と呼び、得られた値（20）を点推定値 (point estimate) と呼ぶ。\n私たちの例題の点推定値は20である。\n\n9.5.2 区間推定 (interval estimation)\n上で1つの値を推定したが、私たちが推定を行うとき、その推定にどれくらい自信があるか（より正確には、どれくらい自信がないか）は問題によって違う。推定値が同じ10でも、「絶対10だ」というのと「だいたい10くらいだろう」というのでは、答えの意味は異なる。そこで、この「推定に対する自信のなさ (uncertainty)」を推定の方法に取り込んだのが、区間推定 (interval estimation) と呼ばれる方法である。\nより具体的には、統計的仮説検定で棄却されない仮説の集合を、区間推定に使う。私たちは、\\(N=36\\)という仮説（仮説2）を棄却した。したがって、\\(N=36\\) は区間推定には使わない。他方、\\(N=16\\) という仮説は棄却しなかった（保留した）ので、\\(N=16\\) は区間推定の一部として使う。\\(N=36\\) が仮説として妥当でないことがわかっているので、\\(N=10, 11, \\dots, 35\\) について、仮説が棄却できるかどうか確かめればよい。\nしかし、上の仮説検定で実行したことを何度も何度も繰り返すのは、やや面倒である。そこで、実験のための関数を自分で作ってしまおう。関数の作り方はまだ理解しなくてもいいので、こんなことができるということを体験して欲しい。Rで自分の関数を作るには、function() を使う（つまり、「関数」という名前の関数で関数を作る）。\n\nbin_exp <- function(h, trials = 10000) {\n  # h: 仮説 (hypothesis) N = h を検証する\n  # trials: 実験の繰り返し回数、既定（デフォルト）値は10,000\n  res <- rbinom(n = trials, size = h, prob = 0.5)\n  return(quantile(res, prob = c(0.025, 0.975)))\n}\n\n上のコマンドは関数を定義しただけなので、実行しても何も起きない。ただし、RStudio では右下（または右上）の “Environment” タブの中に、“Functions（関数）” という項目が追加され、そこに定義した bin_exp が表示されているはずである。\nこの関数を使ってみよう。先ほど試した仮説1 (\\(N=16\\)) を検証するには、次のようにする。\n\nbin_exp(16)\n\n 2.5% 97.5% \n    4    12 \n\n\n先ほどと（ほぼ）同じ結果が得られた。データである10はこの2つの数値の間にあるので、仮説1は保留する。\n実験の繰り返し回数を変更し、5000回にすると、\n\nbin_exp(16, trials = 5000)\n\n 2.5% 97.5% \n    4    12 \n\n\nとなる。\n同様に、仮説2 (\\(N=36\\)) は、\n\nbin_exp(36)\n\n 2.5% 97.5% \n   12    24 \n\n\nとなり、データである10はこの2つの数値の間にはないので、仮説2を棄却する。\nこの関数を使えば比較的簡単に10以上、35以下のすべての数について仮説を棄却すべきかどうか確かめられる。1つ1つの値を順番に検証してもいいが、一気に実行するには次のようにする。\n\nset.seed(2019-05-10)  # 乱数の種を指定\nx <- 10 : 35          # 10から35までの整数の数列を作り、xという名前で保存する\nnames(x) <- 10 : 35\nsapply(x, bin_exp)    # xの要素をすべて bin_exp に適用 (apply) する\n\n      10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33\n2.5%   2  2  3  3  3  4  4  5  5  5  6  6  6  7  7  8  8  9  9  9 10 10 11 11\n97.5%  8  9  9 10 11 11 12 12 13 14 14 15 15 16 17 17 18 19 19 20 20 21 21 22\n      34 35\n2.5%  11 12\n97.5% 23 23\n\n\nsapply() の意味を理解するのが難しければ、for ループを使ってもよい。\n\nset.seed(2019-05-10)     # 乱数の種を指定\nfor (x in 10 : 35) {\n  res <- bin_exp(x)\n  cat(x, \":\", res, \"\\n\") # 結果を表示するためのコード\n}\n\n10 : 2 8 \n11 : 2 9 \n12 : 3 9 \n13 : 3 10 \n14 : 3 11 \n15 : 4 11 \n16 : 4 12 \n17 : 5 12 \n18 : 5 13 \n19 : 5 14 \n20 : 6 14 \n21 : 6 15 \n22 : 6 15 \n23 : 7 16 \n24 : 7 17 \n25 : 8 17 \n26 : 8 18 \n27 : 9 19 \n28 : 9 19 \n29 : 9 20 \n30 : 10 20 \n31 : 10 21 \n32 : 11 21 \n33 : 11 22 \n34 : 11 23 \n35 : 12 23 \n\n\n\\(N\\)が10から12の間または32以上では、データである10が2つの数値の間にないことがわかるので、これらの仮説は棄却する。よって、\\(N \\in [13, 31]\\) すなわち \\(13 \\leq N \\leq 31\\) （\\(N\\)は整数）と答えるのが、区間推定である。"
  },
  {
    "objectID": "pop-n-sample.html",
    "href": "pop-n-sample.html",
    "title": "\n10  母集団と標本をシミュレーションで理解する\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "pop-n-sample.html#sec-prep10",
    "href": "pop-n-sample.html#sec-prep10",
    "title": "\n10  母集団と標本をシミュレーションで理解する\n",
    "section": "\n10.1 準備",
    "text": "10.1 準備\n必要なパッケージを読み込む。\n\nlibrary(tidyverse)\n\n次に、日本語が正しく表示されるようにする。\n\n## 図のなかで日本語を使えるようにする\n## フォントの設定はお好みで\n## （Unix/Linux ではIPAexフォントのインストールが必要かも）\nlibrary(fontregisterer)\nif (.Platform$OS.type == \"windows\") { # Windows\n  my_font <- \"Yu Gothic\"\n} else if (capabilities(\"aqua\")) { # macOS\n  my_font <- \"Hiragino Sans\"\n} else { # Unix/Linux\n  my_font <- \"IPAexGothic\"\n}\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))"
  },
  {
    "objectID": "pop-n-sample.html#sec-simpopnsample",
    "href": "pop-n-sample.html#sec-simpopnsample",
    "title": "\n10  母集団と標本をシミュレーションで理解する\n",
    "section": "\n10.2 母集団と標本のシミュレーション",
    "text": "10.2 母集団と標本のシミュレーション\n\n10.2.1 母集団を用意する\n例として、女性4,600人、男性5,400人から成る母集団を考える。合計10,000人で、女性比率が0.46、男性比率は0.54である。これらは母集団の比率なので、母比率と呼ばれる。\nこの母集団 (population) をRで定義しよう。\n\npop <- rep(c(\"female\", \"male\"), c(4600, 5400))\n\n総人口を確認する。\n\nlength(pop)\n\n[1] 10000\n\n\n男女の数を確認する。\n\ntable(pop)\n\npop\nfemale   male \n  4600   5400 \n\n\n例題どおりの母集団が定義できた。\nここで、私たちは母比率を知らないと仮定しよう。 正しい母比率を調べるもっとも単純な方法は、1万人全員の性別を調べることである。しかし、1万人を調査するのは大変なので、1万人から100人だけを無作為に（ランダムに）選び、100人の性別を調べ、その結果を利用して母比率を推定することにする。\n\n10.2.2 母集団から100人をランダムに選ぶ\n上で定義した母集団から、ランダムに100人を抜き出してみよう。\nsample() でランダムに100人抽出すればよい。同じ人物を2度以上抜き出すことがないよう、replace = FALSE で非復元抽出を指定する。また、標本サイズ \\(N\\) は繰り返し使うので、最初に定義しておく。\n\nN <- 100\nsample_1 <- sample(pop, size = N, replace = FALSE)\n\n取り出した\\(N=100\\)のサンプルで、男女の比率を調べてみよう。\n\ntable(sample_1) / N\n\nsample_1\nfemale   male \n  0.56   0.44 \n\n\nこの比率は標本（サンプル）の比率なので、標本比率と呼ばれる。 女性比率だけを調べる（女性比率がわかれば男性比率もわかるので）には、\n\nsum(sample_1 == \"female\") / N\n\n[1] 0.56\n\n\nまたは、\n\nmean(sample_1 == \"female\")\n\n[1] 0.56\n\n\nとすればよい。\nもう一度、別の100人で調べてみよう（先ほどと同じ人物が選ばれる可能性はある）。\n\nsample_2 <- sample(pop, size = N, replace = FALSE)\nmean(sample_2 == \"female\")\n\n[1] 0.51\n\n\nもう一度、別の100人で調べてみよう（先ほどと同じ人物が選ばれる可能性はある）。\n\nsample_3 <- sample(pop, size = N, replace = FALSE)\nmean(sample_3 == \"female\")\n\n[1] 0.46\n\n\nこのように、毎回異なる標本比率が得られる。標本から得られる統計量は、母数（この例題の場合は母比率）と必ずしも一致しないし、同じ方法を何度も繰り返すと異なる値が得られる。\n1万人から100人を選ぶ方法は \\(6.5 \\times 10^{241}\\) 通りあるので、全部の組み合わせを調べるのは不可能である。そこで、Rを使って10,000通りだけ調べてみよう。\nまず、1万個の結果（女性の標本比率）を保存する容器（ベクトル, vector）を用意する。\n\nres_1 <- rep(NA, 1e4) \n\nNA は欠測値（値がないこと）を表す。まだ結果を得ていないので、欠測値が1万個ある「空の」容器を用意した。\n\n\n\n\n\n\nヒント\n\n\n\n1e4 というのは、\\(1 \\times 10^4\\) すなわち 10000 のことである。 この例のように、コンピュータでは桁が大きい数を e （プログラムによっては大文字の E）を用いて表すので覚えておこう。この e は自然対数の底（ネイピア数）ではないので注意。 Rでのネイピア数は exp(1) である。\n\n\n確認のため、最初の10個分だけ表示してみよう。\n\nres_1[1:10]\n\n [1] NA NA NA NA NA NA NA NA NA NA\n\n\nすべて NA である。\n次に、forループ を使って標本抽出（サンプリング）と母比率の計算を1万回実行する。\\(i\\)番目の結果は、res_1 の \\(i\\)番目の値として保存する。res_1の\\(i\\) 番目は res_1[i] と書く。\n\nfor (i in 1 : 1e4) {\n  x <- sample(pop, size = N, replace = FALSE)\n  res_1[i] <- mean(x == \"female\")\n}\n\nこれで、結果が res_1 に保存された。確認のため、最初の10個の結果を表示してみよう。\n\nres_1[1 : 10]\n\n [1] 0.44 0.51 0.43 0.53 0.54 0.48 0.43 0.52 0.56 0.41\n\n\nさきほどは NA だったところに数値（標本比率）が保存されたことがわかる。\n結果をヒストグラムにしてみよう。私たちは母比率を知っているので、母比率である0.46を赤い線で示す。\n\ndf1 <- tibble(sample = res_1)\nhist1 <- ggplot(df1, aes(x = sample)) +\n  geom_histogram(binwidth = 0.02, \n                 color = \"black\", \n                 fill = \"dodgerblue\") +\n  geom_vline(xintercept = 0.46, \n             color = \"red\", \n             size = 1.5) +\n  labs(x = \"女性の標本比率\", \n       y = \"度数\")\nplot(hist1)\n\n\n\n\nヒストグラムを見ると、一つひとつの標本比率は母比率よりも大きかったり、母比率よりも小さかったりすることがわかる。しかし、平均すると母比率に近い値を得ることができそうだ。\nこのヒストグラムからわかる通り、統計量は分布する（つまり、標本ごとにばらばらの値をとる）。このような標本ごとの分布を 標本分布 (sampling distribution) と呼ぶ（標本分布については、次のトピックで説明する）。\n\n10.2.3 標準誤差 (standard error; SE)\n標準誤差は、標本分布に現れる標準偏差（統計量のばらつき）なので、このシミュレーションで得られる標準誤差は、\n\nsd(res_1)\n\n[1] 0.04979728\n\n\nである。\n詳しくは次のトピックで説明するが、理論的には \\[\\mbox{SE} = \\frac{母標準偏差}{\\sqrt{標本サイズ}}\\] なので、\n\npi <- 0.46\npop_sd <- sqrt(pi * (1 - pi))\npop_sd / sqrt(100)\n\n[1] 0.04983974\n\n\nになるはずであるが、シミュレーションなので実行する度に値が変わり、理論値に近づいたり離れたりする。"
  },
  {
    "objectID": "pop-n-sample.html#sec-ex10",
    "href": "pop-n-sample.html#sec-ex10",
    "title": "\n10  母集団と標本をシミュレーションで理解する\n",
    "section": "\n10.3 実習課題",
    "text": "10.3 実習課題\n標本サイズ \\(N\\) の値を変えて (N = 25, N = 400)、同様のシミュレーションを実行してみよう。\n\nヒストグラムはどのように変化するだろうか。\n標準誤差はどのように変化するだろうか。"
  },
  {
    "objectID": "lawoflargenumbers.html",
    "href": "lawoflargenumbers.html",
    "title": "\n11  シミュレーションを利用して大数の法則を理解する\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "lawoflargenumbers.html#sec-prep11",
    "href": "lawoflargenumbers.html#sec-prep11",
    "title": "\n11  シミュレーションを利用して大数の法則を理解する\n",
    "section": "\n11.1 準備",
    "text": "11.1 準備\n必要なパッケージを読み込む。\n\nlibrary(tidyverse)\n\n次に、日本語が正しく表示されるようにする。\n\n## 図のなかで日本語を使えるようにする\n## フォントの設定はお好みで\n## （Unix/Linux ではIPAexフォントのインストールが必要かも）\nlibrary(fontregisterer)\nif (.Platform$OS.type == \"windows\") { # Windows\n  my_font <- \"Yu Gothic\"\n} else if (capabilities(\"aqua\")) { # macOS\n  my_font <- \"Hiragino Sans\"\n} else { # Unix/Linux\n  my_font <- \"IPAexGothic\"\n}\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))"
  },
  {
    "objectID": "lawoflargenumbers.html#sec-lln",
    "href": "lawoflargenumbers.html#sec-lln",
    "title": "\n11  シミュレーションを利用して大数の法則を理解する\n",
    "section": "\n11.2 大数の法則 (Law of Large Numbers; LLN)",
    "text": "11.2 大数の法則 (Law of Large Numbers; LLN)\n「公正な（表が出る確率と裏が出る確率が等しい）」コインを使って、大数の法則のシミュレーションを行う。\nコイン投げは、\n\ncoin <- c(\"表\", \"裏\")\nsample(coin, size = 1)\n\n[1] \"表\"\n\n\nで実行する。\nこれを1回だけ実行したとき、表の比率は、\n\n表が出れば1\n裏が出れば0\n\nである。コイン投げの回数が少ないと、表が出る比率は真の比率である0.5に近くなるとは限らない。\nしかし、大数の法則によると、コインを投げる回数を十分大きくすると、表の比率は0.5 に近づくはずである。Rを使って確かめてみよう。\nまず、コインを投げる回数 n_flips を決める。500に設定してみよう。\n\nn_flips <- 500\n\n次に、結果を記録する容器（ベクトル）を用意する。\n\nratio_1 <- rep(NA, n_flips)\n\n準備ができたので、n_flips回コイン投げを行い、それぞれのコイン投げが終わった時点での表の比率を計算する。\n\ncoins_1 <- sample(coin, size = n_flips, replace = TRUE)\nfor (i in 1 : n_flips) {\n  n_head <- sum(coins_1[1:i] == \"表\") # i回目までに何回表が出たか数える\n  ratio_1[i] <- n_head / i            # i回目までの表の比率を計算して記録する\n}\n\nこれで、ratio_1 に結果が記録された。確認のため、最初の5回分を表示してみよう。\n\nratio_1[1 : 5]\n\n[1] 1.0000000 0.5000000 0.6666667 0.5000000 0.6000000\n\n\n結果を図示しよう。\n\ndf2 <- tibble(N = 1 : n_flips,\n              ratio_1 = ratio_1)\np1 <- ggplot(df2, aes(x = N, y = ratio_1)) +\n  geom_hline(yintercept = 0.5, \n             linetype = \"dashed\") +\n  geom_line(color = \"dodgerblue\") +\n  labs(x = \"試行回数\", \n       y = \"表の割合\")  \nplot(p1)\n\n\n\n\n比率が少しずつ0.5に近づいていくことがわかる。\nもう1度やってみよう。\n\nratio_2 <- rep(NA, n_flips)\ncoins_2 <- sample(coin, size = n_flips, replace = TRUE)\nfor (i in 1 : n_flips) {\n  n_head <- sum(coins_2[1:i] == \"表\") # i回目までに何回表が出たか数える\n  ratio_2[i] <- n_head / i            # i回目までの表の比率を計算して記録する\n}\ndf2$ratio_2 <- ratio_2\np2 <- ggplot(df2, aes(x = N, y = ratio_2)) +\n  geom_hline(yintercept = 0.5,\n             linetype = \"dashed\") +\n  geom_line(color = \"dodgerblue\") +\n  labs(x = \"試行回数\", \n       y = \"表の割合\")  \nplot(p2)\n\n\n\n\nもう1度やってみよう。\n\nratio_3 <- rep(NA, n_flips)\ncoins_3 <- sample(coin, size = n_flips, replace = TRUE)\nfor (i in 1 : n_flips) {\n  n_head <- sum(coins_3[1:i] == \"表\") # i回目までに何回表が出たか数える\n  ratio_3[i] <- n_head / i            # i回目までの表の比率を計算して記録する\n}\ndf2$ratio_3 <- ratio_3\np3 <- ggplot(df2, aes(x = N, y = ratio_3)) +\n  geom_hline(yintercept = 0.5, \n             linetype = \"dashed\") +\n  geom_line(color = \"dodgerblue\") +\n  labs(x = \"試行回数\", \n       y = \"表の割合\")  \nplot(p3)\n\n\n\n\nシミュレーションを実行する度に、異なる軌跡を描きながら、比率が0.5に近づいていく様子が見てとれる。"
  },
  {
    "objectID": "lawoflargenumbers.html#sec-ex11",
    "href": "lawoflargenumbers.html#sec-ex11",
    "title": "\n11  シミュレーションを利用して大数の法則を理解する\n",
    "section": "\n11.3 実習課題",
    "text": "11.3 実習課題\n\nコイン投げの回数 n_flips を減らしたり増やしたりして、シミュレーションを行ってみよう。\n表が出る確率 \\(\\theta = 0.8\\), 裏が出る確率 \\(1-\\theta = 0.2\\)として、同様のシミュレーションを実行してみよう。"
  },
  {
    "objectID": "sampling-distribution.html",
    "href": "sampling-distribution.html",
    "title": "\n12  標本分布を理解する\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "sampling-distribution.html#sec-prep12",
    "href": "sampling-distribution.html#sec-prep12",
    "title": "\n12  標本分布を理解する\n",
    "section": "\n12.1 準備",
    "text": "12.1 準備\n必要なパッケージを読み込む。\n\nlibrary(tidyverse)\n\n次に、日本語が正しく表示されるようにする。\n\n## 図のなかで日本語を使えるようにする\n## フォントの設定はお好みで\n## （Unix/Linux ではIPAexフォントのインストールが必要かも）\nlibrary(fontregisterer)\nif (.Platform$OS.type == \"windows\") { # Windows\n  my_font <- \"Yu Gothic\"\n} else if (capabilities(\"aqua\")) { # macOS\n  my_font <- \"Hiragino Sans\"\n} else { # Unix/Linux\n  my_font <- \"IPAexGothic\"\n}\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))"
  },
  {
    "objectID": "sampling-distribution.html#sec-simsd",
    "href": "sampling-distribution.html#sec-simsd",
    "title": "\n12  標本分布を理解する\n",
    "section": "\n12.2 標本分布のシミュレーション",
    "text": "12.2 標本分布のシミュレーション\n\n12.2.1 シミュレーション問題の設定\n母集団（成人男性全体）では、平均身長が170cm、身長の標準偏差が5.5cm であり、身長は正規分布に従うことを知っているとする。\n\nmu <- 170     # 母平均\nsigma <- 5.5  # 母標準偏差\n\n以下では、様々な標本サイズで標本を抽出し、その標本の平均身長を求める作業を 1万回ずつ繰り返すことにする。\n\nn_sims <- 1e4  # シミュレーションの繰り返し回数\n\n\n12.2.2 標本サイズ (\\(N\\)) が1のとき\n標本サイズ \\(N = 1\\) で標本を抽出し、標本平均を計算することを10^{4} 回n_sims 回）繰り返す。まず、\\(N\\) を設定する。\n\nN <- 1\n\n1回の標本抽出は、\n\nh <- rnorm(N, mean = mu, sd = sigma)\n\nで行える。標本平均は、\n\nmean(h)\n\n[1] 177.7841\n\n\nである。 これを1万回繰り返せばよい。\n（本当はもっと簡単な方法もあるが） for ループを使ってシミュレーションを実行してみよう。\nまず、結果を保存するために、10^{4} 個の値を保存する容器（ベクトル）を用意する。要素（中身）は NA にしておく。\n\nsim_1 <- rep(NA, n_sims)\n\nシミュレーションを実行する準備が整ったので、forループでシミュレーションを実行する（forループ以外で実行する方法を知っている者は、その方法を利用してよい）。\n\nfor (i in 1 : n_sims) {\n  h <- rnorm(N, mean = mu, sd = sigma)\n  sim_1[i] <- mean(h)\n}\n\n結果をヒストグラムにしてみよう。\n\ndf1 <- tibble(sim_1)\nhist1 <- ggplot(df1, aes(x = sim_1, y = after_stat(density))) +\n  geom_histogram(color = \"black\", \n                 fill = \"dodgerblue\") +\n  labs(x = \"身長の標本平均 (cm)\",\n       y = \"確率密度\",\n       title = \"N = 1 の標本分布\")\nplot(hist1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nこのヒストグラムに、平均 170、標準偏差 5.5 の正規分布 (\\(\\mbox{N}(170, 5.5)\\) と表記する) の確率密度曲線を重ね書きしてみよう。\n\ndf1$x <- seq(140, 200, length.out = nrow(df1))\ndf1$dens <- dnorm(df1$x, mean = mu, sd = sigma)\nhist1_2 <- hist1 + \n  geom_line(data = df1, \n            aes(x = x, y = dens), \n            color = \"red\", \n            size = 1.5)\nplot(hist1_2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n図を見る限り、標本平均の標本分布と、母集団の分布はとてもよく似ている。\n統計量も確かめてみよう。\n\nmean(sim_1) # 標本平均の平均値\n\n[1] 169.9419\n\nsd(sim_1)   # 標本平均の標準偏差 = 標準誤差\n\n[1] 5.575504\n\n\nこのように、標本平均の平均値は母平均とほぼ同じであり、標本平均の標準偏差（これを平均値の標準誤差 (standard errors: SE) と呼ぶ）は、母標準偏差とほぼ同じである。\n\n12.2.3 標本サイズ (\\(N\\)) が2のとき\n標本サイズ \\(N = 2\\) で、同様のシミュレーションを行ってみよう。 まず、\\(N\\) を設定する。\n\nN <- 2\n\nあとは、さきほどと同様のコマンドを実行すればよい。ただし、結果を上書きしないように、結果に異なる名前をつける。\n\nsim_2 <- rep(NA, n_sims) \nfor (i in 1 : n_sims) {\n  h <- rnorm(N, mean = mu, sd = sigma)\n  sim_2[i] <- mean(h)  # sim_2 を使う\n}\n\n結果をヒストグラムにしてみよう。\n\ndf2 <- tibble(sim_2)\nhist2 <- ggplot(df2, aes(x = sim_2, y = after_stat(density))) +\n  geom_histogram(color = \"black\", \n                 fill = \"dodgerblue\") +\n  labs(x = \"身長の標本平均 (cm)\",\n       y = \"確率密度\",\n       title = \"N = 2 の標本分布\")\nplot(hist2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nこのヒストグラムに、平均 170、標準偏差 5.5 の正規分布 (\\(\\mbox{Normal}(170, 5.5)\\)) の確率密度曲線を重ね書きしてみよう。\n\nhist2_2 <- hist2 + \n  geom_line(data = df1, \n            aes(x = x, y = dens), \n            color = \"red\", \n            size = 1.5)\nplot(hist2_2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n先ほどとは異なり、標本平均の標本分布と、母集団の分布は少し異なる。標本分布の方が、母集団よりも狭い範囲に集まっていることがわかる。\n統計量も確かめてみよう。\n\nmean(sim_2) # 標本平均の平均値\n\n[1] 170.0054\n\nsd(sim_2)   # 標本平均の標準偏差 = 標準誤差\n\n[1] 3.858958\n\n\n上のシミュレーションと同様、標本平均の平均値は母平均とほぼ同じである。しかし、標本平均の標準偏差である標準誤差 (standard errors; SE) は、母標準偏差よりもかなり小さくなっていることがわかる。\n理論的には、標本平均の標準偏差は \\(母標準偏差/\\sqrt{標本サイズ}\\) になるはずである。確かめてみよう。\n\nsigma / sqrt(N)\n\n[1] 3.889087\n\n\nこれは、上で求めた標準誤差にほぼ一致する。\n\n12.2.4 標本サイズ (\\(N\\)) が10のとき\n標本サイズ \\(nN = 10\\) で同様のシミュレーションを行ってみよう。 まず、\\(N\\) を設定する。\n\nN <- 10\n\nあとは、先ほどと同様のコマンドを実行すればよい。ただし、結果を上書きしないように、結果に異なる名前をつける。\n\nsim_3 <- rep(NA, n_sims) \nfor (i in 1 : n_sims) {\n  h <- rnorm(N, mean = mu, sd = sigma)\n  sim_3[i] <- mean(h)  # sim_3 を使う\n}\n\n結果をヒストグラムにしてみよう。\n\ndf3 <- tibble(sim_3)\nhist3 <- ggplot(df3, aes(x = sim_3, y = after_stat(density))) +\n  geom_histogram(color = \"black\", \n                 fill = \"dodgerblue\") +\n  labs(x = \"身長の標本平均 (cm)\", \n       y = \"確率密度\",\n       title = \"N = 10 の標本分布\")\nplot(hist3)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nこのヒストグラムに、平均 170、標準偏差 5.5 の正規分布 (\\(\\mbox{N}(170, 5.5)\\)) の確率密度曲線を重ね書きしてみよう。\n\nhist3_2 <- hist3 +\n  geom_line(data = df1, \n            aes(x = x, y = dens), \n            color = \"red\", \n            size = 1.5)\nplot(hist3_2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n標本分布がさらに狭い範囲に集まっていることがわかる。\n統計量を確かめてみよう。\n\nmean(sim_3) # 標本平均の平均値\n\n[1] 169.9907\n\nsd(sim_3)   # 標本平均の標準偏差 = 標準誤差\n\n[1] 1.720269\n\n\n先程と同様、標本平均の平均値は母平均とほぼ同じである。また、標本平均の標準偏差である標準誤差 (standard errors; SE) は、母標準偏差よりもより一層小さくなっていることがわかる。\n理論的には、標本平均の標準偏差は \\(母標準偏差/\\sqrt{標本サイズ}\\) になるはずである。確かめてみよう。\n\nsigma / sqrt(N)\n\n[1] 1.739253\n\n\nこれは、上で求めた標準誤差にほぼ一致する。\n\n12.2.5 実習課題\n標本サイズ \\(N\\) を50、100にして、同様のシミュレーションを実行しよう。どのようなことがわかるか文章にまとめて整理しよう。"
  },
  {
    "objectID": "sampling-distribution.html#sec-error",
    "href": "sampling-distribution.html#sec-error",
    "title": "\n12  標本分布を理解する\n",
    "section": "\n12.3 誤差の分布",
    "text": "12.3 誤差の分布\n標本平均の誤差は、 \\[誤差 = 標本平均 - 母平均\\] と表すことができる。また、標本平均の平均値（期待値）は母平均に等しいので、 \\[誤差 = 標本平均 - 標本平均の平均値\\] でも同じことである。\nしたがって、上で実行した3つのシミュレーション（それぞれ、\\(N = 1, 2, 10\\)）の誤差 err_1, err_2, err_3 は、\n\nerr_1 <- sim_1 - mean(sim_1)\nerr_2 <- sim_2 - mean(sim_2)\nerr_3 <- sim_3 - mean(sim_3)\n\nである。さらに、それぞれを標準誤差（標本平均の標準偏差の推定値）で割ってみる。\n\nz1 <- err_1 / sd(sim_1)\nz2 <- err_2 / sd(sim_2)\nz3 <- err_3 / sd(sim_3)\n\n平均値を引いて、それを標準偏差で割っているので、これは標準化 (standardization あるいは \\(z\\)化) である。\nここで、標準正規分布 \\(\\mbox{Normal}(0, 1)\\) の分布を図にしてみよう。\n\ndf_nml <- tibble(z = seq(from = -4, to = 4, length.out = 1000))\ndf_nml$dens <- dnorm(df_nml$z,  mean = 0, sd = 1)\nstdn <- ggplot(df_nml, aes(x = z, y = dens)) +\n  geom_line() +\n  labs(y = \"確率密度\")\nplot(stdn)\n\n\n\n\nこの図に、先ほど計算した z1, z2, z3 の分布を上書きしてみよう。確率密度 (density) を加えるため、geom_density() を使う。\n\ndf_z <- tibble(z1, z2, z3)\ndens_lines <- stdn +\n  geom_density(data = df_z, \n               aes(x = z1, y = after_stat(density)),\n               color = \"red\") +\n  geom_density(data = df_z, \n               aes(x = z2, y = after_stat(density)), \n               color = \"blue\") +\n  geom_density(data = df_z, \n               aes(x = z3, y = after_stat(density)),\n               color = \"orange\")\nplot(dens_lines)\n\n\n\n\nこのように、標本平均を標準化すると、標準正規分布に似た分布が出てくる（4つの曲線が重なり合っていて区別が難しい）。よって、標準正規分布を利用した推定ができそうに見える（本当にできるかどうかは他の機会に解説する）。"
  },
  {
    "objectID": "sampling-distribution.html#sec-mp4",
    "href": "sampling-distribution.html#sec-mp4",
    "title": "\n12  標本分布を理解する\n",
    "section": "\n12.4 標本分布のシミュレーション",
    "text": "12.4 標本分布のシミュレーション\n標本分布のシミュレーション動画 (MP4) を例として示す\n\n\\(N = 1\\)\n\\(N = 2\\)\n\\(N = 10\\)"
  },
  {
    "objectID": "estimating-mean.html",
    "href": "estimating-mean.html",
    "title": "\n13  母平均の推定\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "estimating-mean.html#sec-prep13",
    "href": "estimating-mean.html#sec-prep13",
    "title": "\n13  母平均の推定\n",
    "section": "\n13.1 準備",
    "text": "13.1 準備\n必要なパッケージを読み込む。\n\nlibrary(tidyverse)\n\n次に、日本語が正しく表示されるようにする。\n\n## 図のなかで日本語を使えるようにする\n## フォントの設定はお好みで\n## （Unix/Linux ではIPAexフォントのインストールが必要かも）\nlibrary(fontregisterer)\nif (.Platform$OS.type == \"windows\") { # Windows\n  my_font <- \"Yu Gothic\"\n} else if (capabilities(\"aqua\")) { # macOS\n  my_font <- \"Hiragino Sans\"\n} else { # Unix/Linux\n  my_font <- \"IPAexGothic\"\n}\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))"
  },
  {
    "objectID": "estimating-mean.html#sec-defpop13",
    "href": "estimating-mean.html#sec-defpop13",
    "title": "\n13  母平均の推定\n",
    "section": "\n13.2 母集団を定義する",
    "text": "13.2 母集団を定義する\n\n\n\n成人男性の身長に興味があるとする。母集団の人口を100万、母平均を約170cm、母標準偏差を約6cm に設定する。\n\npop <- rnorm(1e6, mean = 170, sd = 6)\n\n母集団の身長分布は以下のようになる。\n\npop_height <- ggplot(tibble(pop), \n                     aes(x = pop, \n                         y = after_stat(density))) +\n  geom_histogram(color = \"black\") +\n  labs(x = \"身長 (cm)\", \n       y = \"確率密度\", \n       title = \"母集団の分布\")\nplot(pop_height)\n\n\n\n\nこの母集団における身長の母平均は、\n\nmean(pop)\n\n[1] 170.0008\n\n\nであり、母標準偏差は、\n\nsd(pop)\n\n[1] 6.001557\n\n\nである。"
  },
  {
    "objectID": "estimating-mean.html#sec-saple13",
    "href": "estimating-mean.html#sec-saple13",
    "title": "\n13  母平均の推定\n",
    "section": "\n13.3 標本を抽出して母平均を推定する",
    "text": "13.3 標本を抽出して母平均を推定する\n\n13.3.1 標本1\n100万人の母集団全員を調べるのではなく、100人だけ標本として抽出し、その標本を利用して母平均を推定してみよう。\n標本サイズ100の標本を1つ抽出する。\n\nN <- 100  # 標本サイズ\nsample_1 <- sample(pop, size = N, replace = FALSE)\n\n\n13.3.1.1 点推定 (point estimation)\n標本平均を計算する。\n\nmean(sample_1)\n\n[1] 169.3795\n\n\nこれが母平均の点推定値 (point estimate) である。\n\n13.3.1.2 区間推定 (interval estimation)\n区間推定では、1つの値を示す代わりに推定に区間を利用することで、推定に対する不確実性（自信のなさ）を示す。\n推定に標準正規分布を利用する場合、身長 \\(h\\) の点推定値を \\(\\bar{h}\\) とすると、以下のように定義される信頼区間 (confidence interval) を区間推定に使う。 \\[\n\\left[\\bar{h} - Q \\cdot \\mathrm{SE}, \\bar{h} + Q \\cdot \\mathrm{SE} \\right].\n\\] ここで、SE は標準誤差 (standard error) で、これは以下のように推定する。 \\[\\mathrm{SE} = \\frac{u}{\\sqrt{N}}.\\] \\(N\\) は標本サイズ、\\(u\\) は不偏分散の平方根（下で説明する）である。\nまた、\\(Q\\)（と\\(-Q\\)） は、どのような信頼区間を求めたいかによって変わる。 例えば、95％信頼区間を求めたいときは、\\(Q = 1.96\\) を使う。\n特定の信頼度（信頼度に何パーセントを使うか）に対するQの求め方は次の通りである。 まず、100%から信頼度を引く。95%の場合 \\(1 - 0.95 = 0.05\\) である。次に、その値を2で割る。 95%の場合、\\(0.05/2= 0.025\\) である。この値を qnorm() 関数に当てはめる。ただし、lower.tail = FALSE を指定する（指定しない場合は\\(-Q\\) が出てくるので、それを利用してもよい）。\n\n(Q_95 <- qnorm((1 - 0.95) / 2, lower.tail= FALSE))\n\n[1] 1.959964\n\n\n小数第2位までで丸めると、\n\nround(Q_95, digit = 2)\n\n[1] 1.96\n\n\nである。\n87%信頼区間を使いたいときは、\n\n(Q_87 <- qnorm( (1 - 0.87) / 2, lower.tail = FALSE))\n\n[1] 1.514102\n\n\nを使う。\n次に、SE（標準誤差）を求めよう。 そのためにまず、標本の分散（不偏分散, unbiased variance）を計算する。身長を \\(h\\)とすると、身長の不偏分散 Var(\\(h\\)) は \\[\\mathrm{Var}(h) = \\frac{\\sum_{i=1}^n (h_i - \\bar{h})^2}{N - 1}\\] と定義される。これは、var() で計算できる。\n\n(var_1 <- var(sample_1))\n\n[1] 37.35728\n\n\nこの平方根が不偏分散の平方根である。\n\n(sd_1 <- sqrt(var_1))\n\n[1] 6.11206\n\n\nこの値はsd() で直接求められる。\n\nsd(sample_1)\n\n[1] 6.11206\n\n\n母分散（母集団の分散）または母標準偏差（母集団の標準偏差）を知らないときは、ここで計算した標本から得られる値を推定値として使う。ここでは、標本の標準偏差（不偏分散の平方根）を母標準偏差の推定値として使おう。 すると、このサンプルから推定されるSEは、\n\n(SE_1 <- sd_1 / sqrt(N))\n\n[1] 0.611206\n\n\nとなる。\n以上から、95%信頼区間の下限は、\n\n(lb <- mean(sample_1) - Q_95 * SE_1)\n\n[1] 168.1816\n\n\n上限は、\n\n(ub <- mean(sample_1) + Q_95 * SE_1)\n\n[1] 170.5775\n\n\nよって、この標本（標本1）から得られる95%信頼区間は、[168.18, 170.58] である。\n\n13.3.2 信頼区間を求める関数を作る\n上で説明した方法で信頼区間を求められるが、以上の内容を標本を抽出し直す度に実行するのは面倒なので、信頼区間 (confidence intervals) を求める関数を作ってしまおう。信頼度は引数を指定して選べるようにする。\n\nget_confint <- function(x, level = 0.95) {\n  ## 標準正規分布を利用して信頼区間を求める関数\n  ## 引数：x = 推定に使う標本（サンプル）\n  ##       level = 信頼度。既定値（デフォルト）は 0.95\n  ## 返り値：点推定値、信頼区間の下限値、信頼区間の上限値の3つを含むベクトル\n  N <- length(x)  # サンプルサイズ\n  mean_x <- mean(x)\n  SE <- sd(x) / sqrt(N)\n  Q <- qnorm((1 - level) / 2, lower.tail = FALSE)\n  lb <- mean_x - Q * SE\n  ub <- mean_x + Q * SE\n  estimates <- c(round(mean_x, 2), round(lb, 2), round(ub, 2))\n  names(estimates) <- c(\"estimate\", \"lower bound\", \"upper bound\")\n  return(estimates)\n}\n\n先ほどのサンプルを使い、この関数が意図した通りに動くか確認しよう。\n\nget_confint(sample_1)\n\n   estimate lower bound upper bound \n     169.38      168.18      170.58 \n\n\n上で求めたのものと同じ結果が得られた。\nこの関数を使って50%信頼区間を求めるには、\n\nget_confint(sample_1, level = 0.5)\n\n   estimate lower bound upper bound \n     169.38      168.97      169.79 \n\n\nとする。\n87%信頼区間は、\n\nget_confint(sample_1, level = 0.87)\n\n   estimate lower bound upper bound \n     169.38      168.45      170.30 \n\n\nで求められる。\n以下ではこの関数を利用しよう。\n\n13.3.3 標本2\n先ほどとは別の標本（サイズは同じ）を抽出して、母平均を推定してみよう。\n\nsample_2 <- sample(pop, size = N, replace = FALSE)\n\n\nget_confint(sample_2)\n\n   estimate lower bound upper bound \n     169.41      168.22      170.59 \n\n\n先ほどとは異なる推定値が得られた。\n\n\n13.3.4 標本3\nもう1度やってみよう。 先ほどとは別の標本（サイズは同じ）を抽出して、母平均を推定してみよう。\n\nsample_3 <- sample(pop, size = N, replace = FALSE)\n\n\nget_confint(sample_3)\n\n   estimate lower bound upper bound \n     169.65      168.44      170.86"
  },
  {
    "objectID": "estimating-mean.html#sec-13sim",
    "href": "estimating-mean.html#sec-13sim",
    "title": "\n13  母平均の推定\n",
    "section": "\n13.4 シミュレーション",
    "text": "13.4 シミュレーション\n標本抽出を何度も繰り返し、推定（の誤差）がどのようにばらつくか確認してみよう。\nまず、シミュレーションの繰り返し回数を決める。1万回にしてみよう。（コンピュータの性能があまり良くない場合は、この回数を少し小さめ [例えば 1e3]　にしたほうがいいかもしれない）。\n\nn_sims <- 1e4\n\n結果を保存する容器を用意する。今回は、1回ごとに保存する値が3つあるので、1万行 \\(\\times\\) 3列の行列 (matrix) を用意する。行 (row) の数は nrow、列 (column) の数は ncol で指定する。いつものシミュレーションと同じように、とりあえず NA を入れておく。\n\nres_sim <- matrix(NA, nrow = n_sims, ncol = 3)\n\n行列の中身をわかりやすくするために、3つの列に名前をつけておこう。名前は、est（estimate, 推定値）、lb（lower bound, 95％信頼区間の下限値)、ub (upper bound, 95％信頼区間の上限値）にする。\n\ncolnames(res_sim) <- c(\"est\", \"lb\", \"ub\")\n\n準備ができたので、forループでシミュレーションを行う。結果を res_sim の \\(i\\) 行目に保存するために、res_sim[i, ] で \\(i\\)行目を指定する。\n\nfor (i in 1 : n_sims) {\n  smpl <- sample(pop, size = N, replace = FALSE)\n  res_sim[i,] <- get_confint(smpl)\n}\n\nまず、最初の5つの結果を確認してみよう。\n\nres_sim[1:5, ]\n\n        est     lb     ub\n[1,] 169.15 167.90 170.39\n[2,] 171.05 169.87 172.23\n[3,] 169.95 168.85 171.05\n[4,] 170.46 169.05 171.86\n[5,] 169.81 168.67 170.95\n\n\nこのように、1つの標本から計算された値が各行に保存されている。\n\n13.4.1 不偏性を確認する\n上で実行したシミュレーションの結果を利用して、点推定値のヒストグラムを作ってみよう。点推定値は res_sim の1列目に保存されている。 ggplotで図を描くために、行列をデータフレームに変換しよう。as_tibble() で変換できる。\n\ndf_sim <- as_tibble(res_sim)\n\n中身を確認してみよう。\n\nglimpse(df_sim)\n\nRows: 10,000\nColumns: 3\n$ est <dbl> 169.15, 171.05, 169.95, 170.46, 169.81, 170.30, 169.66, 169.45, 16…\n$ lb  <dbl> 167.90, 169.87, 168.85, 169.05, 168.67, 169.11, 168.55, 168.25, 16…\n$ ub  <dbl> 170.39, 172.23, 171.05, 171.86, 170.95, 171.50, 170.76, 170.65, 17…\n\n\nこのように、行列 res_sim の列名を変数名とするデータフレームができた。あとで使うために、シミュレーションid を通し番号で追加しておく。\n\ndf_sim$id <- 1 : n_sims\n\nシミュレーションで得られた点推定値の分布をヒストグラムで確認してみよう。\n\nh_est <- ggplot(df_sim, aes(x = est)) +\n  geom_histogram(color = \"black\", \n                 fill = \"dodgerblue\") +\n  geom_vline(xintercept = mean(pop), \n             color = \"red\") +    # 母平均を赤線で示す\n  labs(x = \"身長の標本平均 (cm)\", \n       y = \"度数\",\n       title = \"標本平均の標本分布\")\nplot(h_est)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nこれらの標本平均の平均は母平均に一致するというのが「不偏性」である。確かめてみよう。\n\nmean(df_sim$est)\n\n[1] 170.0055\n\nmean(pop)\n\n[1] 170.0008\n\n\n標本平均の平均と母平均が、ほぼ一致することがわかる。\n\n13.4.2 信頼区間の意味を理解する\n95%信頼区間とは何だろうか。\n1つの信頼区間を取り出してみる。ここでは、79番目の信頼区間を取り出す。79番目にした理由は特にない。\n\nres_sim[79, 2:3]\n\n    lb     ub \n167.53 170.28 \n\n\nこの信頼区間に、真の母平均170.0007993 は含まれているだろうか。母数が区間内にあれば、この95％信頼区間が母数（パラメタ）を区間内に捉えている確率は1 (100%) である。反対に、母数がこの区間内になければ、この95％信頼区間が母数（パラメタ）を区間内に捉えている確率は0である。\n別の信頼区間を取り出してみる。ここでは、5番目の信頼区間を取り出す。5番目を選んだ理由は特にない。\n\nres_sim[5, 2:3]\n\n    lb     ub \n168.67 170.95 \n\n\nこの信頼区間に、真の母平均170.0007993 は含まれているだろうか。母数が区間内にあれば、この95％信頼区間が母数（パラメタ）を区間内に捉えている確率は1 (100%) である。反対に、母数がこの区間内になければ、この95％信頼区間が母数（パラメタ）を区間内に捉えている確率は0である。\nこれを、1つひとつの標本について確かめ、1万回行ったシミュレーションのうち、母数を捉える95%信頼区間がいくつ得られたか数えてみよう。母数を捉えているかどうかは、2つの不等式で判断できる。\n\n95%信頼区間の下限値 \\(\\leq\\) 母数（母平均）\n95%信頼区間の上限値 \\(\\geq\\) 母数（母平均）\n\n上の2つの条件を両方とも満たすとき、信頼区間が母数を捉えているといえる。今回のように、2つの以上の条件があるときは、& で条件を並べる。\n\ncaught <- res_sim[, 2] <= mean(pop) & res_sim[, 3] >= mean(pop)\n\n条件を2つとも満たす場合は TRUE, そうでない（1つでも条件に合わない）場合は FALSE になる。最初の5つ分だけ確認してみよう。\n\ncaught[1:5]\n\n[1] TRUE TRUE TRUE TRUE TRUE\n\n\n母数を捉えた区間の数は TRUE の個数なので、\n\nsum(caught)\n\n[1] 9481\n\n\nである。つまり、1万個の95％信頼区間のうち、母数を捉えることができた区間は 9481個ある。言い換えると、標本抽出と区間推定を繰り返し行うと、得られた95%信頼区間の94.8%（約95％）は、母数を区間内に捉えられる。これが、信頼区間のパーセンテージの意味である。\n理解を深めるために、信頼区間を図示してみよう。 シミュレーションで得た1万個の信頼区間から、50個だけ無作為に選び、選んだ50個の信頼区間を図示してみよう。\nまず、無作為に50個の結果を選ぶ。データフレームから無作為に行を選びたいときは、dplyr パッケージ（tidyverse に含まれる）の slice_sample() を使う。\n\n\n\n\nrdm_50 <- slice_sample(df_sim, n = 50)\n\n選ばれた信頼区間を図示する。 ::: {.cell}\nci1 <- ggplot(rdm_50, \n              aes(x = as.factor(id), \n                  y = est, \n                  ymin = lb, \n                  ymax = ub)) +\n  geom_pointrange() +\n  labs(x = \"シミュレーション ID\", \n       y = \"点推定値と95%信頼区間\") +\n  coord_flip()  # x軸とy軸を入れ替える\nplot(ci1)\n\n\n\n:::\n結果を見やすくするため、点推定値の大きで並べ替えてみよう。並べ替えは、reorder() で行う。 点推定値 (est) が小さい順に並べ替えよう。\n\nci2 <- ggplot(rdm_50, aes(x = as.factor(reorder(id, est)), \n                          y = est, \n                          ymin = lb,\n                          ymax = ub)) +\n  geom_pointrange() +\n  geom_hline(yintercept = mean(pop), \n             color = \"blue\", \n             linetype = \"dashed\") +\n  labs(x = \"シミュレーション ID\", \n       y = \"点推定値と95%信頼区間\") +\n  coord_flip()  # x軸とy軸を入れ替える\nplot(ci2)\n\n\n\n\n95％信頼区間が青い点線の位置を区間内に含めば、その信頼区間は母数を捉えている。反対に、95％信頼区間が青い点線と交わっていないとき、その信頼区間は母数を捉え損ねている。母数を捉え損ねた区間に色をつけてみよう。\nまず、先ほどと同じ条件を使い、母数を捉えているかどうかを調べる。\n\nrdm_50$caught <- rdm_50$lb <= mean(pop) & rdm_50$ub >= mean(pop)\n\nmyd$caught が TRUE の場合とFALSEの場合で線の色と点推定値の形を区別する。\n\nci3 <- ggplot(rdm_50, aes(x = as.factor(reorder(id, est)), \n                          y = est,\n                          ymin = lb, \n                          ymax = ub, \n                          color = caught,\n                          shape = caught)) +\n  geom_pointrange() +\n  geom_hline(yintercept = mean(pop), \n             color = \"black\", \n             linetype = \"dashed\") +\n  labs(x = \"シミュレーション ID\", \n       y = \"点推定値と95%信頼区間\") +\n  scale_color_brewer(palette = \"Set1\",\n                     name = \"母数を捉えることに\", \n                     labels = c(\"失敗\", \"成功\")) +\n  scale_shape_discrete(name = \"母数を捉えることに\", \n                     　labels = c(\"失敗\", \"成功\")) +\n  coord_flip()  # x軸とy軸を入れ替える\nplot(ci3)\n\n\n\n\n50個の95％信頼区間のうち、2個（2/50 = 0.04）の信頼区間が母数を捉え損ねている。 言い換えると、96％（約95％）の信頼区間が母数を捉えることに成功している。 これが95%信頼区間の「95%」の意味である。"
  },
  {
    "objectID": "estimating-mean.html#sec-ex13",
    "href": "estimating-mean.html#sec-ex13",
    "title": "\n13  母平均の推定\n",
    "section": "\n13.5 実習課題",
    "text": "13.5 実習課題\n成人女性の身長に興味があるとする。母集団の人口を100万、母平均を約162cm、母標準偏差を約5cm に設定して、上と同様のシミュレーションを行い、複数の95％信頼区間を図示してみよう。"
  },
  {
    "objectID": "t-distribution.html",
    "href": "t-distribution.html",
    "title": "\n14  \\(t\\) 分布を利用した母平均の推定\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "t-distribution.html#sec-prep14",
    "href": "t-distribution.html#sec-prep14",
    "title": "\n14  \\(t\\) 分布を利用した母平均の推定\n",
    "section": "\n14.1 準備",
    "text": "14.1 準備\n必要なパッケージを読み込み、図の日本語が正しく表示されるようにする。\n\nlibrary(tidyverse)\nlibrary(fontregisterer)\nif (.Platform$OS.type == \"windows\") { # Windows\n  my_font <- \"Yu Gothic\"\n} else if (capabilities(\"aqua\")) { # macOS\n  my_font <- \"Hiragino Sans\"\n} else { # Unix/Linux\n  my_font <- \"IPAexGothic\"\n}\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))"
  },
  {
    "objectID": "t-distribution.html#sec-14defpop",
    "href": "t-distribution.html#sec-14defpop",
    "title": "\n14  \\(t\\) 分布を利用した母平均の推定\n",
    "section": "\n14.2 母集団を定義する",
    "text": "14.2 母集団を定義する\n\n\n\n成人男性の身長に興味があるとする。母集団の人口を100万、母平均を約170cm、母標準偏差を約6cm に設定する。\n\npop <- rnorm(1e6, mean = 170, sd = 6)\n\n母集団の身長分布は以下のようになる。\n\npop_height <- ggplot(tibble(pop), \n                     aes(x = pop, \n                         y = after_stat(density))) +\n  geom_histogram(color = \"black\") +\n  labs(x = \"身長 (cm)\", \n       y = \"確率密度\", \n       title = \"母集団の分布\")\nplot(pop_height)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nこの母集団の身長の平均（母平均）は、\n\nmean(pop)\n\n[1] 169.9955\n\n\nであり、身長の標準偏差（母標準偏差）は、\n\nsd(pop)\n\n[1] 6.011032\n\n\nである。"
  },
  {
    "objectID": "t-distribution.html#sec-14sample",
    "href": "t-distribution.html#sec-14sample",
    "title": "\n14  \\(t\\) 分布を利用した母平均の推定\n",
    "section": "\n14.3 標本を抽出して母平均を推定する",
    "text": "14.3 標本を抽出して母平均を推定する\n\n14.3.1 標本抽出と母平均の推定のシミュレーション\n100万人の母集団で全員を調べるのではなく、10人だけ標本として抜き出して母平均を推定することを考える。 シミュレーションで標本抽出を1万回繰り返し、それぞれの標本で標本平均を計算しよう。\nまず、標本サイズを10に、シミュレーション回数を1万に設定する。\n\nN <- 10          # 標本サイズ\nn_sims <- 1e4    # シミュレーションの繰り返し回数\n\n1万個の標本平均を保存するためのベクトルを用意する。\n\nmeans <- rep(NA, 1e4)\n\nまた、後で使うので、不偏分散の平方根も保存できるようにする。\n\nu <- rep(NA, 1e4)\n\n母集団 pop から標本サイズ N = 10 の標本を抽出する作業を n_sims = 10^{4} 回繰り返し、それぞれで標本平均と不偏分散の平方根を計算する。\n\nfor (i in 1 : n_sims) {\n  smpl <- sample(pop, size = N, replace = FALSE)\n  means[i] <- mean(smpl)\n  u[i] <- sd(smpl)\n}\n\n標本平均の標本分布を確認してみよう。\n\ndf_sim <- tibble(mean = means, \n                 sd = u)\nh1 <- ggplot(df_sim, aes(x = mean)) +\n  geom_histogram(binwidth = 1, \n                 color = \"black\", \n                 fill = \"dodgerblue\") +\n  labs(x = \"身長の標本平均 (cm)\", \n       y = \"度数\")\nplot(h1)\n\n\n\n\nなんとなく正規分布になっているように見えるが、はたしてそうだろうか。 得られた標本平均を標準化して、標準正規分布と分布を比べてみよう。\n\n14.3.1.1 母分散 \\(\\sigma^2\\) を知っているとき\n母分散 \\(\\sigma^2\\)（あるいは母標準偏差 \\(\\sigma\\)）を知っているという特殊な場合について考える。このとき、標本平均 \\(\\bar{x}\\)は、以下の式で標準化 (standardize) できる。\n\\[\nz = \\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{N}}}.\n\\] 標本平均は不偏推定量なので、 \\[\n\\mathbb{E}[\\bar{x}] = \\mu\n\\] となる。そこで、\\(\\mu\\) は、\n\n(mu <- mean(means))\n\n[1] 169.9729\n\n\nとしよう。\nまた、仮定により \\(\\sigma\\) は知っているので母集団の \\(\\sigma\\) を使う。\n\n(sigma <- sd(pop))\n\n[1] 6.011032\n\n\nこれらの値を使うと、標準化された標本平均 \\(z\\) は、\n\nz <- (means - mu) / (sigma / sqrt(N))\n\nとなる。\nこの \\(z\\) の分布を確認してみよう。\n\ndf_sim$z <- z\nh2 <- ggplot(df_sim, aes(x = z)) +\n  geom_histogram(binwidth = 0.5, \n                 color = \"black\", \n                 fill = \"lightblue\") +\n  labs(title = \"母分散が既知の場合\", \n       y = \"度数\")\nplot(h2)\n\n\n\n\n標準正規分布に似ているように見える。geom_density() を使って \\(z\\) の確率密度曲線（青い点線） を描き、標準正規分布の確率密度曲線（赤い実線）と比べてみよう。\n\ndf_sim$x <- seq(from = -4, to = 4, length.out = nrow(df_sim))\ndf_sim$dens <- dnorm(df_sim$x, mean = 0, sd = 1)\nh3 <- ggplot(df_sim) +\n  geom_histogram(aes(x = z, \n                     y = after_stat(density)),\n                 binwidth = 0.5, \n                 color = \"black\", \n                 fill = \"lightblue\") +\n  geom_density(aes(x = z, \n                   y = after_stat(density)), \n               color = \"blue\", \n               linetype = \"dashed\") +\n  geom_line(aes(x = x, \n                y = dens), \n            color = \"red\") +\n  labs(y = \"確率密度\", \n       title = \"母分散が既知の場合\")\nplot(h3)\n\n\n\n\n2つの確率密度曲線はほぼ一致している。\nこの例のように、母分散を知っているとき、標本平均を標準化した \\(z\\) の分布は標準正規分布に従う。したがって、私たちは区間推定に（これまでどおり）標準正規分布を利用することができる。\n\n14.3.1.2 母分散 \\(\\sigma^2\\) を知らないとき\nしかし、通常私たちは標本しか調べられないので母分散を知らない。母分散を知らないときはどうなるだろうか。\n母分散を知らないとき、先ほどと同じ標準化はできない。なぜなら、上で使った標準化の式には、\\(\\sigma\\) が出てくるが、その値を知らないからだ。そこで、母標準偏差 \\(\\sigma\\) の推定値として、不偏分散の平方根 \\(u\\) を使う。この値は既にuとして保存してある。\nこの \\(u\\) を使い、標本平均 \\(\\bar{x}\\)は、以下の式で標準化する（\\(\\hat{z}\\) は「\\(z\\)ハット」と読む）。 \\[\\hat{z} = \\frac{\\bar{x} - \\mu}{\\frac{u}{\\sqrt{N}}}.\\]\n\nz_hat <- (means - mu) / (u / sqrt(N))\n\nこの \\(\\hat{z}\\) の分布を確認してみよう。\n\ndf_sim$z_hat <- z_hat\nh4 <- ggplot(df_sim, aes(x = z_hat)) +\n  geom_histogram(binwidth = 0.5, \n                 color = \"black\", \n                 fill = \"gray\") +\n  labs(x = expression(hat(z)),\n       y = \"度数\", \n       title = \"母分散が未知の場合\")\nplot(h4)\n\n\n\n\n標準正規分布に似ているように見えるが、どうだろうか。geom_density() を使って \\(\\hat{z}\\)の確率密度曲線（青い点線） を描き、標準正規分布の確率密度曲線（赤い実線）と比べてみよう。\n\nh5 <- ggplot(df_sim) +\n  geom_histogram(aes(x = z_hat, \n                     y = after_stat(density)),\n                 binwidth = 0.5, \n                 color = \"black\", \n                 fill = \"gray\") +\n  geom_density(aes(x = z_hat,\n                   y = after_stat(density)), \n               color = \"blue\", \n               linetype = \"dashed\") +\n  geom_line(aes(x = x, \n                y = dens), \n            color = \"red\") +\n  labs(x = expression(hat(z)), \n       y = \"確率密度\", \n       title = \"母分散が未知の場合\")\nplot(h5)\n\n\n\n\n2つの確率密度曲線は、少しずれている。 2つの確率密度は、0（付近）で最大値をとるという点で同じである。 しかし、分布のばらつきが違う。 平均値付近を比べると、\\(\\hat{z}\\) の分布の方が確率密度が低くなっている。 代わりに、分布の両裾を比べると、\\(\\hat{z}\\) の分布の方が、確率密度が高い。 言い換えると、\\(\\hat{z}\\) の分布は、標準正規分布よりも裾が厚い（重い）分布になっている。\nこの例のように、母分散を知らないとき、標本平均を標準化した \\(\\hat{z}\\) の分布は標準正規分布に従わない。したがって、私たちは区間推定に標準正規分布を利用することができない。\n実は、\\(\\hat{z}\\) の分布は自由度 \\(N - 1\\) の \\(t\\) 分布にしたがっている。 ためしに（シミュレーションで使ったサンプル\\(N\\)は 10なので）自由度9の\\(t\\)分布の確率密度曲線（赤い実線）を重ね書きしてみよう。\n\ndf_sim$tdens <- dt(df_sim$x, df = 9)\nh6 <- ggplot(df_sim) +\n  geom_histogram(aes(x = z_hat, \n                     y = after_stat(density)),\n                 binwidth = 0.5, \n                 color = \"black\", \n                 fill = \"gray\") +\n  geom_density(aes(x = z_hat, \n                   y = after_stat(density)), \n               color = \"blue\", \n               linetype = \"dashed\") +\n  geom_line(aes(x = x, y = tdens), \n            color = \"red\") +\n  labs(x = expression(hat(z)), \n       y = \"確率密度\", \n       title = \"母分散が未知の場合\")\nplot(h6)\n\n\n\n\nこのように、確率密度曲線がほぼ一致する。\n\n14.3.1.3 \\(\\ast\\)分布の比べ方\n上の例では、確率密度曲線を重ね書きすることで分布を比較した。 もう少し厳密に分布を比べたいとき、特に2つの分布が同じ分布といえるかどうか確かめたいときには、Q-Qプロット (qunatile-quantile plot) という図を使う。\nこの図では、分布を確かめる対象となるシミュレーションで得た変数の分位点 (quantile) を縦軸に、比較対象の分布の分位点を横軸にとる。分位点と分位点を比べるので、Q-Q プロットと呼ばれる。\n分位点とは、簡単に言うと、「確率分布で下からa%分に相当する値はいくつか」という値である。標準正規分布では、2.5%の分位点 (「2.5パーセンタイル」と呼ばれる) は\\(-1.96\\)、50%の分位点（50パーセンタイル）は0、97.5％の分位点は1.96 である。 Rでは、quantile() で分位点を求めることができる。\n\nquantile(z, probs = c(0.025, 0.5, 0.975))\n\n        2.5%          50%        97.5% \n-1.968565253 -0.001995798  1.922012245 \n\n\nシミュレーションで得た \\(z\\) の分布については、2.5パーセンタイルが -1.97、50パーセンタイルが0、97.5パーセンタイルが 1.92 であることがわかる。\n2つの分布がもし完全に一致するなら、2つの分布の a% の分位点は、aがどんな値であっても等しいはずである。したがって、片方の分布の分位点を \\(y\\)、もう一方の分布の分位点を \\(x\\) とすれば、2つの分布が等しいときには \\(y=x\\) になるはずである。つまり、yとxの散布図の点が45度線の上にすべて乘るはずである。\nこの性質を利用し、Q-Qプロット上の点が45度線の上にあるかどうか（45度線からどれだけずれているか）を調べることで、分布を比較してみよう。\nまず、\\(z\\)（母分散を知っているときに、標本平均を標準化したもの; sample）と標準正規分布 (qnorm) を比べてみよう。 標準正規分布と比較するためのQ-Qプロットは、stat_qq() で作れる。\n\nqq1 <- ggplot(df_sim, aes(sample = z)) + \n  geom_abline(intercept = 0, \n              slope = 1, \n              linetype = \"dashed\") +  # 45度線 \n  stat_qq(distribution = qnorm) +\n  coord_fixed(ratio = 1) +       　   # 図の縦横比を1:1にする\n  labs(x = \"標準正規分布\", \n       y = \"シミュレーションで得たz\")\nplot(qq1)\n\n\n\n\nシミュレーションなので多少のずれはあるものの、点がほぼ45度線上にあることがわかる。\n次に、\\(\\hat{z}\\)（母分散を知らないときに、標本平均を標準化したもの）と標準正規分布を比べてみよう。\n\nqq2 <- ggplot(df_sim, aes(sample = z_hat)) + \n  geom_abline(intercept = 0, \n              slope = 1, \n              linetype = \"dashed\") +  # 45度線 \n  stat_qq(distribution = qnorm) +\n  xlim(-6, 6) + ylim(-6, 6) +\n  coord_fixed(ratio = 1) +            # 図の縦横比を1:1にする\n  labs(x = \"標準正規分布\", \n       y = expression(paste(\"シミュレーションで得た\", hat(z))))\nplot(qq2)\n\nWarning: Removed 4 rows containing missing values (geom_point).\n\n\n\n\n\n先ほどとは異なり、点が45度線から大きくずれている。ここから、\\(\\hat{z}\\)は標準正規分布に従わないことがよりはっきりとわかる。特に、裾（図の両端）で標準正規分布との違いが大きいことがわかるだろう。\n最後に、\\(\\hat{z}\\)（母分散を知らないときに、標本平均を標準化したもの）と自由度9の\\(t\\)分布 (qt(df = 9)) を比べてみよう。\n\nqq3 <- ggplot(df_sim, aes(sample = z_hat)) + \n  geom_abline(intercept = 0,\n              slope = 1,\n              linetype = \"dashed\") +  # 45度線 \n  stat_qq(distribution = qt, dparams = 9) +\n  xlim(-6, 6) + ylim(-6, 6) +\n  coord_fixed(ratio = 1) +            # 図の縦横比を1:1にする\n  labs(x = \"自由度9のt分布\",\n       y = expression(paste(\"シミュレーションで得た\", hat(z))))\nplot(qq3)\n\nWarning: Removed 4 rows containing missing values (geom_point).\n\n\n\n\n\nやはり多少のずれはあるものの、ほとんどの点が45度線上に乗っていることがわかる。よって、\\(\\hat{z}\\)は、自由度9の\\(t\\)分布に従っていると言えそうである（少なくとも、「自由度9の\\(t\\)分布に従っていない」とはっきり言うことはできない）。"
  },
  {
    "objectID": "t-distribution.html#sec-tdist",
    "href": "t-distribution.html#sec-tdist",
    "title": "\n14  \\(t\\) 分布を利用した母平均の推定\n",
    "section": "\n14.4 \\(t\\) 分布を理解する",
    "text": "14.4 \\(t\\) 分布を理解する\n\\(t\\) 分布は、自由度 \\(df > 0\\) によってその形を変える。\nたとえば、自由度1, 2, 10の \\(t\\)乗分布は以下のように分布する。比較のため、標準正規分布も一緒に示す。\nまず、データフレームを作る。\n\nx1 <-  seq(-3, 3, length = 1000)\nstdn <- dnorm(x1, mean = 0, sd = 1)\nt1 <- dt(x1, df = 1)\nt2 <- dt(x1, df = 2)\nt10 <- dt(x1, df = 10)\ndf_t <- tibble(x = rep(x1, 4),\n               t = c(stdn, t1, t2, t10),\n               group = rep(c(\"stdn\", \"t1\", \"t2\", \"t10\"), rep(1000, 4)))\nglimpse(df_t)\n\nRows: 4,000\nColumns: 3\n$ x     <dbl> -3.000000, -2.993994, -2.987988, -2.981982, -2.975976, -2.969970…\n$ t     <dbl> 0.004431848, 0.004512344, 0.004594136, 0.004677241, 0.004761679,…\n$ group <chr> \"stdn\", \"stdn\", \"stdn\", \"stdn\", \"stdn\", \"stdn\", \"stdn\", \"stdn\", …\n\n\n図を作る（この図の作り方は理解できなくてもよい）。\n\nplt_t <- ggplot(df_t, aes(x = x, y = t, \n                          color = group, linetype = group)) +\n  geom_line() +\n  scale_color_brewer(palette = \"Accent\",\n                     name = \"\", \n                     labels = c(\"標準正規分布\", \"t(df = 1)\",\n                                \"t(df = 2)\", \"t(df = 10)\")) +\n  scale_linetype_discrete(name = \"\", \n                          labels = c(\"標準正規分布\", \"t(df = 1)\",\n                                     \"t(df = 2)\", \"t(df = 10)\")) +\n  labs(x = \"\", y = \"確率密度\")\nplot(plt_t)\n\n\n\n\n\\(t\\)分布の特徴として、\n\n0を中心として左右対称\n標準正規分布より山の頂上が低く、裾が厚い（重い）\n自由度が大きくなるほど標準正規分布に近づく\n\nという点が挙げられらる。\n\\(t\\)分布の形状を確認するための関数を用意したので、これを使って色々な\\(t\\)分布の形状を確認し、\\(t\\)分布の特徴を理解しよう（この関数の中身を理解する必要はない）。\n\nplot_t <- function(df) {\n  x <- seq(from = -4, to = 4, length = 1000)\n  t <- dt(x, df = df)\n  nml <- dnorm(x, mean = 0, sd = 1)\n  d <- tibble(x, t, nml)\n  p <- ggplot(d, aes(x = x)) +\n    geom_line(aes(y = nml), linetype = \"dashed\") +\n    geom_line(aes(y = t), color = \"royalblue\") +\n    labs(x = \"\", y = \"確率密度\",\n         title = str_c(\"自由度\", df, \"のt分布（青い実線）と標準正規分布（黒い点線）\"))\n  plot(p)\n}\n\n自由度1の\\(t\\)分布は、\n\nplot_t(df = 1)\n\n\n\n\n自由度3の \\(t\\)分布は、\n\nplot_t(df = 3)\n\n\n\n\nとなることが確認できる。\n実習課題\n自由度 (df) の値をによって\\(t\\)分布がどのように変化するか、関数 plot_t() を使って確かめてみよう。"
  },
  {
    "objectID": "t-distribution.html#sec-estwt",
    "href": "t-distribution.html#sec-estwt",
    "title": "\n14  \\(t\\) 分布を利用した母平均の推定\n",
    "section": "\n14.5 \\(t\\) 分布を利用した区間推定",
    "text": "14.5 \\(t\\) 分布を利用した区間推定\n\\(t\\) 分布を使った区間推定の方法も、基本的に標準正規分布を使った推定方法と同じである。 身長 \\(x\\) の点推定値を \\(\\bar{x}\\) とすると、以下のように定義される信頼区間 (confidence interval) を区間推定に使う。\n\\[\n\\left[\\bar{h} - t_{N-1, p} \\cdot \\mathrm{SE}, \\bar{h} + t_{N-1, p} \\cdot \\mathrm{SE} \\right].\n\\]\n標準正規分布で \\(Q\\) と表していた値（qnorm() で求めた）を\\(t_{N-1, p}\\) （qt() で求める）に変えただけである。\n母集団から \\(N=10\\) の標本を1つ取り出して、身長の母平均を推定してみよう。\n\nsmpl_1 <- sample(pop, size = 10, replace = FALSE)\n\n身長 \\(x\\) の母平均の点推定値 \\(\\bar{x}\\) は、\n\n(x_bar <- mean(smpl_1))\n\n[1] 167.7088\n\n\nである。\nまた、標準誤差は、\\[\\mathrm{SE} = \\frac{u}{\\sqrt{N}}\\] だから、\n\n(se <- sd(smpl_1) / sqrt(10))\n\n[1] 2.283386\n\n\nである。\nここで、標本サイズ\\(N = 10\\) だから、区間推定を行うには自由度 \\(N - 1 = 9\\) の \\(t\\) 分布を利用する。95パーセント信頼区間を求めたいとすると、\\(t\\)分布の下側2.5%分と、上側2.5%分を除外したい。そのために必要なのが、\\(t_{9, 0.025}\\)（または、\\(-t_{9, 0.025}\\)）の値である。これを qt() で求める。\n\nqt(df = 9, p = 0.025)  # 下側\n\n[1] -2.262157\n\n## qt(df = 9, p = 0.025, lower.tail = FALSE)  # 上側\n## qt(df = 9, p = 0.975)  # 上側はこれでも求められる\n\nこれらの値を使うと、母平均の95%信頼区間を求める。\n\n(lb <- x_bar + qt(df = 9, p = 0.025) * se)\n\n[1] 162.5434\n\n(ub <- x_bar + qt(df = 9, p = 0.975) * se)\n\n[1] 172.8742\n\n\nよって、母平均の95%信頼区間は、[162.54, 172.87] である。\nちなみに、\\(t\\) 分布の代わりに標準正規分布を使って95%信頼区間を求めると、\n\n(lb_n <- x_bar + qnorm(p = 0.025) * se)\n\n[1] 163.2335\n\n(ub_n <- x_bar + qnorm(p = 0.975) * se)\n\n[1] 172.1842\n\n\nとなり、[163.23, 172.18] という区間が得られる。この区間は、\\(t\\)分布を使って求めた区間よりも短い。 つまり、標準正規分布を使うと、不確実性を低く見積もり、「自信過剰な」信頼区間を出してしまう。結果として、標本抽出を繰り返しても95%信頼区間が正解を出す確率が95%よりも低くなってしまうので注意が必要である。\n最後に、\\(t\\) 分布を使って区間推定を行う関数を作っておこう。\n\nget_ci <- function(x, level = 0.95) {\n  ## t 分布を利用して母平均の95%信頼区間を求める関数\n  ## 引数：x = 標本（観測値のベクトル）\n  ##       level = 信頼度（既定値は0.95）\n  N <- length(x)  # 標本サイズを調べる\n  x_bar <- mean(x)\n  se <- sd(x) / sqrt(N)\n  t <- qt(df = N - 1, p = (1 - level) / 2, lower.tail = FALSE)\n  lb <- x_bar - t * se\n  ub <- x_bar + t * se\n  confint <- c(下限値 = lb, 上限値 = ub)\n  message(paste0(level * 100, \"%信頼区間\"))\n  return(confint)\n}\n\nこの関数を使ってみよう。標本1 (smpl_1) から得られる母平均の95%信頼区間は、\n\nget_ci(smpl_1)\n\n95%信頼区間\n\n\n  下限値   上限値 \n162.5434 172.8742 \n\n\nとなり、先ほどと同じ結果が得られた。\n89%信頼区間は、\n\nget_ci(smpl_1, level = 0.89)\n\n89%信頼区間\n\n\n  下限値   上限値 \n163.6606 171.7571 \n\n\nである。\n99.9%信頼区間は、\n\nget_ci(smpl_1, level = 0.999)\n\n99.9%信頼区間\n\n\n  下限値   上限値 \n156.7921 178.6255 \n\n\nである。"
  },
  {
    "objectID": "mean-comparison.html",
    "href": "mean-comparison.html",
    "title": "\n15  統計的検定と平均値の比較\n",
    "section": "",
    "text": "今回の目標"
  },
  {
    "objectID": "mean-comparison.html#sec-prep15",
    "href": "mean-comparison.html#sec-prep15",
    "title": "\n15  統計的検定と平均値の比較\n",
    "section": "\n15.1 準備",
    "text": "15.1 準備\n必要なパッケージを読み込み、図の日本語が正しく表示されるようにする。\n\nlibrary(tidyverse)\n\n## 図のなかで日本語を使えるようにする\n## フォントの設定はお好みで\n## （Unix/Linux ではIPAexフォントのインストールが必要かも）\nlibrary(fontregisterer)\nif (.Platform$OS.type == \"windows\") { # Windows\n  my_font <- \"Yu Gothic\"\n} else if (capabilities(\"aqua\")) { # macOS\n  my_font <- \"Hiragino Sans\"\n} else { # Unix/Linux\n  my_font <- \"IPAexGothic\"\n}\ntheme_set(theme_gray(base_size = 9,\n                     base_family = my_font))"
  },
  {
    "objectID": "mean-comparison.html#sec-15test",
    "href": "mean-comparison.html#sec-15test",
    "title": "\n15  統計的検定と平均値の比較\n",
    "section": "\n15.2 統計的検定",
    "text": "15.2 統計的検定\n\n15.2.1 有意水準の意味を理解する：帰無仮説が正しい場合の仮説検定シミュレーション\n標準正規分布に従う変数 \\(X\\) について考える。これを\n\\[\nX \\sim  \\mbox{Normal}(\\mu = 0, \\sigma = 1)\n\\] と表記する。\n\n\n\n\n\n\n備考\n\n\n\n正規分布 (normal distribution) は \\(\\mbox{Normal}(\\mu, \\sigma^2)\\) のように分散 \\(\\sigma^2\\) を用いて表現されることが多いが、R の関数（例：rnrom()、dnorm() など）の引数は標準偏差 sd なので、標準偏差 \\(\\sigma\\) を用いて \\(\\mbox{Normal}(\\mu, \\sigma)\\) と書くことにする。\n\n\n私たちが母数（パラメタ）を知らないと仮定して、この集団からランダムに標本を抽出し、以下の仮説を検証する。\n\n帰無仮説：\\(\\mu = 0\\)\n\n対立仮説：\\(\\mu \\neq 0\\)\n\n\n有意水準を5% に設定し、検定を行う。実際には帰無仮説のほうが正しいので、帰無仮説を棄却しないことが望ましい。母数を知らずに検定を行った場合、どのような結果が得られるだろうか。\n\n15.2.1.1 1つの標本で検定を行う\n\nまず、標本を抽出する。標本サイズ \\(N = 20\\) に設定しよう。\n\nN <- 20\nsmp_1 <- rnorm(N, mean = 0, sd = 1)  # 標準正規分布からの乱数生成\n\nこの標本の標本平均は、\n\nmean(smp_1)\n\n[1] 0.3524868\n\n\nである。 この標本平均は0ではない。つまり \\(\\bar{x} \\neq 0\\) であるが、ここから、\\(\\mu \\neq 0\\)と言えるだろうか？\n標本平均の分布は自由度 \\(N - 1\\) の \\(t\\) 分布に従うので、\\(t\\) 分布を利用して検定を行う（このような検定を、\\(t\\) 検定と呼ぶ）。\nある標本を利用して、「母平均が0」という帰無仮説を検証したいときは、t.test() という関数を使う。\n対立仮説が「母平均は0ではない」のときは、次のようにする。\n\n(res_1 <- t.test(smp_1))\n\n\n    One Sample t-test\n\ndata:  smp_1\nt = 1.9263, df = 19, p-value = 0.06916\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.03050174  0.73547526\nsample estimates:\nmean of x \n0.3524868 \n\n\nこの結果の読み方を説明しよう。まず、data: smp_1 というところに、検定に利用した標本が示される。次の行を見ると、検定統計量 \\(T\\) の値が t = で 示された後、自由度 (df) と\\(p\\) 値 (p-value) が表示される（\\(p\\)値については「計量経済学」の講義で説明する [説明しないかもしれないが、\\(p\\) 値は使わない方針なので問題ない]）。検定統計量の絶対値 \\(|T|\\) が、自ら決めた有意水準における臨界値の絶対値 |\\(c\\)| より大きいとき、帰無仮説を棄却する。検定統計量自体は、次のようにすれば取り出せる。\n\nres_1$statistic\n\n       t \n1.926333 \n\n\nまた、自由度 \\(N - 1\\) の \\(t\\) 分布で、有意水準が5%のときに必要な臨界値は、\n\nqt(p = 0.05 / 2, df = N - 1)\n\n[1] -2.093024\n\n\nである。この2つの値の絶対値同士を比べると、\\[|T| < |c|\\] だから、帰無仮説は棄却されない。つまり、\\(\\mu = 0\\) を否定する証拠はない。\n実際、\\(\\mu = 0\\)ということを私たちは知っているので、これは妥当な結論である。標本抽出と仮説検定を繰り返したら、どんなことが起きるだろうか？\n\n\n\n\n\n\n重要\n\n\n\n\\(p\\)値というのは統計学の中でもとりわけ難しい概念である。大学教員のなかにものその意味を正しく理解していない人がいるくらいである（皆が統計学を専門としているわけではないのでしかたない）。よって、かなり真剣に統計学を勉強する気がある者以外は、\\(p\\)値には関わらないほうがよいだろう。意味もわからずに卒業論文に\\(p\\)値を掲載すると、質疑応答で困った事態になることが予想される。\n「計量経済学」を受講してくれれば説明はする予定である（気が変わるかもしれないが）。\n\n\n\n15.2.1.2 仮説検定のシミュレーション\n\nまず、標本抽出と仮説検定を1回行い、帰無仮説 (null hypothesis) を棄却しないときは null を、帰無仮説を棄却して対立仮説 (alternative hypothesis) を採用するときは alt を返す関数を作る。 有意水準 (level) と標本サイズは自分で設定できるようにしておく。\n\nsmp_test <- function(N = 10, level = 0.05) {\n  ## 標本を抽出し、「母平均 = 0」という仮説を検定する関数\n  ## 引数：N = 標本サイズ（既定値は10）\n  ##       level = 有意水準（既定値は0.05）\n  smp <- rnorm(N, mean = 0, sd = 1)  # 標準正規分布から乱数を生成する\n  test <- t.test(smp)\n  judge <- abs(test$statistic) > abs(qt(p = level / 2, df = N - 1)) \n  res <- ifelse(judge, \"alt\", \"null\")\n  return(res)\n}\n\n\n\n\n\n\n\n備考\n\n\n\nabs() は絶対値 (abosolute values) を計算する関数である。\n\n\n試しにこの関数を使ってみると、\n\nsmp_test(N = 20, level = 0.05)\n\n     t \n\"null\" \n\n\nというように、1つの標本からどちらの仮説を採用したかがわかる。\n標本サイズ \\(N = 20\\)、有意水準5% で、この作業を10,000回繰り返してみよう。関数を繰り返し実行する際は、replicate() を使うのが便利である。\n\nn_sims <- 1e4\nsim_1 <- replicate(n_sims, smp_test(N = 20, level = 0.05))\n\nsim_1 の中に、10,000個の検定結果が保存されたはずである。最初の5個だけ確認してみよう。\n\nsim_1[1 : 5]\n\n     t      t      t      t      t \n\"null\" \"null\" \"null\" \"null\" \"null\" \n\n\n結果が保存されていることが確認できる。\nでは、それぞれの仮説はそれぞれ何回ずつ採用されただろうか？表 (table) にしてみよう。\n\ntable(sim_1)\n\nsim_1\n alt null \n 507 9493 \n\n\n割合を表示するために、シミュレーション回数で割ると、\n\ntable(sim_1) / n_sims\n\nsim_1\n   alt   null \n0.0507 0.9493 \n\n\nとなる。 このように、対立仮説が約5%、帰無仮説が95%の検定で採用されている。\n私たちは、上で \\(\\mu=0\\) と設定しているので、帰無仮説こそが正しい仮説である。しかし、帰無仮説が正しくても、5%分の検定では、誤って帰無仮説を棄却し、対立仮説を採用してしまう。この誤りのことを、「第1種の誤り (Type I error)」と呼ぶ。第1種の誤りの確率は、有意水準に一致する。私たちは有意水準5%を選んだので、約5%の検定で第1種の誤りをおかしてしまう。\n有意水準を1%にして、本当にそうなるか確かめてみよう。\n\nsim_2 <- replicate(n_sims, smp_test(N = 20, level = 0.01))\ntable(sim_2) / n_sims\n\nsim_2\n  alt  null \n0.011 0.989 \n\n\n第1種の誤り（null が正しいのに alt を採用）の割合は、約1%である。\n有意水準を14%にすると、\n\nsim_3 <- replicate(n_sims, smp_test(N = 20, level = 0.14))\ntable(sim_3) / n_sims\n\nsim_3\n   alt   null \n0.1406 0.8594 \n\n\n第1種の誤り（null が正しいのに alt を採用）の割合は、約14%になる。\n実習課題： 第1種の誤りは、標本サイズの影響を受けるだろうか? 有意水準を固定し、標本サイズ \\(N\\) を10, 20, 100, 200 と変えて、第1種の誤りの割合をシミュレーションしてみよう！\n\n15.2.2 危険率、検出力、標本サイズ：対立仮説が正しい場合の仮説検定シミュレーション\n平均3、標準偏差2の正規分布に従う変数 \\(Y\\) について考える。すなわち、\n\\[\nY \\sim \\mbox{Normal}(\\mu = 3, \\sigma = 2)\n\\] となる変数 \\(Y\\) について考える。\n私たちが母数を知らないと仮定して、この集団からランダムに標本を抽出し、以下の仮説を検証する。\n\n帰無仮説：\\(\\mu = 0\\)\n\n対立仮説：\\(\\mu \\neq 0\\)\n\n\n有意水準を5% に設定し、検定を行う。実際には対立仮説のほうが正しいので、帰無仮説を棄却したい。母数を知らずに検定を行った場合、どのような結果が得られるだろうか。\n\n15.2.2.1 1つの標本で検定を行う\n\nまず、標本を抽出する。標本サイズ \\(N = 20\\) に設定しよう。\n\nN <- 20\nsmp_2 <- rnorm(N, mean = 3, sd = 2)  # N(3, 2) からの乱数生成\n\nこの標本の標本平均は、\n\nmean(smp_2)\n\n[1] 2.597166\n\n\nである。 この標本平均は0ではない。つまり \\(\\bar{y} \\neq 0\\) であるが、ここから、\\(\\mu \\neq 0\\)と言えるだろうか？\n標本平均の分布は自由度 \\(N - 1\\) の \\(t\\) 分布に従うので、\\(t\\) 分布を利用して検定を行う。\n先ほど同様、t.test() を使う。仮説は先ほどと同じなので、次のようにする。\n\n(res_2 <- t.test(smp_2))\n\n\n    One Sample t-test\n\ndata:  smp_2\nt = 4.1959, df = 19, p-value = 0.0004898\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n 1.301646 3.892686\nsample estimates:\nmean of x \n 2.597166 \n\n\n検定統計量 \\(T\\) の値は、\n\nres_2$statistic\n\n       t \n4.195944 \n\n\nである。 また、自由度 \\(N - 1\\) の \\(t\\) 分布で、有意水準が5%のときに必要な臨界値は、\n\nqt(p = 0.05 / 2, df = N - 1)\n\n[1] -2.093024\n\n\nである。この2つの値の絶対値同士を比べると、\\[|T| > |c|\\] だから、帰無仮説は棄却される。\n実際、\\(\\mu = 2\\)ということを私たちは知っているので、これは妥当な結論であるが、標本抽出と仮説検定を繰り返したら、どんなことが起きるだろうか？\n\n15.2.2.2 仮説検定のシミュレーション\n\nまず、標本抽出と仮説検定を1回行い、帰無仮説 (null hypothesis) を棄却しないときは null を、帰無仮説を棄却して対立仮説 (alternative hypothesis) を採用するときは alt を返す関数を作る。 先ほど作った関数を改良し、母平均と母標準偏差も自分で設定できるようにする。\n\nsmp_test_2 <- function(N = 10, level = 0.05, mu = 0, sigma = 1) {\n  ## 標本を抽出し、「母平均 = 0」という仮説を検定する関数\n  ## 引数：N = 標本サイズ（既定値は10）\n  ##       level = 有意水準（既定値は0.05）\n  ##       mu = 母平均（既定値は0）\n  ##       sigma = 母標準偏差（既定値は1）\n  smp <- rnorm(N, mean = mu, sd = sigma)  # 正規分布から乱数を生成する\n  test <- t.test(smp)\n  judge <- abs(test$statistic) > abs(qt(p = level / 2, df = N - 1))\n  res <- ifelse(judge, \"alt\", \"null\")\n  return(res)\n}\n\n試しにこの関数を使ってみると、\n\nsmp_test_2(N = 20, level = 0.05, mu = 2, sigma = 3)\n\n    t \n\"alt\" \n\n\nというように、1つの標本からどちらの仮説を採用したかがわかる。\n標本サイズ \\(N = 20\\)、有意水準5% で、この作業を10,000回繰り返してみよう。\n\nn_sims <- 1e4\nsim_11 <- replicate(n_sims, smp_test_2(N = 20, level = 0.05, mu = 2, sigma = 3))\n\nsim_11 の中に、10,000個の検定結果が保存されたはずである。最初の5個だけ確認してみよう。\n\nsim_11[1 : 5]\n\n    t     t     t     t     t \n\"alt\" \"alt\" \"alt\" \"alt\" \"alt\" \n\n\n結果が保存されていることが確認できる。\nでは、それぞれの仮説はそれぞれ何割ずつ採用されただろうか？表 (table) にしてみよう。\n\ntable(sim_11) / n_sims\n\nsim_11\n   alt   null \n0.8104 0.1896 \n\n\nこのように、対立仮説が約81%、帰無仮説が約19%の検定で採用されている。\n私たちは、上で \\(\\mu=2\\) と設定しているので、対立仮説こそが正しい仮説である。しかし、対立仮説が正しくても、19%分の検定では、帰無仮説を棄却せず、対立仮説を採用できない。この誤りのことを、「第2種の誤り (Type II error)」と呼ぶ。第2種の誤りの確率は、どうやって決まるのだろうか？\n有意水準を1%にして、第2種の誤りの割合を計算してみよう。\n\nsim_12 <- replicate(n_sims, smp_test_2(N = 20, level = 0.01, mu = 2, sigma = 3))\ntable(sim_12) / n_sims\n\nsim_12\n   alt   null \n0.5639 0.4361 \n\n\n第2種の誤り（null が正しいのに alt を採用 alt が正しいのに null を採用）の割合は、約44%である。有意水準を小さくしたところ、第2種の誤りの割合が大きくなった。\n今度は、有意水準を10%にしてみよう。\n\nsim_13 <- replicate(n_sims, smp_test_2(N = 20, level = 0.1, mu = 2, sigma = 3))\ntable(sim_13) / n_sims\n\nsim_13\n   alt   null \n0.8892 0.1108 \n\n\n第2種の誤り（null が正しいのに alt を採用）の割合は、約11%である。有意水準を大きくしたところ、第2種の誤りの割合が小さくなった。\nこのように、第2種の誤りの確率は、有意水準と負の相関関係をもつ。第2種の誤りをおかす確率を小さくするためには、有意水準を大きくすればよい。しかし、有意水準は、それ自体が第1種の誤りの確率を表しているので、有意水準を大きくするということは、第1種の誤りの確率が大きくなるということである。\n有意水準を変えずに、第2種の誤りの確率を小さくすることはできないだろうか。 第2種の誤りを小さくするには、「0との違い」を見つけ出す力を強めればよい。つまり、小さな違いでも違いとして見つけ出すことができれば、帰無仮説を棄却することができるようになり、第2種の誤りの確率は小さくなる。このような力のことを検出力 (power) と呼ぶ。検出力は標本サイズに依存する。\n有意水準を5%にして、標本サイズを 10, 20, 50, 100, 200 と変えて、第2種の誤りの割合を計算してみよう。\n\\(N = 10\\) のとき。\n\nsim_14 <- replicate(n_sims, smp_test_2(N = 10, level = 0.05, mu = 2, sigma = 3))\ntable(sim_14) / n_sims\n\nsim_14\n  alt  null \n0.471 0.529 \n\n\n\\(N = 20\\) のとき。\n\nsim_15 <- replicate(n_sims, smp_test_2(N = 20, level = 0.05, mu = 2, sigma = 3))\ntable(sim_15) / n_sims\n\nsim_15\n   alt   null \n0.8016 0.1984 \n\n\n\\(N = 50\\) のとき。\n\nsim_16 <- replicate(n_sims, smp_test_2(N = 50, level = 0.05, mu = 2, sigma = 3))\ntable(sim_16) / n_sims\n\nsim_16\n   alt   null \n0.9969 0.0031 \n\n\n\\(N = 100\\) のとき。\n\nsim_17 <- replicate(n_sims, smp_test_2(N = 100, level = 0.05, mu = 2, sigma = 3))\ntable(sim_17) / n_sims\n\nsim_17\nalt \n  1 \n\n\n\\(N = 200\\) のとき。\n\nsim_18 <- replicate(n_sims, smp_test_2(N = 200, level = 0.05, mu = 2, sigma = 3))\ntable(sim_18) / n_sims\n\nsim_18\nalt \n  1 \n\n\nこのように、標本サイズを大きくすると、第2種の誤りの確率は下がる。したがって、統計的検定における誤りの確率を減らすためには、有意水準を小さくし、標本サイズを大きくすることが重要になる（しかし、このことは、標本サイズさえ大きくすれば、些細な違いも検出されてしまうということも意味しているので、実用上は注意が必要である）。"
  },
  {
    "objectID": "mean-comparison.html#sec-ttest",
    "href": "mean-comparison.html#sec-ttest",
    "title": "\n15  統計的検定と平均値の比較\n",
    "section": "\n15.3 平均値の差の検定",
    "text": "15.3 平均値の差の検定\n2つのグループの平均値に差があるかどうか、統計的検定で判断しよう。これまで同様、t.test() を使って\\(t\\)検定を行うが、問題によって指定しなけばいけない引数が異なるので注意が必要である。\n\n15.3.1 対応のないデータの平均値の差の検定\n例題： 2つのコーヒーチェーンで、どちらのコーヒーが美味しいか調べるため、無作為に選んだ10人にD店のコーヒーを、無作為に選んだ別の10人にS店のコーヒーを飲んでもらった。10点満点で点数をつけてもらったところ、次のようなデータが得られた。\n\nd <- c(8, 7, 8, 6, 4, 8, 9, 10, 7, 7)\ns <- c(6, 10, 3, 10, 4, 4, 5, 7, 2, 6)\n\nd とs がそれぞれのコーヒーに対する10人の評価である。D店のコーヒーを飲んだ10人と、S店のコーヒーを飲んだ10人は異なるので、これは対応のないデータであると考えられる。\n2つの店のコーヒーの味に対する評価の平均値は、\n\nmean(d)\n\n[1] 7.4\n\nmean(s)\n\n[1] 5.7\n\n\nであり、単純に比較すれば、D店のコーヒーの方が美味しいということになりそうである。しかし、この結果は、1つの標本から得られた結果に過ぎない。言い換えると、今回抽出された人たちは、たまたまD店の味を好んだだけかもしれない。そこで、統計的検定の方法を使って、2店の美味しさに違いがあるかどうか判断しよう。\n各コーヒー店のコーヒーの味の評価の母数（パラメタ、真実の値）をそれぞれ \\(D\\) と \\(S\\) とすると、今回検証する仮説は、\n\n帰無仮説：\\(D = S\\)（つまり、\\(D - S = 0\\)）\n対立仮説：\\(D \\neq S\\)（つまり、\\(D - S \\neq 0\\)）\n\nということになる。これを、有意水準5% で検定する。また、2つのグループの分散は異なると仮定する（2つのグループの分散が等しいと仮定できるときは、var.equal = TRUE を指定するが、通常は母分散を知らないので等しいと仮定しない）。\n以下のコマンドで Welch の \\(t\\) 検定を実行する。\n\n(eg_1 <- t.test(d, s, var.equal = FALSE))\n\n\n    Welch Two Sample t-test\n\ndata:  d and s\nt = 1.6953, df = 14.848, p-value = 0.1109\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.4392736  3.8392736\nsample estimates:\nmean of x mean of y \n      7.4       5.7 \n\n\n検定統計量は、1.6953 である。また、この検定に必要な \\(t\\) 分布の自由度 (df) は、14.848 である。この自由度を使って検定に使う臨界値を求めると、\n\nqt(p = 0.05 / 2, df = 14.848)\n\n[1] -2.133352\n\n\nである。\\(|T| = 1.6953 < 2.133352 = |c|\\) だから、帰無仮説は棄却されない。したがって、D店のコーヒーのほうが美味しいとは言えない。\nちなみに、t.test() の結果として表示される95%信頼区間から、検定結果を出すこともできる。 この例では、DとSの差の95%信頼区間が表示されており、それが \\([-0.439, 3.839]\\) である。この区間が0（つまり、2つの美味しさに差がない）を含んでいるので、有意水準5%で帰無仮説を棄却できない。\n\n15.3.2 対応のあるデータの平均値の差の検定\n例題： 2つのコーヒーチェーンで、どちらのコーヒーが美味しいか調べるため、無作為に選んだ10人にD店のコーヒーとS店のコーヒーを1杯ずつ飲んでもらった。それぞれのコーヒーに10点満点で点数をつけてもらったところ、次のようなデータが得られた。\n\nsurvey <- tibble(\n  id = 1:10,\n  d = c(8, 7, 8, 6, 4, 8, 9, 10, 7, 7),\n  s = c(6, 10, 3, 10, 4, 4, 5, 7, 2, 6)\n)\nsurvey\n\n# A tibble: 10 × 3\n      id     d     s\n   <int> <dbl> <dbl>\n 1     1     8     6\n 2     2     7    10\n 3     3     8     3\n 4     4     6    10\n 5     5     4     4\n 6     6     8     4\n 7     7     9     5\n 8     8    10     7\n 9     9     7     2\n10    10     7     6\n\n\nid は、回答者番号、d はD店のコーヒーに対する評価、s はS店のコーヒーに対する評価である。\n同じ10人がD店のコーヒーとS店のコーヒーの両方を飲んで評価しているので、これは対応のあるデータであると考えられる。\n2つの店のコーヒーの味に対する評価の平均値は、\n\nmean(survey$d)\n\n[1] 7.4\n\nmean(survey$s)\n\n[1] 5.7\n\n\nであり、単純に比較すれば、D店のコーヒーのほうが美味しいということになりそうである。しかし、この結果は、1つの標本から得られた結果に過ぎない。言い換えると、今回抽出された人たちは、たまたまD店の味を好んだだけかもしれない。そこで、統計的検定の方法を使って、2店の美味しさに違いがあるかどうか判断しよう。\n各コーヒー店のコーヒーの味の評価の母数（パラメタ、真実の値）をそれぞれ \\(D\\) と \\(S\\) とすると、今回検証する仮説は、\n\n帰無仮説：\\(D = S\\)（つまり、\\(D - S = 0\\)）\n対立仮説：\\(D \\neq S\\)（つまり、\\(D - S \\neq 0\\)）\n\nということになる。これを、有意水準5% で検証する。対応のあるデータであることをRに伝えるため、paired = TRUE を指定する）。\n\n(eg_2 <- t.test(survey$d, survey$s, paired = TRUE))\n\n\n    Paired t-test\n\ndata:  survey$d and survey$s\nt = 1.6805, df = 9, p-value = 0.1272\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.5883968  3.9883968\nsample estimates:\nmean of the differences \n                    1.7 \n\n\n検定統計量は、1.6805 である。また、この検定に必要な \\(t\\) 分布の自由度 (df) は、9 である。この自由度を使って検定に使う臨界値を求めると、\n\nqt(p = 0.05 / 2, df = 9)\n\n[1] -2.262157\n\n\nである。\\(|T| = 1.6953 < 2.262157 = |c|\\) だから、帰無仮説は棄却されない。したがって、D店のコーヒーのほうが美味しいとは言えない。\n2つの美味しさの差の95%信頼区間を見てみると、 \\([-0.588, 3.988]\\) である。この区間が0（美味しさに差がない） を含んでいるので、有意水準5%で帰無仮説は棄却されず、保留される。"
  }
]